{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import davos\n",
    "except:\n",
    "    %pip install davos\n",
    "davos.config.suppress_stdout = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jmanning/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# from bs4 smuggle BeautifulSoup                              # pip: beautifulsoup4==4.12.2\n",
    "smuggle requests                                            # pip: requests==2.28.2\n",
    "from tqdm smuggle tqdm                                      # pip: tqdm==4.65.0\n",
    "# smuggle textract                                            # pip: textract==1.6.4\n",
    "# smuggle Levenshtein                                         # pip: levenshtein\n",
    "# smuggle fuzzywuzzy                                          # pip: fuzzywuzzy==0.18.0\n",
    "# smuggle unidecode                                           # pip: Unidecode==1.3.6\n",
    "smuggle pandas as pd                                        # pip: pandas==2.0.1\n",
    "smuggle numpy as np                                         # pip: numpy==1.25.2\n",
    "smuggle seaborn as sns                                      # pip: seaborn==0.12.2\n",
    "from matplotlib smuggle pyplot as plt                       # pip: matplotlib==3.7.1\n",
    "from IPython.display import Markdown\n",
    "# smuggle llama_cpp                                           # pip: llama-cpp-python==0.1.83\n",
    "# from langchain.llms smuggle LlamaCpp                        # pip: langchain==0.0.274\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import LLMChain\n",
    "# from huggingface_hub smuggle hf_hub_download\n",
    "smuggle openpyxl                                           # pip: openpyxl==3.1.2\n",
    "\n",
    "from nltk.tokenize smuggle word_tokenize, sent_tokenize     # pip: nltk==3.8.1\n",
    "from nltk import pos_tag\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "smuggle contractions                                       # pip: contractions==0.1.73\n",
    "\n",
    "smuggle re\n",
    "smuggle os\n",
    "smuggle urllib\n",
    "smuggle json\n",
    "smuggle string\n",
    "smuggle warnings\n",
    "smuggle pickle\n",
    "from glob smuggle glob as lsdir\n",
    "from collections import defaultdict\n",
    "\n",
    "from pathlib smuggle Path\n",
    "\n",
    "from helpers smuggle format_filename, get_soup, get_pdf_text, get_doc_text, get_dialogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting references to past and future events\n",
    "\n",
    "At a high level, the goal of this meta analysis is to predict in-text references to past and future events.  Manually identifying these references is labor and time intensive, so it is impractical to scale up manual tagging to millions of documents.  Instead, we've defined some heuristics for *predicting* when text is referring to real or hypothetical past or future events.  Our approach comprises four main steps:\n",
    "\n",
    "1. First we use the `nltk` package to segment each document into individual sentences. Each sentence is processed independently of the others.\n",
    "2. Next, we handle contractions using the `contractions` package (e.g., \"we'll\" gets split into \"we will,\" and so on).\n",
    "3. Third, we define two sets of \"keywords\" (words and phrases) that tend to be indicative of referring to the past (`past_keywords.txt`) or future (`future_keywords.txt`).  We used ChatGPT (`gpt-4`) to generate each list, with exactly 50 templates per list, using the following prompt:\n",
    "```\n",
    "I'm designing a heuristic algorithm for identifying references (in text) to past and future events. Part of the algorithm will involve looking for specific keywords or phrases that suggest that the text is referring to something that happened (or will happen) in the past and/or future. Could you help me generate a list of 50 keywords or phrases to include in each list (one list for identifying references to the past and a second list for identifying references to the future)? I'd like to be able to paste the lists you generate into two plain text documents with one row per keyword or phrase, and no other content. Please output the lists as a \"code\" block (enclosed by ```...```).\n",
    "```\n",
    "4. Finally, we use part-of-speech tagging (using the `nltk` package) to look for verbs or verb phrases that are in past or future tenses. After the words are tagged with their predicted parts of speech, we use regular expressions (applied to the sequences of tags) to label each verb or verb phrase with a human readable verb form (e.g., \"future perfect continuous passive,\" \"conditional perfect continuous passive,\" and so on).\n",
    "\n",
    "We treat each keyword match (of past or future keywords) as a single \"reference\" (to a past or future event, respectively), and if any past or future verb forms are detected we treat those as (up to) one additional reference.  We then tally up the numbers of past and/or future references across sentences within the document.\n",
    "\n",
    "The `process_folder` function returns two things:\n",
    "  - `df_results` is a DataFrame with one row per document (index), and the following columns:\n",
    "    - `Past`: the number of references to past events identified in the document\n",
    "    - `Future`: the number of references to future events identified in the document\n",
    "  - `sent_results` is a dictionary whose keys are filenames of .txt files in the given folder, and whose values are DataFrames with one row per sentence in the given document.  The per-document DataFrames have the following columns:\n",
    "    - `content`: the text of the given sentence\n",
    "    - `past`: the number of references to past events identified in the given sentence\n",
    "    - `future`: the number of references to future events identified in the given sentence\n",
    "\n",
    "In the metaanalysis reported in our paper, we only use results from the `df_results` DataFrames.  However, the `sent_results` dictionaries are useful for spot-checking how the heuristics are working, and for digging into results for any given document(s).\n",
    "\n",
    "Running the `process_folder` function can take a long time if there are many documents to process.  We save out the results as pickle files after running the function for the first time on a given directory so that the analysis only needs to be run one time per folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keywords(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return set(line.strip() for line in f)\n",
    "\n",
    "\n",
    "def handle_contractions(sentence):\n",
    "    return contractions.fix(sentence)\n",
    "\n",
    "\n",
    "def sentence_tense(x):\n",
    "  # source: https://stackoverflow.com/questions/30016904/determining-tense-of-a-sentence-python\n",
    "  def tense_detect(tagged_sentence):        \n",
    "    verb_tags = ['MD','MDF',\n",
    "                'BE','BEG','BEN','BED','BEDZ','BEZ','BEM','BER',\n",
    "                'DO','DOD','DOZ',\n",
    "                'HV','HVG','HVN','HVD','HVZ',\n",
    "                'VB','VBG','VBN','VBD','VBZ',\n",
    "                'SH',\n",
    "                'TO',                \n",
    "                'JJ']\n",
    "    \n",
    "    verb_phrase = []\n",
    "    for item in tagged_sentence:\n",
    "        if item[1] in verb_tags:\n",
    "            verb_phrase.append(item)\n",
    "\n",
    "    grammar = r'''\n",
    "            future perfect continuous passive:     {<MDF><HV><BEN><BEG><VBN|VBD>+}\n",
    "            conditional perfect continuous passive:{<MD><HV><BEN><BEG><VBN|VBD>+}\n",
    "            future continuous passive:             {<MDF><BE><BEG><VBN|VBD>+}   \n",
    "            conditional continuous passive:        {<MD><BE><BEG><VBN|VBD>+}    \n",
    "            future perfect continuous:             {<MDF><HV><BEN><VBG|HVG|BEG>+}   \n",
    "            conditional perfect continuous:        {<MD><HV><BEN><VBG|HVG|BEG>+}\n",
    "            past perfect continuous passive:       {<HVD><BEN><BEG><VBN|VBD>+}\n",
    "            present perfect continuous passive:    {<HV|HVZ><BEN><BEG><VBN|VBD>+}\n",
    "            future perfect passive:                {<MDF><HV><BEN><VBN|VBD>+}   \n",
    "            conditional perfect passive:           {<MD><HV><BEN><VBN|VBD>+}    \n",
    "            future continuous:                     {<MDF><BE><VBG|HVG|BEG>+ }   \n",
    "            conditional continuous:                {<MD><BE><VBG|HVG|BEG>+  }   \n",
    "            future indefinite passive:             {<MDF><BE><VBN|VBD>+ }\n",
    "            conditional indefinite passive:        {<MD><BE><VBN|VBD>+  }\n",
    "            future perfect:                        {<MDF><HV><HVN|BEN|VBN|VBD>+ }   \n",
    "            conditional perfect:                   {<MD><HV><HVN|BEN|VBN|VBD>+  }   \n",
    "            past continuous passive:               {<BED|BEDZ><BEG><VBN|VBD>+}  \n",
    "            past perfect continuous:               {<HVD><BEN><HVG|BEG|VBG>+}   \n",
    "            past perfect passive:                  {<HVD><BEN><VBN|VBD>+}\n",
    "            present continuous passive:            {<BEM|BER|BEZ><BEG><VBN|VBD>+}   \n",
    "            present perfect continuous:            {<HV|HVZ><BEN><VBG|BEG|HVG>+}    \n",
    "            present perfect passive:               {<HV|HVZ><BEN><VBN|VBD>+}\n",
    "            future indefinite:                     {<MDF><BE|DO|VB|HV>+ }       \n",
    "            conditional indefinite:                {<MD><BE|DO|VB|HV>+  }   \n",
    "            past continuous:                       {<BED|BEDZ><VBG|HVG|BEG>+}           \n",
    "            past perfect:                          {<HVD><BEN|VBN|HVD|HVN>+}\n",
    "            past indefinite passive:               {<BED|BEDZ><VBN|VBD>+}   \n",
    "            present indefinite passive:            {<BEM|BER|BEZ><VBN|VBD>+}            \n",
    "            present continuous:                    {<BEM|BER|BEZ><BEG|VBG|HVG>+}            \n",
    "            present perfect:                       {<HV|HVZ><BEN|HVD|VBN|VBD>+  }       \n",
    "            past indefinite:                       {<DOD><VB|HV|DO>|<BEDZ|BED|HVD|VBN|VBD>+}        \n",
    "            infinitive:                            {<TO><BE|HV|VB>+}\n",
    "            present indefinite:                    {<DO|DOZ><DO|HV|VB>+|<DO|HV|VB|BEZ|DOZ|BER|HVZ|BEM|VBZ>+}    \n",
    "            '''\n",
    "\n",
    "    if len(verb_phrase) > 0:\n",
    "      cp = nltk.RegexpParser(grammar)\n",
    "      result = cp.parse(verb_phrase)\n",
    "    else:\n",
    "      result = []\n",
    "    \n",
    "    tenses_set = set()\n",
    "    for node in result:\n",
    "      if type(node) is nltk.tree.Tree:\n",
    "        tenses_set.add(node.label())\n",
    "    \n",
    "    return tenses_set\n",
    "    \n",
    "  text = word_tokenize(x)\n",
    "  tagged = pos_tag(text)\n",
    "  return tense_detect(tagged)\n",
    "\n",
    "\n",
    "def analyze_sentence(sentence, past_keywords, future_keywords):\n",
    "    past_count = 0\n",
    "    future_count = 0\n",
    "\n",
    "    sentence = handle_contractions(sentence)\n",
    "    \n",
    "    # Check for past and future keywords\n",
    "    past_kw_found = any(keyword in sentence for keyword in past_keywords)\n",
    "    future_kw_found = any(keyword in sentence for keyword in future_keywords)\n",
    "\n",
    "    # Count up to one past and/or future reference based on keywords\n",
    "    past_count += int(past_kw_found)\n",
    "    future_count += int(future_kw_found)\n",
    "    \n",
    "    # Also look at tenses\n",
    "    tenses = sentence_tense(sentence)\n",
    "    if any(['past' in x for x in tenses]):\n",
    "        past_count += 1\n",
    "    if any(['future' in x for x in tenses]) or any(['conditional indefinite' in x for x in tenses]):\n",
    "        future_count += 1\n",
    "\n",
    "    return past_count, future_count\n",
    "\n",
    "\n",
    "def process_folder(folder_path, past_keywords, future_keywords):    \n",
    "    # Dictionary to store results\n",
    "    results_dict = defaultdict(lambda: {\"Past\": 0, \"Future\": 0})\n",
    "    sentence_dfs = {}\n",
    "\n",
    "    for file_name in tqdm(os.listdir(folder_path)):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            with open(os.path.join(folder_path, file_name), 'r', encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "                sentences = nltk.sent_tokenize(content)\n",
    "\n",
    "                # Dataframe to store results for each sentence in the current file\n",
    "                df = pd.DataFrame(columns=[\"content\", \"past\", \"future\"])\n",
    "\n",
    "                for sentence in sentences:\n",
    "                    past_count, future_count = analyze_sentence(sentence, past_keywords, future_keywords)\n",
    "                    results_dict[file_name][\"Past\"] += past_count\n",
    "                    results_dict[file_name][\"Future\"] += future_count\n",
    "                    df = df._append({\"content\": sentence, \"past\": past_count, \"future\": future_count}, ignore_index=True)\n",
    "\n",
    "                sentence_dfs[file_name] = df\n",
    "\n",
    "    df_results = pd.DataFrame(results_dict).T\n",
    "\n",
    "    return df_results, sentence_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords that reflect past events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Past keywords and phrases:**\n",
       "\n",
       "used to be | historically | in those days | once upon a time | last season | last semester | since | hitherto | last quarter | wrote | before | last year | yesterday | last month | so far | made | had | was | used to | back when | antiquity | formerly | were | last time | concluded | recently | once | up to now | bygone | long ago | previously | yesteryear | terminated | ceased | last night | then | heretofore | expired | last week | in the past | already | ago | olden days | did | elapsed | to date | thus far | earlier | said | final"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_keywords = load_keywords(str(Path.cwd().parent.joinpath('data', 'past_keywords.txt')))\n",
    "Markdown('**Past keywords and phrases:**\\n\\n' + ' | '.join(past_keywords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords that reflect future events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Future keywords and phrases:**\n",
       "\n",
       "intend to | in time | imminently | after | hereafter | upcoming | on the horizon | impending | next quarter | eventual | futuristic | looming | may | in the future | next week | subsequent | predicted | soon | might | could | succeeding | later on | next time | next year | next month | scheduled to | next season | will | shall | in the works | eventually | to be | shortly | going to | next semester | can | prospective | tomorrow | anticipated | down the line | later | in the cards | plan to | some day | forthcoming"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_keywords = load_keywords(str(Path.cwd().parent.joinpath('data', 'future_keywords.txt')))\n",
    "Markdown('**Future keywords and phrases:**\\n\\n' + ' | '.join(future_keywords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the data\n",
    "\n",
    "We'll examine 12 datasets that span several broad categories of documents: *film* (transcripts of movies or excerpts of transcripts from movies), *television* (transcripts of television shows or excerpts of transcripts from television shows), *speech* (transcripts of spoken communication), and *text* (written works or conversations that took place using text-based media).\n",
    "\n",
    "The datasets are summarized in the DataFrame below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Short name</th>\n",
       "      <th>Data URL</th>\n",
       "      <th>Source URL</th>\n",
       "      <th>Description</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Internet Movie Script Database</td>\n",
       "      <td>IMSDb</td>\n",
       "      <td>https://www.dropbox.com/scl/fi/ct39vqqq9sjqyyh...</td>\n",
       "      <td>https://imsdb.com</td>\n",
       "      <td>A collection of scripts from roughly 1000 popu...</td>\n",
       "      <td>Film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Dialogues Dataset</td>\n",
       "      <td>Movies</td>\n",
       "      <td>https://www.dropbox.com/s/881yuhil48v6q1n/movi...</td>\n",
       "      <td>https://convokit.cornell.edu/documentation/mov...</td>\n",
       "      <td>A large collection of fictional conversations ...</td>\n",
       "      <td>Film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Switchboard Dialog Act Corpus</td>\n",
       "      <td>Switchboard</td>\n",
       "      <td>https://www.dropbox.com/s/qvx4211u41l2ex4/swit...</td>\n",
       "      <td>https://convokit.cornell.edu/documentation/swi...</td>\n",
       "      <td>A collection of five-minute telephone conversa...</td>\n",
       "      <td>Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Supreme Court Corpus</td>\n",
       "      <td>SCOTUS</td>\n",
       "      <td>https://www.dropbox.com/s/icxk3ubo2u2brzq/supr...</td>\n",
       "      <td>https://convokit.cornell.edu/documentation/sup...</td>\n",
       "      <td>A collection of cases from the U.S. Supreme Co...</td>\n",
       "      <td>Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tennis Interviews</td>\n",
       "      <td>Tennis</td>\n",
       "      <td>https://www.dropbox.com/s/q7bfirllnu32mao/tenn...</td>\n",
       "      <td>https://convokit.cornell.edu/documentation/ten...</td>\n",
       "      <td>Transcripts for tennis singles post-match pres...</td>\n",
       "      <td>Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Persuasion for Good Corpus</td>\n",
       "      <td>PfG</td>\n",
       "      <td>https://www.dropbox.com/scl/fi/ei7uxv9husg9noj...</td>\n",
       "      <td>https://convokit.cornell.edu/documentation/per...</td>\n",
       "      <td>A collection of online conversations generated...</td>\n",
       "      <td>Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Intelligence Squared Debates Corpus</td>\n",
       "      <td>IQ2</td>\n",
       "      <td>https://www.dropbox.com/scl/fi/srg1j0m4rhgoqhl...</td>\n",
       "      <td>https://convokit.cornell.edu/documentation/iq2...</td>\n",
       "      <td>This dataset contains transcripts of debates h...</td>\n",
       "      <td>Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Group Affect and Performance Corpus</td>\n",
       "      <td>GAP</td>\n",
       "      <td>https://www.dropbox.com/scl/fi/j1zh1pey7m8kcyr...</td>\n",
       "      <td>https://convokit.cornell.edu/documentation/gap...</td>\n",
       "      <td>Group members completed a Winter Survival Task...</td>\n",
       "      <td>Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Chair</td>\n",
       "      <td>Chair</td>\n",
       "      <td>https://www.dropbox.com/scl/fi/9cpj3t1n1ktxghu...</td>\n",
       "      <td>https://scrapsfromtheloft.com/?s=THE+CHAIR</td>\n",
       "      <td>Scraped transcripts from The Chair, Season 1.</td>\n",
       "      <td>Television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Friends Corpus</td>\n",
       "      <td>Friends</td>\n",
       "      <td>https://www.dropbox.com/s/nfaa6ap0ws1rqjy/frie...</td>\n",
       "      <td>https://convokit.cornell.edu/documentation/fri...</td>\n",
       "      <td>A collection of all the conversations that occ...</td>\n",
       "      <td>Television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gutenberg Dialogue Dataset</td>\n",
       "      <td>Gutenberg</td>\n",
       "      <td>https://www.dropbox.com/s/84rid3cboynutmr/gute...</td>\n",
       "      <td>https://github.com/ricsinaruto/gutenberg-dialog</td>\n",
       "      <td>Dialogues extracted from the Project Gutenberg...</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Reddit Corpus</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>https://www.dropbox.com/s/k7cun7f6x2guwva/redd...</td>\n",
       "      <td>https://convokit.cornell.edu/documentation/sub...</td>\n",
       "      <td>A collection of Corpuses of Reddit data built ...</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Dataset   Short name   \n",
       "0        Internet Movie Script Database        IMSDb  \\\n",
       "1               Movie Dialogues Dataset       Movies   \n",
       "2         Switchboard Dialog Act Corpus  Switchboard   \n",
       "3                  Supreme Court Corpus       SCOTUS   \n",
       "4                     Tennis Interviews       Tennis   \n",
       "5            Persuasion for Good Corpus          PfG   \n",
       "6   Intelligence Squared Debates Corpus          IQ2   \n",
       "7   Group Affect and Performance Corpus          GAP   \n",
       "8                             The Chair        Chair   \n",
       "9                        Friends Corpus      Friends   \n",
       "10           Gutenberg Dialogue Dataset    Gutenberg   \n",
       "11                        Reddit Corpus       Reddit   \n",
       "\n",
       "                                             Data URL   \n",
       "0   https://www.dropbox.com/scl/fi/ct39vqqq9sjqyyh...  \\\n",
       "1   https://www.dropbox.com/s/881yuhil48v6q1n/movi...   \n",
       "2   https://www.dropbox.com/s/qvx4211u41l2ex4/swit...   \n",
       "3   https://www.dropbox.com/s/icxk3ubo2u2brzq/supr...   \n",
       "4   https://www.dropbox.com/s/q7bfirllnu32mao/tenn...   \n",
       "5   https://www.dropbox.com/scl/fi/ei7uxv9husg9noj...   \n",
       "6   https://www.dropbox.com/scl/fi/srg1j0m4rhgoqhl...   \n",
       "7   https://www.dropbox.com/scl/fi/j1zh1pey7m8kcyr...   \n",
       "8   https://www.dropbox.com/scl/fi/9cpj3t1n1ktxghu...   \n",
       "9   https://www.dropbox.com/s/nfaa6ap0ws1rqjy/frie...   \n",
       "10  https://www.dropbox.com/s/84rid3cboynutmr/gute...   \n",
       "11  https://www.dropbox.com/s/k7cun7f6x2guwva/redd...   \n",
       "\n",
       "                                           Source URL   \n",
       "0                                   https://imsdb.com  \\\n",
       "1   https://convokit.cornell.edu/documentation/mov...   \n",
       "2   https://convokit.cornell.edu/documentation/swi...   \n",
       "3   https://convokit.cornell.edu/documentation/sup...   \n",
       "4   https://convokit.cornell.edu/documentation/ten...   \n",
       "5   https://convokit.cornell.edu/documentation/per...   \n",
       "6   https://convokit.cornell.edu/documentation/iq2...   \n",
       "7   https://convokit.cornell.edu/documentation/gap...   \n",
       "8          https://scrapsfromtheloft.com/?s=THE+CHAIR   \n",
       "9   https://convokit.cornell.edu/documentation/fri...   \n",
       "10    https://github.com/ricsinaruto/gutenberg-dialog   \n",
       "11  https://convokit.cornell.edu/documentation/sub...   \n",
       "\n",
       "                                          Description    Category  \n",
       "0   A collection of scripts from roughly 1000 popu...        Film  \n",
       "1   A large collection of fictional conversations ...        Film  \n",
       "2   A collection of five-minute telephone conversa...      Speech  \n",
       "3   A collection of cases from the U.S. Supreme Co...      Speech  \n",
       "4   Transcripts for tennis singles post-match pres...      Speech  \n",
       "5   A collection of online conversations generated...      Speech  \n",
       "6   This dataset contains transcripts of debates h...      Speech  \n",
       "7   Group members completed a Winter Survival Task...      Speech  \n",
       "8       Scraped transcripts from The Chair, Season 1.  Television  \n",
       "9   A collection of all the conversations that occ...  Television  \n",
       "10  Dialogues extracted from the Project Gutenberg...        Text  \n",
       "11  A collection of Corpuses of Reddit data built ...        Text  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = Path.cwd().parent.joinpath('data', 'metaanalysis-datasets.xlsx')\n",
    "data = pd.read_excel(data_list)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect past and future events\n",
    "\n",
    "For each dataset in the `data` DataFrame, we'll:\n",
    "  - Download and extract the dataset if it doesn't already exist locally\n",
    "  - Check to see whether the metaanalysis has already been run on that folder.  If not, we'll run the `process_folder` function on the dataset's directory and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.dropbox.com/scl/fi/ct39vqqq9sjqyyhie5tav/imsdb.zip?rlkey=g3hfbe8wl40aczt21lzamm717&dl=1'\n",
      " 'https://www.dropbox.com/s/881yuhil48v6q1n/movie_dialogues.zip?dl=1'\n",
      " 'https://www.dropbox.com/s/qvx4211u41l2ex4/switchboard.zip?dl=1'\n",
      " 'https://www.dropbox.com/s/icxk3ubo2u2brzq/supreme_court_oral_arguments.zip?dl=1'\n",
      " 'https://www.dropbox.com/s/q7bfirllnu32mao/tennis_interviews.zip?dl=1'\n",
      " 'https://www.dropbox.com/scl/fi/ei7uxv9husg9nojzknq4y/persuasion_for_good.zip?rlkey=4scpdku5xaeoca845o5vlrnuz&dl=1'\n",
      " 'https://www.dropbox.com/scl/fi/srg1j0m4rhgoqhlblre71/intelligence_squared.zip?rlkey=nm275vghhfg07pv24jgo0va9x&dl=1'\n",
      " 'https://www.dropbox.com/scl/fi/j1zh1pey7m8kcyryfzsw7/group_affect_and_performance.zip?rlkey=xynn96irg4lpj1bgdu3ncinca&dl=1'\n",
      " 'https://www.dropbox.com/scl/fi/9cpj3t1n1ktxghuuislr7/the_chair.zip?rlkey=br9c8n1tqnhgj69cypp0t42uq&dl=1'\n",
      " 'https://www.dropbox.com/s/nfaa6ap0ws1rqjy/friends_dialogues.zip?dl=1'\n",
      " 'https://www.dropbox.com/s/84rid3cboynutmr/gutenberg_dialogue.zip?dl=1'\n",
      " 'https://www.dropbox.com/s/k7cun7f6x2guwva/reddit.zip?dl=1']\n"
     ]
    }
   ],
   "source": [
    "print(data['Data URL'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.dropbox.com/scl/fi/ct39vqqq9sjqyyhie5tav/imsdb.zip?rlkey=g3hfbe8wl40aczt21lzamm717&dl=1'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data['Data URL'].values[0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'imsdb'"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in x.split('/') if '.zip' in s][0].split('?')[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_name(url):\n",
    "    return [s for s in url.split('/') if '.zip' in s][0].split('?')[0][:-4]\n",
    "\n",
    "def download_dataset(url, outdir):\n",
    "    # Download dataset\n",
    "    filename = get_folder_name(url) + '.zip'\n",
    "    x = requests.get(url)\n",
    "\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(x.content)\n",
    "    \n",
    "    # Unzip dataset\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall(outdir)\n",
    "\n",
    "    # Delete zip file\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: Internet Movie Script Database\n",
      "Processing dataset: Movie Dialogues Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 304713/304713 [20:30<00:00, 247.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: Switchboard Dialog Act Corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122646/122646 [08:57<00:00, 228.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: Supreme Court Corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 287413/1700789 [36:11<2:00:56, 194.78it/s]"
     ]
    }
   ],
   "source": [
    "datadir = Path.cwd().parent.joinpath('data')\n",
    "results = {}\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    print('Processing dataset: ' + row['Dataset'])\n",
    "    results_fname = datadir.joinpath(row['Short name'].lower() + '_results.pkl')\n",
    "    if not results_fname.exists():\n",
    "        # check whether the dataset exists locally and has at least 5 .txt files\n",
    "        next_datadir = datadir.joinpath(get_folder_name(row['Data URL']))\n",
    "        if not (next_datadir.exists() and len(lsdir(str(next_datadir.joinpath('*.txt')))) >= 5):\n",
    "            # download the dataset\n",
    "            download_dataset(row['Data URL'], datadir)\n",
    "        \n",
    "        # process the dataset\n",
    "        df_results, sentence_dfs = process_folder(next_datadir, past_keywords, future_keywords)\n",
    "        with open(results_fname, 'wb') as f:\n",
    "            pickle.dump([df_results, sentence_dfs], f)\n",
    "    \n",
    "    with open(results_fname, 'rb') as f:\n",
    "        results[row['Short name']] = pickle.load(f)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tense</th>\n",
       "      <th>count</th>\n",
       "      <th>Episode</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Past</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Future</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>0.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Past</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Future</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Past</td>\n",
       "      <td>177</td>\n",
       "      <td>3</td>\n",
       "      <td>0.608247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Future</td>\n",
       "      <td>114</td>\n",
       "      <td>3</td>\n",
       "      <td>0.391753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Past</td>\n",
       "      <td>148</td>\n",
       "      <td>4</td>\n",
       "      <td>0.594378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Future</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "      <td>0.405622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Past</td>\n",
       "      <td>164</td>\n",
       "      <td>5</td>\n",
       "      <td>0.616541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Future</td>\n",
       "      <td>102</td>\n",
       "      <td>5</td>\n",
       "      <td>0.383459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Past</td>\n",
       "      <td>160</td>\n",
       "      <td>6</td>\n",
       "      <td>0.536913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Future</td>\n",
       "      <td>138</td>\n",
       "      <td>6</td>\n",
       "      <td>0.463087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tense  count  Episode  proportion\n",
       "0     Past    152        1    0.575758\n",
       "1   Future    112        1    0.424242\n",
       "2     Past    108        2    0.529412\n",
       "3   Future     96        2    0.470588\n",
       "4     Past    177        3    0.608247\n",
       "5   Future    114        3    0.391753\n",
       "6     Past    148        4    0.594378\n",
       "7   Future    101        4    0.405622\n",
       "8     Past    164        5    0.616541\n",
       "9   Future    102        5    0.383459\n",
       "10    Past    160        6    0.536913\n",
       "11  Future    138        6    0.463087"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = chair_results.reset_index().rename(columns={\"index\": \"filename\"}).melt(id_vars=[\"filename\"], var_name=\"tense\", value_name=\"count\")\n",
    "auto['Episode'] = auto['filename'].apply(lambda filename: int(filename.split('_')[2][3]))\n",
    "auto['proportion'] = auto['count'] / auto.groupby('Episode')['count'].transform('sum')\n",
    "auto.sort_values(by=['Episode'], inplace=True)\n",
    "auto.drop(columns=['filename'], inplace=True)\n",
    "auto.reset_index(drop=True, inplace=True)\n",
    "auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare manually vs. automatically tagged references from *The Chair*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Episode</th>\n",
       "      <th>tense</th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Past</td>\n",
       "      <td>60</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Future</td>\n",
       "      <td>18</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Past</td>\n",
       "      <td>30</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Future</td>\n",
       "      <td>14</td>\n",
       "      <td>0.318182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Past</td>\n",
       "      <td>43</td>\n",
       "      <td>0.565789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Future</td>\n",
       "      <td>33</td>\n",
       "      <td>0.434211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>Past</td>\n",
       "      <td>31</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>Future</td>\n",
       "      <td>21</td>\n",
       "      <td>0.403846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Past</td>\n",
       "      <td>36</td>\n",
       "      <td>0.765957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Future</td>\n",
       "      <td>11</td>\n",
       "      <td>0.234043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>Past</td>\n",
       "      <td>27</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>Future</td>\n",
       "      <td>12</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Episode   tense  count  proportion\n",
       "0         1    Past     60    0.769231\n",
       "1         1  Future     18    0.230769\n",
       "2         2    Past     30    0.681818\n",
       "3         2  Future     14    0.318182\n",
       "4         3    Past     43    0.565789\n",
       "5         3  Future     33    0.434211\n",
       "6         4    Past     31    0.596154\n",
       "7         4  Future     21    0.403846\n",
       "8         5    Past     36    0.765957\n",
       "9         5  Future     11    0.234043\n",
       "10        6    Past     27    0.692308\n",
       "11        6  Future     12    0.307692"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill in proportions for manual reference counts\n",
    "ref_fname = str(Path.cwd().parent.joinpath('data', 'the_chair', 'the_chair_manual_reference_counts.csv'))\n",
    "manual = pd.read_csv(ref_fname)\n",
    "manual['Total'] = manual['Past'] + manual['Future']\n",
    "\n",
    "# # compute proportions\n",
    "# manual['p(Past)'] = manual['Past'] / manual['Total']\n",
    "# manual['p(Future)'] = manual['Future'] / manual['Total']\n",
    "\n",
    "manual.reset_index(inplace=True)\n",
    "manual['Episode'] = manual['index'] + 1\n",
    "manual.drop(['index', 'Total'], axis=1, inplace=True)\n",
    "\n",
    "manual = manual.melt(var_name='tense', value_name='count', id_vars=['Episode'])\n",
    "manual.sort_values(['Episode'], inplace=True)\n",
    "manual.reset_index(inplace=True, drop=True)\n",
    "manual['proportion'] = manual['count'] / manual.groupby('Episode')['count'].transform('sum')\n",
    "manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(figsize=(12, 4), ncols=2)\n",
    "\n",
    "# show counts\n",
    "sns.barplot(data=manual, x='tense', y='count', hue='Episode', palette='viridis', ax=axes[0])\n",
    "sns.barplot(data=auto, x='tense', y='count', hue='Episode', palette='viridis', alpha=0.5, ax=axes[0])\n",
    "sns.barplot(data=auto, x='tense', y='count', hue='Episode', fill=False, edgecolor='k', linewidth=1.5, ax=axes[0])\n",
    "axes[0].get_legend().remove()\n",
    "\n",
    "axes[0].set_xlabel('Tense', fontsize=14)\n",
    "axes[0].set_ylabel('Number of events', fontsize=14)\n",
    "sns.despine(top=True, right=True)\n",
    "\n",
    "# show proportions\n",
    "sns.barplot(data=manual, x='tense', y='proportion', hue='Episode', palette='viridis', ax=axes[1])\n",
    "sns.barplot(data=auto, x='tense', y='proportion', hue='Episode', palette='viridis', alpha=0.5, ax=axes[1])\n",
    "sns.barplot(data=auto, x='tense', y='proportion', hue='Episode', fill=False, edgecolor='k', linewidth=1.5, ax=axes[1])\n",
    "handles, labels = axes[1].get_legend_handles_labels()\n",
    "axes[1].legend(loc='upper right', title='Episode', handles=handles[:6], labels=labels[:6], frameon=False, ncol=2)\n",
    "\n",
    "axes[1].set_xlabel('Tense', fontsize=14)\n",
    "axes[1].set_ylabel('Proportion of events', fontsize=14)\n",
    "sns.despine(top=True, right=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig('the_chair_events.pdf', bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Internet Movie Script Database (IMSDb)](https://imsdb.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsdb_dir = str(Path.cwd().parent.joinpath('data').joinpath('imsdb'))\n",
    "if not os.path.exists(imsdb_dir):\n",
    "  os.makedirs(imsdb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imsdb():\n",
    "    ALL_URL = \"https://imsdb.com/all-scripts.html\"\n",
    "    BASE_URL = \"https://imsdb.com\"\n",
    "    SOURCE = \"imsdb\"\n",
    "\n",
    "    def get_script_from_url(script_url):\n",
    "        text = \"\"\n",
    "\n",
    "        try:\n",
    "            if script_url.endswith('.pdf'):\n",
    "                text = get_pdf_text(script_url, os.path.join(SOURCE, file_name))\n",
    "                return text\n",
    "\n",
    "            if script_url.endswith('.html'):\n",
    "                script_soup = get_soup(\n",
    "                    script_url)\n",
    "                if script_soup == None:\n",
    "                    return text\n",
    "                if len(script_soup.find_all('td', class_=\"scrtext\")) < 1:\n",
    "                    return \"\"\n",
    "                script_text = script_soup.find_all(\n",
    "                    'td', class_=\"scrtext\")[0].pre\n",
    "\n",
    "                if script_text:\n",
    "                    script_text = script_soup.find_all(\n",
    "                        'td', class_=\"scrtext\")[0].pre.pre\n",
    "                    if script_text:\n",
    "                        text = script_text.get_text()\n",
    "\n",
    "                    else:\n",
    "                        script_text = script_soup.find_all(\n",
    "                            'td', class_=\"scrtext\")[0].pre\n",
    "                        text = script_text.get_text()\n",
    "        except Exception as err:\n",
    "            # print(script_url)\n",
    "            # print(err)\n",
    "            text = \"\"\n",
    "\n",
    "        return text\n",
    "\n",
    "    def get_script_url(movie):\n",
    "        script_page_url = movie.contents[0].get('href')\n",
    "        name = movie.contents[0].text\n",
    "        movie_name = script_page_url.split(\"/\")[-1].strip('Script.html')\n",
    "\n",
    "        script_page_soup = get_soup(BASE_URL + urllib.parse.quote(script_page_url))\n",
    "        if script_page_soup == None:\n",
    "            return \"\", name\n",
    "        paras = script_page_soup.find_all('p', align=\"center\")\n",
    "        if len(paras) < 1:\n",
    "            return \"\", \"\"\n",
    "        script_url = paras[0].contents[0].get('href')\n",
    "\n",
    "        return script_url, name\n",
    "\n",
    "    soup = get_soup(ALL_URL)\n",
    "    movielist = soup.find_all('p')\n",
    "\n",
    "    for movie in tqdm(movielist, desc=SOURCE):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            script_url, name = get_script_url(movie)\n",
    "    \n",
    "        if script_url == \"\":\n",
    "            continue\n",
    "        \n",
    "        script_url = BASE_URL + urllib.parse.quote(script_url)\n",
    "        file_name = format_filename(name)\n",
    "\n",
    "        if os.path.exists(os.path.join(imsdb_dir, file_name + '.txt')):\n",
    "            continue\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            text = get_script_from_url(script_url)\n",
    "\n",
    "        if text == \"\" or name == \"\":\n",
    "            continue\n",
    "        \n",
    "        with open(os.path.join(imsdb_dir, file_name + '.txt'), 'w', errors=\"ignore\") as out:\n",
    "            out.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1091 IMSDB scripts.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(imsdb_dir):\n",
    "    fnames = [f for f in os.listdir(imsdb_dir) if f.endswith('.txt')]\n",
    "else:\n",
    "    fnames = []\n",
    "\n",
    "if len(fnames) < 1000:\n",
    "    get_imsdb()\n",
    "    fnames = [f for f in os.listdir(imsdb_dir) if f.endswith('.txt')]\n",
    "\n",
    "print(f'Found {len(fnames)} IMSDB scripts.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a randomly chosen excerpt from a randomly chosen transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Excerpt from Les-Miserables.txt:**\n",
       "\n",
       "VALJEAN (cont'd)\n",
       "\n",
       "And delight.\n",
       "\n",
       "How was I to know\n",
       "\n",
       "That so much love\n",
       "\n",
       "Was held inside me?\n",
       "\n",
       "Something fresh and young\n",
       "\n",
       "Something still unsung\n",
       "\n",
       "Fills the night.\n",
       "\n",
       "How was I to know at last\n",
       "\n",
       "That happiness can come so fast?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = np.random.choice(fnames)\n",
    "\n",
    "with open(os.path.join(imsdb_dir, sample), 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [x.strip() for x in lines if len(x.strip()) > 0]\n",
    "\n",
    "    # choose a 10 line snippet at random\n",
    "    start = np.random.randint(0, len(lines) - 10)\n",
    "    snippet = lines[start:start+10]\n",
    "\n",
    "Markdown(f'**Excerpt from {sample}:**\\n\\n' + '\\n\\n'.join(snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsdb_results_fname = str(Path.cwd().parent.joinpath('data', 'imsdb_results.pkl'))\n",
    "\n",
    "if os.path.exists(imsdb_results_fname):\n",
    "    with open(imsdb_results_fname, 'rb') as f:\n",
    "        imsdb_results, imsdb_sentence_dfs = pickle.load(f)\n",
    "else:\n",
    "    imsdb_results, imsdb_sentence_dfs = process_folder(imsdb_dir, load_keywords(past_keywords_fname), load_keywords(future_keywords_fname))\n",
    "    with open(imsdb_results_fname, 'wb') as f:\n",
    "        pickle.dump((imsdb_results, imsdb_sentence_dfs), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(x):\n",
    "    x = x.reset_index().rename(columns={\"index\": \"filename\"})\n",
    "    x = x.melt(var_name='tense', value_name='count', id_vars=['filename'])\n",
    "    x.reset_index(inplace=True, drop=True)\n",
    "    x['proportion'] = x['count'] / x.groupby('filename')['count'].transform('sum')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>tense</th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Midnight-Express.txt</td>\n",
       "      <td>Past</td>\n",
       "      <td>771</td>\n",
       "      <td>0.699003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Big-Eyes.txt</td>\n",
       "      <td>Past</td>\n",
       "      <td>972</td>\n",
       "      <td>0.727001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Warrior.txt</td>\n",
       "      <td>Past</td>\n",
       "      <td>780</td>\n",
       "      <td>0.672994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hellraiser-Hellseeker.txt</td>\n",
       "      <td>Past</td>\n",
       "      <td>790</td>\n",
       "      <td>0.685169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hannah-and-Her-Sisters.txt</td>\n",
       "      <td>Past</td>\n",
       "      <td>1278</td>\n",
       "      <td>0.641888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>Wild-Wild-West.txt</td>\n",
       "      <td>Future</td>\n",
       "      <td>474</td>\n",
       "      <td>0.364896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>Sessions-The.txt</td>\n",
       "      <td>Future</td>\n",
       "      <td>401</td>\n",
       "      <td>0.377945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>Misery.txt</td>\n",
       "      <td>Future</td>\n",
       "      <td>498</td>\n",
       "      <td>0.410214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>Silver-Linings-Playbook.txt</td>\n",
       "      <td>Future</td>\n",
       "      <td>517</td>\n",
       "      <td>0.374638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>Four-Rooms.txt</td>\n",
       "      <td>Future</td>\n",
       "      <td>495</td>\n",
       "      <td>0.388845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2182 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename   tense  count  proportion\n",
       "0            Midnight-Express.txt    Past    771    0.699003\n",
       "1                    Big-Eyes.txt    Past    972    0.727001\n",
       "2                     Warrior.txt    Past    780    0.672994\n",
       "3       Hellraiser-Hellseeker.txt    Past    790    0.685169\n",
       "4      Hannah-and-Her-Sisters.txt    Past   1278    0.641888\n",
       "...                           ...     ...    ...         ...\n",
       "2177           Wild-Wild-West.txt  Future    474    0.364896\n",
       "2178             Sessions-The.txt  Future    401    0.377945\n",
       "2179                   Misery.txt  Future    498    0.410214\n",
       "2180  Silver-Linings-Playbook.txt  Future    517    0.374638\n",
       "2181               Four-Rooms.txt  Future    495    0.388845\n",
       "\n",
       "[2182 rows x 4 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_df(imsdb_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other datasets\n",
    "- Internet Movie Scripts Database: https://imsdb.com/\n",
    "- Gutenberg Dialogue Dataset: https://github.com/ricsinaruto/gutenberg-dialog\n",
    "- Cornell Movie-Dialogs Corpus: https://convokit.cornell.edu/documentation/movie.html\n",
    "- Friends Corpus: https://convokit.cornell.edu/documentation/friends.html\n",
    "- Reddit Corpus: https://convokit.cornell.edu/documentation/subreddit.html\n",
    "- Switchboard Dialog Act Corpus: https://convokit.cornell.edu/documentation/switchboard.html\n",
    "- Supreme Court Corpus: https://convokit.cornell.edu/documentation/supreme.html\n",
    "- Tennis Interviews: https://convokit.cornell.edu/documentation/tennis.html\n",
    "- Persuasion for Good Corpus: https://convokit.cornell.edu/documentation/persuasionforgood.html\n",
    "- Intelligence Squared Debates Corpus: https://convokit.cornell.edu/documentation/iq2.html\n",
    "- Group Affect and Performance (GAP) corpus: https://convokit.cornell.edu/documentation/gap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit smuggle Corpus, download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_corpus(corpus, outdir):\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    df = corpus.get_utterances_dataframe().reset_index()\n",
    "\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        fname = row['id']\n",
    "        text = row['text']\n",
    "        with open(os.path.join(outdir, fname + '.txt'), 'w') as f:\n",
    "            f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = {'tennis-corpus': 'tennis_interviews',\n",
    "           'persuasionforgood-corpus': 'persuasion_for_good',\n",
    "           'iq2-corpus': 'intelligence_squared',\n",
    "           'gap-corpus': 'group_affect_and_perforamnce'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tennis-corpus to /Users/jmanning/.convokit/downloads/tennis-corpus\n",
      "Downloading tennis-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/tennis-corpus/tennis-corpus.zip (71.2MB)... Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163948/163948 [00:22<00:00, 7250.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading persuasionforgood-corpus to /Users/jmanning/.convokit/downloads/persuasionforgood-corpus\n",
      "Downloading persuasionforgood-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/persuasionforgood-corpus/persuasionforgood.zip (2.7MB)... Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20932/20932 [00:02<00:00, 8939.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading iq2-corpus to /Users/jmanning/.convokit/downloads/iq2-corpus\n",
      "Downloading iq2-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/iq2-corpus/iq2_corpus.zip (8.7MB)... Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26562/26562 [00:03<00:00, 8511.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading gap-corpus to /Users/jmanning/.convokit/downloads/gap-corpus\n",
      "Downloading gap-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/gap-corpus/gap-corpus.zip (264.4KB)... Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8009/8009 [00:00<00:00, 8155.90it/s]\n"
     ]
    }
   ],
   "source": [
    "for key, val in corpora.items():\n",
    "    corpus = Corpus(filename=download(key))\n",
    "    df = corpus.get_utterances_dataframe().reset_index()\n",
    "\n",
    "    outdir = str(Path.cwd().parent.joinpath('data', val))\n",
    "    save_corpus(corpus, outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading supreme-corpus to /Users/jmanning/.convokit/downloads/supreme-corpus\n",
      "Downloading supreme-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/supreme-corpus/supreme-corpus.zip (1255.8MB)... Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1700789/1700789 [08:07<00:00, 3492.26it/s]\n"
     ]
    }
   ],
   "source": [
    "corpora = {'supreme-corpus': 'supreme_court_oral_arguments'} # download forgotten SCOTUS corpus\n",
    "\n",
    "for key, val in corpora.items():\n",
    "    corpus = Corpus(filename=download(key))\n",
    "    df = corpus.get_utterances_dataframe().reset_index()\n",
    "\n",
    "    outdir = str(Path.cwd().parent.joinpath('data', val))\n",
    "    save_corpus(corpus, outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prediction-retrodiction",
   "language": "python",
   "name": "prediction-retrodiction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
