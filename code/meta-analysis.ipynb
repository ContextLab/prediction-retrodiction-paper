{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import davos\n",
    "except:\n",
    "    %pip install davos\n",
    "davos.config.suppress_stdout = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 smuggle BeautifulSoup     # pip: beautifulsoup4==4.12.2\n",
    "smuggle requests                   # pip: requests==2.28.2\n",
    "from tqdm smuggle tqdm             # pip: tqdm==4.65.0\n",
    "smuggle textract                   # pip: textract==1.6.4\n",
    "smuggle Levenshtein                # pip: levenshtein\n",
    "smuggle fuzzywuzzy                 # pip: fuzzywuzzy==0.18.0\n",
    "smuggle unidecode                  # pip: Unidecode==1.3.6\n",
    "smuggle pandas as pd               # pip: pandas==2.0.1\n",
    "smuggle numpy as np                # pip: numpy==1.25.2\n",
    "smuggle seaborn as sns             # pip: seaborn==0.12.2\n",
    "from matplotlib smuggle pyplot as plt  # pip: matplotlib==3.7.1\n",
    "from IPython.display import Markdown\n",
    "smuggle openai                     # pip: openai==0.27.9\n",
    "\n",
    "smuggle re\n",
    "smuggle os\n",
    "smuggle urllib\n",
    "smuggle json\n",
    "smuggle string\n",
    "smuggle warnings\n",
    "smuggle pickle\n",
    "from glob smuggle glob as lsdir\n",
    "\n",
    "from pathlib smuggle Path\n",
    "\n",
    "from helpers smuggle format_filename, get_soup, get_pdf_text, get_doc_text, get_dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_file = Path.cwd().parent.joinpath('data', 'prompt.txt')\n",
    "api_key_file = Path.cwd().parent.joinpath('data', 'api_key.txt')\n",
    "model = \"gpt-3.5-turbo\"\n",
    "chunk_size = 10\n",
    "\n",
    "def generate_gpt_responses_by_chunk(data_folder, prompt_file, api_key_file, model=\"gpt-3.5-turbo\",\n",
    "                                    chunk_size=20, max_files=None):\n",
    "    # Read API key\n",
    "    with open(api_key_file, 'r') as f:\n",
    "        openai.api_key = f.read().strip()\n",
    "        \n",
    "    # Read prompt template\n",
    "    with open(prompt_file, 'r') as f:\n",
    "        prompt_template = f.read()\n",
    "    \n",
    "    # Initialize variables\n",
    "    all_responses = pd.DataFrame()\n",
    "    all_errors = []\n",
    "\n",
    "    # Calculate total number of chunks for tqdm\n",
    "    total_chunks = 0\n",
    "    for file in os.listdir(data_folder)[:max_files]:\n",
    "        if file.endswith('.txt'):\n",
    "            with open(os.path.join(data_folder, file), 'r') as f:\n",
    "                text = f.read()\n",
    "            \n",
    "            sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "            sentences = [' '.join(s.strip().split()) for s in sentences if len(s.strip()) > 0]\n",
    "            total_chunks += -(-len(sentences) // chunk_size)\n",
    "\n",
    "    # Initialize tqdm\n",
    "    pbar = tqdm(total=total_chunks)\n",
    "    \n",
    "    # Start generating responses\n",
    "    for file in os.listdir(data_folder)[:max_files]:\n",
    "        if not file.endswith('.txt'):\n",
    "            continue\n",
    "\n",
    "        pkl_filename = f\"{file[:-4]}_chunk{chunk_size}.pkl\"\n",
    "        pkl_filepath = os.path.join(data_folder, pkl_filename)\n",
    "\n",
    "        if os.path.exists(pkl_filepath):\n",
    "            # Load existing data\n",
    "            with open(pkl_filepath, 'rb') as f:\n",
    "                responses_df, file_errors = pickle.load(f)\n",
    "        else:\n",
    "            # Read and chunk file\n",
    "            with open(os.path.join(data_folder, file), 'r') as f:\n",
    "                text = f.read()\n",
    "            \n",
    "            sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "            sentences = [' '.join(s.strip().split()) for s in sentences if len(s.strip()) > 0]\n",
    "            \n",
    "            chunks = [sentences[i:i + chunk_size] for i in range(0, len(sentences), chunk_size)]\n",
    "            responses_df = pd.DataFrame(columns=['file', 'chunk_idx', 'response'])\n",
    "            file_errors = []\n",
    "            \n",
    "            # Generate GPT responses for each chunk\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                prompt = prompt_template.replace(\"{text}\", ' '.join(chunk))\n",
    "\n",
    "                response = openai.ChatCompletion.create(model=model, messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant and an expert linguist. You are extremely good at following instructions.\"},\n",
    "                                                                               {\"role\": \"user\", \"content\": prompt}])['choices'][0]['message']['content']\n",
    "                    \n",
    "                responses_df = responses_df._append(pd.DataFrame({'file': [file], 'chunk_idx': [i], 'response': [response]}), ignore_index=True)\n",
    "                pbar.update(1)\n",
    "\n",
    "            # Save chunk responses to a pickle file\n",
    "            with open(pkl_filepath, 'wb') as f:\n",
    "                pickle.dump((responses_df, file_errors), f)\n",
    "        \n",
    "        # Append responses and errors\n",
    "        all_responses = all_responses._append(responses_df, ignore_index=True)\n",
    "        all_errors.extend([(file, *error_tuple) for error_tuple in file_errors])\n",
    "        \n",
    "    pbar.close()\n",
    "    return all_responses, all_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_summarize_gpt_responses(all_responses):\n",
    "    results_df = pd.DataFrame(columns=[\"filename\", \"past_count\", \"future_count\"])\n",
    "\n",
    "    for responses_df in all_responses:\n",
    "        filename = responses_df.iloc[0]['filename']\n",
    "        total_past = 0\n",
    "        total_future = 0\n",
    "        for index, row in responses_df.iterrows():\n",
    "            output = row['response']\n",
    "            try:\n",
    "                parts = output.split('F')\n",
    "                past_count = int(parts[0][1:])\n",
    "                future_count = int(parts[1])\n",
    "                total_past += past_count\n",
    "                total_future += future_count\n",
    "            except ValueError:\n",
    "                pass  # Ignore incorrectly formatted responses\n",
    "        \n",
    "        new_row = {\"filename\": filename, \"past_count\": total_past, \"future_count\": total_future}\n",
    "        results_df = results_df._append(new_row, ignore_index=True)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare manually vs. automatically tagged references from *The Chair*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Episode</th>\n",
       "      <th>tense</th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Past</td>\n",
       "      <td>60</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Future</td>\n",
       "      <td>18</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Past</td>\n",
       "      <td>30</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Future</td>\n",
       "      <td>14</td>\n",
       "      <td>0.318182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Past</td>\n",
       "      <td>43</td>\n",
       "      <td>0.565789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Future</td>\n",
       "      <td>33</td>\n",
       "      <td>0.434211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>Past</td>\n",
       "      <td>31</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>Future</td>\n",
       "      <td>21</td>\n",
       "      <td>0.403846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Past</td>\n",
       "      <td>36</td>\n",
       "      <td>0.765957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Future</td>\n",
       "      <td>11</td>\n",
       "      <td>0.234043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>Past</td>\n",
       "      <td>27</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>Future</td>\n",
       "      <td>12</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Episode   tense  count  proportion\n",
       "0         1    Past     60    0.769231\n",
       "1         1  Future     18    0.230769\n",
       "2         2    Past     30    0.681818\n",
       "3         2  Future     14    0.318182\n",
       "4         3    Past     43    0.565789\n",
       "5         3  Future     33    0.434211\n",
       "6         4    Past     31    0.596154\n",
       "7         4  Future     21    0.403846\n",
       "8         5    Past     36    0.765957\n",
       "9         5  Future     11    0.234043\n",
       "10        6    Past     27    0.692308\n",
       "11        6  Future     12    0.307692"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill in proportions for manual reference counts\n",
    "ref_fname = str(Path.cwd().parent.joinpath('data', 'the_chair', 'the_chair_manual_reference_counts.csv'))\n",
    "manual = pd.read_csv(ref_fname)\n",
    "manual['Total'] = manual['Past'] + manual['Future']\n",
    "\n",
    "# # compute proportions\n",
    "# manual['p(Past)'] = manual['Past'] / manual['Total']\n",
    "# manual['p(Future)'] = manual['Future'] / manual['Total']\n",
    "\n",
    "manual.reset_index(inplace=True)\n",
    "manual['Episode'] = manual['index'] + 1\n",
    "manual.drop(['index', 'Total'], axis=1, inplace=True)\n",
    "\n",
    "manual = manual.melt(var_name='tense', value_name='count', id_vars=['Episode'])\n",
    "manual.sort_values(['Episode'], inplace=True)\n",
    "manual.reset_index(inplace=True, drop=True)\n",
    "manual['proportion'] = manual['count'] / manual.groupby('Episode')['count'].transform('sum')\n",
    "manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "chair_dir = Path.cwd().parent.joinpath('data', 'the_chair')\n",
    "\n",
    "chair_results_fname = chair_dir.joinpath(f'the_chair_gpt_responses_c{chunk_size}.pkl')\n",
    "\n",
    "if chair_results_fname.exists():\n",
    "    with open(chair_results_fname, 'rb') as f:\n",
    "        auto, errors = pickle.load(f)\n",
    "else:\n",
    "    auto, errors = generate_gpt_responses_by_chunk(chair_dir, prompt_file=prompt_file, api_key_file=api_key_file, chunk_size=chunk_size, max_files=10, model=model)\n",
    "    with open(chair_results_fname, 'wb') as f:\n",
    "        pickle.dump((auto, errors), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_json_string(bad_json_str):\n",
    "    result = []\n",
    "    is_key = True  # Tracks if we are within a key\n",
    "    is_value = False  # Tracks if we are within a value\n",
    "    is_escaped = False  # Tracks if the current character is escaped (preceded by a backslash)\n",
    "    quote_type = None  # Tracks the type of quote (' or \") for the current key or value\n",
    "\n",
    "    for c in bad_json_str:\n",
    "        if c == '\\\\':  # Escape character\n",
    "            is_escaped = not is_escaped\n",
    "            result.append(c)\n",
    "        elif (c == '\"' or c == \"'\") and not is_escaped:  # Quote character\n",
    "            if quote_type is None:  # Starting a new quoted section\n",
    "                quote_type = c\n",
    "                result.append('\"')  # Always use double quotes in the output\n",
    "            elif quote_type == c:  # Ending the current quoted section\n",
    "                quote_type = None\n",
    "                result.append('\"')  # Always use double quotes in the output\n",
    "                is_key = not is_key  # Toggle is_key because keys and values alternate\n",
    "                is_value = not is_value  # Toggle is_value as well\n",
    "            else:\n",
    "                result.append(c)  # Leave other quotes untouched\n",
    "        elif c == ':' and quote_type is None:  # Colon (only meaningful outside of quotes)\n",
    "            is_key = False\n",
    "            is_value = True\n",
    "            result.append(c)\n",
    "        elif c == ',' and quote_type is None:  # Comma (only meaningful outside of quotes)\n",
    "            is_key = True\n",
    "            is_value = False\n",
    "            result.append(c)\n",
    "        else:  # All other characters\n",
    "            result.append(c)\n",
    "\n",
    "        # Reset the escape flag if the current character was not a backslash\n",
    "        if c != '\\\\':\n",
    "            is_escaped = False\n",
    "\n",
    "    # Join the list into a single string and attempt to parse it as JSON\n",
    "    fixed_json_str = ''.join(result)\n",
    "    try:\n",
    "        fixed_json = json.loads(fixed_json_str)\n",
    "        return fixed_json\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Failed to decode JSON:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to decode JSON: Unterminated string starting at: line 1 column 364 (char 363)\n",
      "Failed to decode JSON: Extra data: line 16 column 1 (char 1188)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Episode</th>\n",
       "      <th>tense</th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Past</td>\n",
       "      <td>80</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Future</td>\n",
       "      <td>28</td>\n",
       "      <td>0.259259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Past</td>\n",
       "      <td>79</td>\n",
       "      <td>0.711712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Future</td>\n",
       "      <td>32</td>\n",
       "      <td>0.288288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Past</td>\n",
       "      <td>113</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Future</td>\n",
       "      <td>38</td>\n",
       "      <td>0.251656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>Past</td>\n",
       "      <td>87</td>\n",
       "      <td>0.783784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>Future</td>\n",
       "      <td>24</td>\n",
       "      <td>0.216216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Past</td>\n",
       "      <td>107</td>\n",
       "      <td>0.804511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Future</td>\n",
       "      <td>26</td>\n",
       "      <td>0.195489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>Past</td>\n",
       "      <td>96</td>\n",
       "      <td>0.732824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>Future</td>\n",
       "      <td>35</td>\n",
       "      <td>0.267176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Episode   tense  count  proportion\n",
       "0         1    Past     80    0.740741\n",
       "1         1  Future     28    0.259259\n",
       "2         2    Past     79    0.711712\n",
       "3         2  Future     32    0.288288\n",
       "4         3    Past    113    0.748344\n",
       "5         3  Future     38    0.251656\n",
       "6         4    Past     87    0.783784\n",
       "7         4  Future     24    0.216216\n",
       "8         5    Past    107    0.804511\n",
       "9         5  Future     26    0.195489\n",
       "10        6    Past     96    0.732824\n",
       "11        6  Future     35    0.267176"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = []\n",
    "parsed_responses = []\n",
    "\n",
    "for i, row in auto.iterrows():\n",
    "    parsed_response = None\n",
    "\n",
    "    try:\n",
    "        html = row['response']\n",
    "        parsed = BeautifulSoup(html).get_text()\n",
    "        parsed_response = fix_json_string(parsed)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if parsed_response is None:\n",
    "        errors.append({'file': row['file'], 'chunk_idx': row['chunk_idx'], 'response': row['response'], 'iloc': i})\n",
    "        parsed_responses.append(None)\n",
    "    else:\n",
    "        parsed_responses.append(parsed_response)\n",
    "\n",
    "drop_indices = [e['iloc'] for e in errors]\n",
    "auto.drop(drop_indices, inplace=True)\n",
    "auto.reset_index(inplace=True, drop=True)\n",
    "\n",
    "auto['response'] = [p for p in parsed_responses if p is not None]\n",
    "\n",
    "past = lambda response: np.sum([int(x['P']) for x in response.values()])\n",
    "future = lambda response: np.sum([int(x['F']) for x in response.values()])\n",
    "episode = lambda filename: int(filename.split('_')[2][3])\n",
    "\n",
    "auto['Past'] = auto['response'].apply(past)\n",
    "auto['Future'] = auto['response'].apply(future)\n",
    "auto['Episode'] = auto['file'].apply(episode)\n",
    "\n",
    "auto = auto.groupby('Episode').agg({'Past': 'sum', 'Future': 'sum'}).reset_index()\n",
    "auto = auto.melt(var_name='tense', value_name='count', id_vars=['Episode'])\n",
    "auto.sort_values(['Episode'], inplace=True)\n",
    "auto.reset_index(inplace=True, drop=True)\n",
    "auto['proportion'] = auto['count'] / auto.groupby('Episode')['count'].transform('sum')\n",
    "auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(figsize=(12, 4), ncols=2, sharex=True)\n",
    "\n",
    "# show counts\n",
    "sns.barplot(data=manual, x='tense', y='count', hue='Episode', palette='viridis', ax=axes[0])\n",
    "sns.barplot(data=auto, x='tense', y='count', hue='Episode', palette='viridis', alpha=0.5, edgecolor='k', linewidth=2, ax=axes[0])\n",
    "axes[0].get_legend().remove()\n",
    "\n",
    "axes[0].set_xlabel('Tense', fontsize=14)\n",
    "axes[0].set_ylabel('Count', fontsize=14)\n",
    "sns.despine(top=True, right=True)\n",
    "\n",
    "# show proportions\n",
    "sns.barplot(data=manual, x='tense', y='proportion', hue='Episode', palette='viridis', ax=axes[1])\n",
    "sns.barplot(data=auto, x='tense', y='proportion', hue='Episode', palette='viridis', alpha=0.5, edgecolor='k', linewidth=2, ax=axes[1])\n",
    "handles, labels = axes[1].get_legend_handles_labels()\n",
    "axes[1].legend(loc='upper right', title='Episode', handles=handles[:6], labels=labels[:6], frameon=False)\n",
    "\n",
    "axes[1].set_xlabel('Tense', fontsize=14)\n",
    "axes[1].set_ylabel('Proportion', fontsize=14)\n",
    "sns.despine(top=True, right=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig('the_chair_events.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5', '6', '1', '2', '3', '4', '5', '6']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer tense from text using NLTK's taggers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single sentence tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = str(Path.cwd().parent.joinpath('data'))\n",
    "tagger = os.path.join(data_dir, 'english-bidirectional-distsim.tagger')\n",
    "jar = os.path.join(data_dir, 'stanford-postagger.jar')\n",
    "\n",
    "stanford_tagger = StanfordPOSTagger(tagger, jar, encoding='utf8')\n",
    "\n",
    "def sentence_tense(x):\n",
    "  # source: https://stackoverflow.com/questions/30016904/determining-tense-of-a-sentence-python\n",
    "  def tense_detect(tagged_sentence):        \n",
    "    verb_tags = ['MD','MDF',\n",
    "                'BE','BEG','BEN','BED','BEDZ','BEZ','BEM','BER',\n",
    "                'DO','DOD','DOZ',\n",
    "                'HV','HVG','HVN','HVD','HVZ',\n",
    "                'VB','VBG','VBN','VBD','VBZ',\n",
    "                'SH',\n",
    "                'TO',                \n",
    "                'JJ']\n",
    "    \n",
    "    verb_phrase = []\n",
    "    for item in tagged_sentence:\n",
    "        if item[1] in verb_tags:\n",
    "            verb_phrase.append(item)\n",
    "\n",
    "    grammar = r'''\n",
    "            future perfect continuous passive:     {<MDF><HV><BEN><BEG><VBN|VBD>+}\n",
    "            conditional perfect continuous passive:{<MD><HV><BEN><BEG><VBN|VBD>+}\n",
    "            future continuous passive:             {<MDF><BE><BEG><VBN|VBD>+}   \n",
    "            conditional continuous passive:        {<MD><BE><BEG><VBN|VBD>+}    \n",
    "            future perfect continuous:             {<MDF><HV><BEN><VBG|HVG|BEG>+}   \n",
    "            conditional perfect continuous:        {<MD><HV><BEN><VBG|HVG|BEG>+}\n",
    "            past perfect continuous passive:       {<HVD><BEN><BEG><VBN|VBD>+}\n",
    "            present perfect continuous passive:    {<HV|HVZ><BEN><BEG><VBN|VBD>+}\n",
    "            future perfect passive:                {<MDF><HV><BEN><VBN|VBD>+}   \n",
    "            conditional perfect passive:           {<MD><HV><BEN><VBN|VBD>+}    \n",
    "            future continuous:                     {<MDF><BE><VBG|HVG|BEG>+ }   \n",
    "            conditional continuous:                {<MD><BE><VBG|HVG|BEG>+  }   \n",
    "            future indefinite passive:             {<MDF><BE><VBN|VBD>+ }\n",
    "            conditional indefinite passive:        {<MD><BE><VBN|VBD>+  }\n",
    "            future perfect:                        {<MDF><HV><HVN|BEN|VBN|VBD>+ }   \n",
    "            conditional perfect:                   {<MD><HV><HVN|BEN|VBN|VBD>+  }   \n",
    "            past continuous passive:               {<BED|BEDZ><BEG><VBN|VBD>+}  \n",
    "            past perfect continuous:               {<HVD><BEN><HVG|BEG|VBG>+}   \n",
    "            past perfect passive:                  {<HVD><BEN><VBN|VBD>+}\n",
    "            present continuous passive:            {<BEM|BER|BEZ><BEG><VBN|VBD>+}   \n",
    "            present perfect continuous:            {<HV|HVZ><BEN><VBG|BEG|HVG>+}    \n",
    "            present perfect passive:               {<HV|HVZ><BEN><VBN|VBD>+}\n",
    "            future indefinite:                     {<MDF><BE|DO|VB|HV>+ }       \n",
    "            conditional indefinite:                {<MD><BE|DO|VB|HV>+  }   \n",
    "            past continuous:                       {<BED|BEDZ><VBG|HVG|BEG>+}           \n",
    "            past perfect:                          {<HVD><BEN|VBN|HVD|HVN>+}\n",
    "            past indefinite passive:               {<BED|BEDZ><VBN|VBD>+}   \n",
    "            present indefinite passive:            {<BEM|BER|BEZ><VBN|VBD>+}            \n",
    "            present continuous:                    {<BEM|BER|BEZ><BEG|VBG|HVG>+}            \n",
    "            present perfect:                       {<HV|HVZ><BEN|HVD|VBN|VBD>+  }       \n",
    "            past indefinite:                       {<DOD><VB|HV|DO>|<BEDZ|BED|HVD|VBN|VBD>+}        \n",
    "            infinitive:                            {<TO><BE|HV|VB>+}\n",
    "            present indefinite:                    {<DO|DOZ><DO|HV|VB>+|<DO|HV|VB|BEZ|DOZ|BER|HVZ|BEM|VBZ>+}    \n",
    "            '''\n",
    "\n",
    "    if len(verb_phrase) > 0:\n",
    "      cp = nltk.RegexpParser(grammar)\n",
    "      result = cp.parse(verb_phrase)\n",
    "    else:\n",
    "      result = []\n",
    "    \n",
    "    tenses_set = set()\n",
    "    for node in result:\n",
    "      if type(node) is nltk.tree.Tree:\n",
    "        tenses_set.add(node.label())\n",
    "    \n",
    "    return tenses_set\n",
    "    \n",
    "  text = word_tokenize(x)\n",
    "  tagged = stanford_tagger.tag(x)\n",
    "  return tense_detect(tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document-level tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_document(x):\n",
    "  counts = {}\n",
    "  for s in tokenize.sent_tokenize(x):\n",
    "    if len(s) > 0:\n",
    "      for t in sentence_tense(s):\n",
    "        counts[t] = counts.get(t, 0) + 1\n",
    "    else:\n",
    "      pass\n",
    "  return counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Internet Movie Script Database (IMSDb)](https://imsdb.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsdb_dir = str(Path.cwd().parent.joinpath('data').joinpath('imsdb'))\n",
    "if not os.path.exists(imsdb_dir):\n",
    "  os.makedirs(imsdb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imsdb():\n",
    "    ALL_URL = \"https://imsdb.com/all-scripts.html\"\n",
    "    BASE_URL = \"https://imsdb.com\"\n",
    "    SOURCE = \"imsdb\"\n",
    "\n",
    "    def get_script_from_url(script_url):\n",
    "        text = \"\"\n",
    "\n",
    "        try:\n",
    "            if script_url.endswith('.pdf'):\n",
    "                text = get_pdf_text(script_url, os.path.join(SOURCE, file_name))\n",
    "                return text\n",
    "\n",
    "            if script_url.endswith('.html'):\n",
    "                script_soup = get_soup(\n",
    "                    script_url)\n",
    "                if script_soup == None:\n",
    "                    return text\n",
    "                if len(script_soup.find_all('td', class_=\"scrtext\")) < 1:\n",
    "                    return \"\"\n",
    "                script_text = script_soup.find_all(\n",
    "                    'td', class_=\"scrtext\")[0].pre\n",
    "\n",
    "                if script_text:\n",
    "                    script_text = script_soup.find_all(\n",
    "                        'td', class_=\"scrtext\")[0].pre.pre\n",
    "                    if script_text:\n",
    "                        text = script_text.get_text()\n",
    "\n",
    "                    else:\n",
    "                        script_text = script_soup.find_all(\n",
    "                            'td', class_=\"scrtext\")[0].pre\n",
    "                        text = script_text.get_text()\n",
    "        except Exception as err:\n",
    "            # print(script_url)\n",
    "            # print(err)\n",
    "            text = \"\"\n",
    "\n",
    "        return text\n",
    "\n",
    "    def get_script_url(movie):\n",
    "        script_page_url = movie.contents[0].get('href')\n",
    "        name = movie.contents[0].text\n",
    "        movie_name = script_page_url.split(\"/\")[-1].strip('Script.html')\n",
    "\n",
    "        script_page_soup = get_soup(BASE_URL + urllib.parse.quote(script_page_url))\n",
    "        if script_page_soup == None:\n",
    "            return \"\", name\n",
    "        paras = script_page_soup.find_all('p', align=\"center\")\n",
    "        if len(paras) < 1:\n",
    "            return \"\", \"\"\n",
    "        script_url = paras[0].contents[0].get('href')\n",
    "\n",
    "        return script_url, name\n",
    "\n",
    "    soup = get_soup(ALL_URL)\n",
    "    movielist = soup.find_all('p')\n",
    "\n",
    "    for movie in tqdm(movielist, desc=SOURCE):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            script_url, name = get_script_url(movie)\n",
    "    \n",
    "        if script_url == \"\":\n",
    "            continue\n",
    "        \n",
    "        script_url = BASE_URL + urllib.parse.quote(script_url)\n",
    "        file_name = format_filename(name)\n",
    "\n",
    "        if os.path.exists(os.path.join(imsdb_dir, file_name + '.txt')):\n",
    "            continue\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            text = get_script_from_url(script_url)\n",
    "\n",
    "        if text == \"\" or name == \"\":\n",
    "            continue\n",
    "        \n",
    "        with open(os.path.join(imsdb_dir, file_name + '.txt'), 'w', errors=\"ignore\") as out:\n",
    "            out.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1127 IMSDB scripts.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(imsdb_dir):\n",
    "    fnames = [f for f in os.listdir(imsdb_dir) if f.endswith('.txt')]\n",
    "else:\n",
    "    fnames = []\n",
    "\n",
    "if len(fnames) < 1000:\n",
    "    get_imsdb()\n",
    "    fnames = [f for f in os.listdir(imsdb_dir) if f.endswith('.txt')]\n",
    "\n",
    "print(f'Found {len(fnames)} IMSDB scripts.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens in the directory: 26023895\n",
      "Estimated cost with GPT-3.5-turbo: $104.09558\n",
      "Estimated cost with GPT-4: $3122.8674\n"
     ]
    }
   ],
   "source": [
    "def count_tokens_in_directory(directory_path):\n",
    "    filenames = [os.path.join(directory_path, f) for f in os.listdir(directory_path) if f.endswith('.txt')]\n",
    "    total_tokens = 0\n",
    "    \n",
    "    for filename in filenames:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            tokens = len(text.split())  # A rough approximation\n",
    "            total_tokens += tokens\n",
    "    \n",
    "    return total_tokens\n",
    "\n",
    "# You need to set the cost per token for each model according to your specific OpenAI plan\n",
    "cost_per_token_gpt3_5 = 0.000004\n",
    "cost_per_token_gpt4 = 0.00012\n",
    "\n",
    "total_tokens = count_tokens_in_directory(imsdb_dir)\n",
    "\n",
    "total_cost_gpt3_5 = total_tokens * cost_per_token_gpt3_5\n",
    "total_cost_gpt4 = total_tokens * cost_per_token_gpt4\n",
    "\n",
    "print(f\"Total tokens in the directory: {total_tokens}\")\n",
    "print(f\"Estimated cost with GPT-3.5-turbo: ${total_cost_gpt3_5}\")\n",
    "print(f\"Estimated cost with GPT-4: ${total_cost_gpt4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smuggle stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanza.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a randomly chosen excerpt from a randomly chosen transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Excerpt from Lock-Stock-and-Two-Smoking-Barrels.txt:**\n",
       "\n",
       "Harry, that boy doesn't know his arsehole from his ear-hole, or you\n",
       "\n",
       "from a hoodwink. This bar is mine, and he has nothing to do with it.\n",
       "\n",
       "HATCHET\n",
       "\n",
       "What, and I care? Remember, you do have the luxurious advantage of\n",
       "\n",
       "being able to sustain your son's life.\n",
       "\n",
       "JD\n",
       "\n",
       "And you do have a reputation, so I'll choose my words carefully. But\n",
       "\n",
       "not to put too fine a point on it, fuck yourself, Harry!\n",
       "\n",
       "Barry pulls a kind of mock-scared face and clutches his heart.\n",
       "\n",
       "80"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = np.random.choice(fnames)\n",
    "\n",
    "with open(os.path.join(imsdb_dir, sample), 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [x.strip() for x in lines if len(x.strip()) > 0]\n",
    "\n",
    "    # choose a 10 line snippet at random\n",
    "    start = np.random.randint(0, len(lines) - 10)\n",
    "    snippet = lines[start:start+10]\n",
    "\n",
    "Markdown(f'**Excerpt from {sample}:**\\n\\n' + '\\n\\n'.join(snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatGPT's solution (after some tweaking)!\n",
    "\n",
    "def count_tenses_in_files(filepaths):\n",
    "    df = pd.DataFrame(columns=['filename', 'past_tense', 'future_tense'])\n",
    "\n",
    "    for filepath in filepaths:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "\n",
    "        sentences = sent_tokenize(text)\n",
    "\n",
    "        past_count = 0\n",
    "        future_count = 0\n",
    "\n",
    "        for sentence in sentences:\n",
    "            # Expand contractions for better matching\n",
    "            sentence = re.sub(r\"won't\", \"will not\", sentence)\n",
    "            sentence = re.sub(r\"can't\", \"cannot\", sentence)\n",
    "            sentence = re.sub(r\"i'm\", \"i am\", sentence)\n",
    "            sentence = re.sub(r\"ain't\", \"is not\", sentence)\n",
    "            sentence = re.sub(r\"(\\w+)'ll\", \"\\\\1 will\", sentence)\n",
    "            sentence = re.sub(r\"(\\w+)n't\", \"\\\\1 not\", sentence)\n",
    "            sentence = re.sub(r\"(\\w+)'ve\", \"\\\\1 have\", sentence)\n",
    "            sentence = re.sub(r\"(\\w+)'s\", \"\\\\1 is\", sentence)\n",
    "            sentence = re.sub(r\"(\\w+)'re\", \"\\\\1 are\", sentence)\n",
    "\n",
    "            # Check for future tense patterns\n",
    "            if re.search(r'\\bwill\\b|\\bshall\\b|\\bam going to\\b|\\bwill have\\b|\\bshall have\\b|\\bwill be\\b|\\bshall be\\b|\\b(is|are) going to\\b|\\b(is|are|am) about to\\b|\\b(is|are|am) planning to\\b|\\b(is|are|am) looking forward to\\b', sentence, re.IGNORECASE):\n",
    "                future_count += 1\n",
    "\n",
    "            # Check for past tense patterns\n",
    "            if re.search(r'\\bwas\\b|\\bwere\\b|\\bhad\\b|\\bdid\\b|\\bhad been\\b|\\bwas going to\\b|\\bwere going to\\b|\\bwas supposed to\\b|\\bwere supposed to\\b|\\bwould have\\b|\\bshould have\\b|\\bcould have\\b|\\bmight have\\b|\\bwas planning to\\b|\\bwere planning to\\b|\\bwas looking forward to\\b|\\bwere looking forward to\\b', sentence, re.IGNORECASE):\n",
    "                past_count += 1\n",
    "\n",
    "        df = df.append({'filename': filepath, 'past_tense': past_count, 'future_tense': future_count}, ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dict(d1, d2):\n",
    "  for k in d2:\n",
    "    if k in d1:\n",
    "      d1[k] += d2[k]\n",
    "    else:\n",
    "      d1[k] = d2[k]\n",
    "  return d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test run: validate against The Chair (Season 1, Episodes 1--6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_fname = lambda n: str(Path.cwd().parent.joinpath('data').joinpath('the_chair_s1e' + str(n) + '_transcript.txt'))\n",
    "ref_fname = str(Path.cwd().parent.joinpath('data').joinpath('the_chair_manual_reference_counts.csv'))\n",
    "\n",
    "def get_demo_tenses(fname):\n",
    "    text = open(fname, 'r').read()\n",
    "    tenses = pd.DataFrame.from_dict(tag_document(text), orient='index', columns=['count']).reset_index().rename(columns={'index': 'tense'})\n",
    "\n",
    "    mapping = {'present indefinite': 'Present',\n",
    "            'past indefinite': 'Past',\n",
    "            'conditional indefinite': 'Future',\n",
    "            'infinitive': 'Present'}\n",
    "\n",
    "    tenses['index'] = tenses['tense'].apply(lambda x: mapping[x] if x in mapping else x)\n",
    "    \n",
    "    # drop present tense\n",
    "    tenses = tenses.groupby('index').sum().reset_index().sort_values('count', ascending=False).set_index('index').loc[['Past', 'Future']]\n",
    "    tenses['proportion'] = tenses['count'] / tenses['count'].sum()\n",
    "\n",
    "    return tenses.drop('tense', axis=1).reset_index().rename(columns={'index': 'tense'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Episode</th>\n",
       "      <th>tense</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Future</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Future</td>\n",
       "      <td>0.318182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.565789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Future</td>\n",
       "      <td>0.434211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>Future</td>\n",
       "      <td>0.403846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.765957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>Future</td>\n",
       "      <td>0.234043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>Future</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Episode   tense  proportion\n",
       "0         1    Past    0.769231\n",
       "6         1  Future    0.230769\n",
       "1         2    Past    0.681818\n",
       "7         2  Future    0.318182\n",
       "2         3    Past    0.565789\n",
       "8         3  Future    0.434211\n",
       "3         4    Past    0.596154\n",
       "9         4  Future    0.403846\n",
       "4         5    Past    0.765957\n",
       "10        5  Future    0.234043\n",
       "5         6    Past    0.692308\n",
       "11        6  Future    0.307692"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill in proportions for manual reference counts\n",
    "manual = pd.read_csv(ref_fname)\n",
    "manual['Total'] = manual['Past'] + manual['Future']\n",
    "\n",
    "# convert to proportions\n",
    "manual['Past'] = manual['Past'] / manual['Total']\n",
    "manual['Future'] = manual['Future'] / manual['Total']\n",
    "\n",
    "manual.reset_index(inplace=True)\n",
    "manual['Episode'] = manual['index'] + 1\n",
    "manual.drop(['index', 'Total'], axis=1, inplace=True)\n",
    "\n",
    "manual = manual.melt(var_name='tense', value_name='proportion', id_vars=['Episode'])\n",
    "manual.sort_values(['Episode'], inplace=True)\n",
    "manual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Java command failed : ['/Users/jmanning/opt/anaconda3/envs/prediction-retrodiction/bin/java', '-mx1000m', '-cp', '/Users/jmanning/prediction-retrodiction-paper/data/stanford-postagger.jar', 'edu.stanford.nlp.tagger.maxent.MaxentTagger', '-model', '/Users/jmanning/prediction-retrodiction-paper/data/english-bidirectional-distsim.tagger', '-textFile', '/var/folders/tp/qtzc39jx5w556wl5w3dj21wr0000gn/T/tmppp4qbrsh', '-tokenize', 'false', '-outputFormatOptions', 'keepEmptySentences', '-encoding', 'utf8']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m episodes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39m1\u001b[39m, \u001b[39m7\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tenses \u001b[39m=\u001b[39m [get_demo_tenses(demo_fname(n)) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m episodes]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# add episode labels\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tenses):\n",
      "\u001b[1;32m/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb Cell 20\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m episodes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39m1\u001b[39m, \u001b[39m7\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tenses \u001b[39m=\u001b[39m [get_demo_tenses(demo_fname(n)) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m episodes]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# add episode labels\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tenses):\n",
      "\u001b[1;32m/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb Cell 20\u001b[0m in \u001b[0;36mget_demo_tenses\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_demo_tenses\u001b[39m(fname):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(fname, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mread()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     tenses \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_dict(tag_document(text), orient\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mreset_index()\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mtense\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     mapping \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mpresent indefinite\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mPresent\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mpast indefinite\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mPast\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mconditional indefinite\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mFuture\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39minfinitive\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mPresent\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     tenses[\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m tenses[\u001b[39m'\u001b[39m\u001b[39mtense\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: mapping[x] \u001b[39mif\u001b[39;00m x \u001b[39min\u001b[39;00m mapping \u001b[39melse\u001b[39;00m x)\n",
      "\u001b[1;32m/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb Cell 20\u001b[0m in \u001b[0;36mtag_document\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m tokenize\u001b[39m.\u001b[39msent_tokenize(x):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(s) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m sentence_tense(s):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m       counts[t] \u001b[39m=\u001b[39m counts\u001b[39m.\u001b[39mget(t, \u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb Cell 20\u001b[0m in \u001b[0;36msentence_tense\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m tenses_set\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m text \u001b[39m=\u001b[39m word_tokenize(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m tagged \u001b[39m=\u001b[39m stanford_tagger\u001b[39m.\u001b[39;49mtag(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tense_detect(tagged)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/nltk/tag/stanford.py:90\u001b[0m, in \u001b[0;36mStanfordTagger.tag\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtag\u001b[39m(\u001b[39mself\u001b[39m, tokens):\n\u001b[1;32m     89\u001b[0m     \u001b[39m# This function should return list of tuple rather than list of list\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtag_sents([tokens]), [])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/nltk/tag/stanford.py:112\u001b[0m, in \u001b[0;36mStanfordTagger.tag_sents\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    109\u001b[0m _input_fh\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    111\u001b[0m \u001b[39m# Run the tagger and get the output\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m stanpos_output, _stderr \u001b[39m=\u001b[39m java(\n\u001b[1;32m    113\u001b[0m     cmd, classpath\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stanford_jar, stdout\u001b[39m=\u001b[39;49mPIPE, stderr\u001b[39m=\u001b[39;49mPIPE\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    115\u001b[0m stanpos_output \u001b[39m=\u001b[39m stanpos_output\u001b[39m.\u001b[39mdecode(encoding)\n\u001b[1;32m    117\u001b[0m \u001b[39m# Delete the temporary file\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/nltk/internals.py:146\u001b[0m, in \u001b[0;36mjava\u001b[0;34m(cmd, classpath, stdin, stdout, stderr, blocking)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m p\u001b[39m.\u001b[39mreturncode \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    145\u001b[0m     \u001b[39mprint\u001b[39m(_decode_stdoutdata(stderr))\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mJava command failed : \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(cmd))\n\u001b[1;32m    148\u001b[0m \u001b[39mreturn\u001b[39;00m (stdout, stderr)\n",
      "\u001b[0;31mOSError\u001b[0m: Java command failed : ['/Users/jmanning/opt/anaconda3/envs/prediction-retrodiction/bin/java', '-mx1000m', '-cp', '/Users/jmanning/prediction-retrodiction-paper/data/stanford-postagger.jar', 'edu.stanford.nlp.tagger.maxent.MaxentTagger', '-model', '/Users/jmanning/prediction-retrodiction-paper/data/english-bidirectional-distsim.tagger', '-textFile', '/var/folders/tp/qtzc39jx5w556wl5w3dj21wr0000gn/T/tmppp4qbrsh', '-tokenize', 'false', '-outputFormatOptions', 'keepEmptySentences', '-encoding', 'utf8']"
     ]
    }
   ],
   "source": [
    "episodes = np.arange(1, 7, dtype=int)\n",
    "tenses = [get_demo_tenses(demo_fname(n)) for n in episodes]\n",
    "\n",
    "# add episode labels\n",
    "for i, t in enumerate(tenses):\n",
    "    t['episode'] = episodes[i]\n",
    "\n",
    "# combine into one dataframe\n",
    "tenses = pd.concat(tenses, ignore_index=True)\n",
    "\n",
    "sns.barplot(tenses, x='tense', y='proportion', hue='episode', palette='viridis')\n",
    "plt.xlabel('Tense', fontsize=14)\n",
    "plt.ylabel('Proportion of references', fontsize=14)\n",
    "plt.legend(title='Episode', loc='upper right')\n",
    "sns.despine(top=True, right=True)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "# add manual reference counts as dotted lines\n",
    "for i, p in enumerate(ax.patches):\n",
    "    x = [p.get_x(), p.get_x() + p.get_width()]  # X-coordinate of the center of the bar\n",
    "    y = manual.iloc[i]['proportion']\n",
    "    ax.plot(x, [y, y], linestyle='dotted', linewidth=2, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jmanning/opt/anaconda3/envs/prediction-retrodiction/bin/java\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('which java')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Java command failed : ['/Users/jmanning/opt/anaconda3/envs/prediction-retrodiction/bin/java', '-mx1000m', '-cp', '/Users/jmanning/prediction-retrodiction-paper/data/stanford-postagger.jar', 'edu.stanford.nlp.tagger.maxent.MaxentTagger', '-model', '/Users/jmanning/prediction-retrodiction-paper/data/english-bidirectional-distsim.tagger', '-textFile', '/var/folders/tp/qtzc39jx5w556wl5w3dj21wr0000gn/T/tmpnv4bm30d', '-tokenize', 'false', '-outputFormatOptions', 'keepEmptySentences', '-encoding', 'utf8']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m stanford_tagger\u001b[39m.\u001b[39;49mtag(\u001b[39m'\u001b[39;49m\u001b[39mThis is a test\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49msplit())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/nltk/tag/stanford.py:90\u001b[0m, in \u001b[0;36mStanfordTagger.tag\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtag\u001b[39m(\u001b[39mself\u001b[39m, tokens):\n\u001b[1;32m     89\u001b[0m     \u001b[39m# This function should return list of tuple rather than list of list\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtag_sents([tokens]), [])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/nltk/tag/stanford.py:112\u001b[0m, in \u001b[0;36mStanfordTagger.tag_sents\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    109\u001b[0m _input_fh\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    111\u001b[0m \u001b[39m# Run the tagger and get the output\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m stanpos_output, _stderr \u001b[39m=\u001b[39m java(\n\u001b[1;32m    113\u001b[0m     cmd, classpath\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stanford_jar, stdout\u001b[39m=\u001b[39;49mPIPE, stderr\u001b[39m=\u001b[39;49mPIPE\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    115\u001b[0m stanpos_output \u001b[39m=\u001b[39m stanpos_output\u001b[39m.\u001b[39mdecode(encoding)\n\u001b[1;32m    117\u001b[0m \u001b[39m# Delete the temporary file\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/nltk/internals.py:146\u001b[0m, in \u001b[0;36mjava\u001b[0;34m(cmd, classpath, stdin, stdout, stderr, blocking)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m p\u001b[39m.\u001b[39mreturncode \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    145\u001b[0m     \u001b[39mprint\u001b[39m(_decode_stdoutdata(stderr))\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mJava command failed : \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(cmd))\n\u001b[1;32m    148\u001b[0m \u001b[39mreturn\u001b[39;00m (stdout, stderr)\n",
      "\u001b[0;31mOSError\u001b[0m: Java command failed : ['/Users/jmanning/opt/anaconda3/envs/prediction-retrodiction/bin/java', '-mx1000m', '-cp', '/Users/jmanning/prediction-retrodiction-paper/data/stanford-postagger.jar', 'edu.stanford.nlp.tagger.maxent.MaxentTagger', '-model', '/Users/jmanning/prediction-retrodiction-paper/data/english-bidirectional-distsim.tagger', '-textFile', '/var/folders/tp/qtzc39jx5w556wl5w3dj21wr0000gn/T/tmpnv4bm30d', '-tokenize', 'false', '-outputFormatOptions', 'keepEmptySentences', '-encoding', 'utf8']"
     ]
    }
   ],
   "source": [
    "stanford_tagger.tag('This is a test'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1127/1127 [5:02:25<00:00, 16.10s/it]   \n"
     ]
    }
   ],
   "source": [
    "all_tenses = []\n",
    "for f in tqdm(fnames):\n",
    "  tenses = {}\n",
    "  dialogue = get_dialogue(os.path.join(imsdb_dir, f))\n",
    "\n",
    "  if dialogue is None:\n",
    "    continue\n",
    "\n",
    "  for d in dialogue['Character_dialogue'].values:\n",
    "    d = d.strip()\n",
    "    if len(d) > 0:\n",
    "      tenses = add_dict(tenses, tag_document(d))\n",
    "  \n",
    "  all_tenses.append((f[:-4], tenses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tenses2df(all_tenses):\n",
    "    keys = set()\n",
    "    for t in all_tenses:\n",
    "        keys = keys.union(set(t[1].keys()))\n",
    "\n",
    "    df = pd.DataFrame(columns=list(keys), index=pd.Index([t[0] for t in all_tenses], name='Film'))\n",
    "    for m, t in all_tenses:\n",
    "        for k in t:\n",
    "            df.loc[m, k] = t[k]\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    df['Total'] = df.sum(axis=1)\n",
    "\n",
    "    for k in keys:\n",
    "        df[k] = df[k] / df['Total']\n",
    "    df.drop('Total', axis=1, inplace=True)\n",
    "    return df.dropna(how='all', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conditional indefinite</th>\n",
       "      <th>present indefinite</th>\n",
       "      <th>past indefinite</th>\n",
       "      <th>infinitive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Film</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Midnight-Express</th>\n",
       "      <td>0.061722</td>\n",
       "      <td>0.542012</td>\n",
       "      <td>0.272303</td>\n",
       "      <td>0.123963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Big-Eyes</th>\n",
       "      <td>0.076048</td>\n",
       "      <td>0.555096</td>\n",
       "      <td>0.284532</td>\n",
       "      <td>0.084325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Warrior</th>\n",
       "      <td>0.069118</td>\n",
       "      <td>0.520588</td>\n",
       "      <td>0.272794</td>\n",
       "      <td>0.137500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hellraiser-Hellseeker</th>\n",
       "      <td>0.088144</td>\n",
       "      <td>0.512725</td>\n",
       "      <td>0.278088</td>\n",
       "      <td>0.121043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hannah-and-Her-Sisters</th>\n",
       "      <td>0.087430</td>\n",
       "      <td>0.511512</td>\n",
       "      <td>0.270068</td>\n",
       "      <td>0.130989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smashed</th>\n",
       "      <td>0.125676</td>\n",
       "      <td>0.448649</td>\n",
       "      <td>0.283108</td>\n",
       "      <td>0.142568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wild-Wild-West</th>\n",
       "      <td>0.093483</td>\n",
       "      <td>0.529380</td>\n",
       "      <td>0.240385</td>\n",
       "      <td>0.136752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sessions-The</th>\n",
       "      <td>0.115983</td>\n",
       "      <td>0.505658</td>\n",
       "      <td>0.239745</td>\n",
       "      <td>0.138614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Silver-Linings-Playbook</th>\n",
       "      <td>0.107998</td>\n",
       "      <td>0.481406</td>\n",
       "      <td>0.280183</td>\n",
       "      <td>0.130413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four-Rooms</th>\n",
       "      <td>0.090014</td>\n",
       "      <td>0.557900</td>\n",
       "      <td>0.218472</td>\n",
       "      <td>0.133615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         conditional indefinite  present indefinite   \n",
       "Film                                                                  \n",
       "Midnight-Express                       0.061722            0.542012  \\\n",
       "Big-Eyes                               0.076048            0.555096   \n",
       "Warrior                                0.069118            0.520588   \n",
       "Hellraiser-Hellseeker                  0.088144            0.512725   \n",
       "Hannah-and-Her-Sisters                 0.087430            0.511512   \n",
       "...                                         ...                 ...   \n",
       "Smashed                                0.125676            0.448649   \n",
       "Wild-Wild-West                         0.093483            0.529380   \n",
       "Sessions-The                           0.115983            0.505658   \n",
       "Silver-Linings-Playbook                0.107998            0.481406   \n",
       "Four-Rooms                             0.090014            0.557900   \n",
       "\n",
       "                         past indefinite  infinitive  \n",
       "Film                                                  \n",
       "Midnight-Express                0.272303    0.123963  \n",
       "Big-Eyes                        0.284532    0.084325  \n",
       "Warrior                         0.272794    0.137500  \n",
       "Hellraiser-Hellseeker           0.278088    0.121043  \n",
       "Hannah-and-Her-Sisters          0.270068    0.130989  \n",
       "...                                  ...         ...  \n",
       "Smashed                         0.283108    0.142568  \n",
       "Wild-Wild-West                  0.240385    0.136752  \n",
       "Sessions-The                    0.239745    0.138614  \n",
       "Silver-Linings-Playbook         0.280183    0.130413  \n",
       "Four-Rooms                      0.218472    0.133615  \n",
       "\n",
       "[998 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tenses2df(all_tenses)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Proportion', ylabel='Tense'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=df.reset_index().melt(id_vars='Film', var_name='Tense', value_name='Proportion'), y='Tense', x='Proportion', orient='h')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prediction-retrodiction",
   "language": "python",
   "name": "prediction-retrodiction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
