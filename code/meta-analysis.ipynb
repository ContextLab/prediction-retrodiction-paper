{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import davos\n",
    "except:\n",
    "    %pip install davos\n",
    "davos.config.suppress_stdout = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 smuggle BeautifulSoup     # pip: beautifulsoup4==4.12.2\n",
    "smuggle requests                   # pip: requests==2.28.2\n",
    "from tqdm smuggle tqdm             # pip: tqdm==4.65.0\n",
    "smuggle textract                   # pip: textract==1.6.4\n",
    "smuggle Levenshtein                # pip: levenshtein\n",
    "smuggle fuzzywuzzy                 # pip: fuzzywuzzy==0.18.0\n",
    "smuggle unidecode                  # pip: Unidecode==1.3.6\n",
    "smuggle pandas as pd               # pip: pandas==2.0.1\n",
    "smuggle numpy as np                # pip: numpy==1.25.2\n",
    "smuggle seaborn as sns             # pip: seaborn==0.12.2\n",
    "from matplotlib smuggle pyplot as plt  # pip: matplotlib==3.7.1\n",
    "from IPython.display import Markdown\n",
    "smuggle openai                     # pip: openai==0.27.9\n",
    "\n",
    "smuggle re\n",
    "smuggle os\n",
    "smuggle urllib\n",
    "smuggle json\n",
    "smuggle string\n",
    "smuggle warnings\n",
    "smuggle pickle\n",
    "from glob smuggle glob as lsdir\n",
    "\n",
    "from pathlib smuggle Path\n",
    "\n",
    "from helpers smuggle format_filename, get_soup, get_pdf_text, get_doc_text, get_dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jmanning/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "import accelerate\n",
    "import einops\n",
    "import bitsandbytes\n",
    "import sentencepiece\n",
    "import llama_cpp\n",
    "from huggingface_hub import hf_hub_download\n",
    "from langchain.llms import LlamaCpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = 'TheBloke/Llama-2-70B-Orca-200k-GGML'\n",
    "# weights = 'llama-2-70b-orca-200k.ggmlv3.Q5_0.bin'\n",
    "\n",
    "# model_path = hf_hub_download(repo_id=model, filename=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = str(Path.cwd().parent.joinpath('data', 'llama-2-70b-orca-200k.gguf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Llama(model_path=model_path, n_gqa=8, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'llama_cpp' has no attribute 'init'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m llama_cpp\u001b[39m.\u001b[39;49minit(model_path)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'llama_cpp' has no attribute 'init'"
     ]
    }
   ],
   "source": [
    "llama_cpp.init(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Llama.__del__ at 0x2a1ed17e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jmanning/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/llama_cpp/llama.py\", line 1435, in __del__\n",
      "    if self.ctx is not None:\n",
      "AttributeError: 'Llama' object has no attribute 'ctx'\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for LlamaCpp\n__root__\n  Could not load Llama model from path: /Users/jmanning/.cache/huggingface/hub/models--TheBloke--Llama-2-70B-Orca-200k-GGML/snapshots/4c53c4642c29ab72a2cb8c4f2478b3f6406d7846/llama-2-70b-orca-200k.ggmlv3.Q5_0.bin. Received error Llama.__init__() got an unexpected keyword argument 'rope_freq_scale' (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m llm \u001b[39m=\u001b[39m LlamaCpp(model_path\u001b[39m=\u001b[39;49mmodel_path, max_tokens\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, n_batch\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/langchain/load/serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lc_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[39m=\u001b[39m validate_model(__pydantic_self__\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[39mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[39m'\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for LlamaCpp\n__root__\n  Could not load Llama model from path: /Users/jmanning/.cache/huggingface/hub/models--TheBloke--Llama-2-70B-Orca-200k-GGML/snapshots/4c53c4642c29ab72a2cb8c4f2478b3f6406d7846/llama-2-70b-orca-200k.ggmlv3.Q5_0.bin. Received error Llama.__init__() got an unexpected keyword argument 'rope_freq_scale' (type=value_error)"
     ]
    }
   ],
   "source": [
    "llm = LlamaCpp(model_path=model_path, max_tokens=256, n_batch=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "with open(Path.cwd().parent.joinpath('data', 'prompt.txt'), 'r') as f:\n",
    "    prompt = f.read()\n",
    "\n",
    "prompt = PromptTemplate(prompt, input_variables=['text'])\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c043f5d9b0324367b8862b7354ed31f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae4c22d065342fa9bd10ed24ad50885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f86feff92c4b269088b6a7bf903291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722a23f5f3814c659e6472f653ba2729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "hf_api_key_fname = Path.cwd().parent.joinpath('data', 'hf_api_key.txt')\n",
    "with open(hf_api_key_fname) as f:\n",
    "    hf_api_key = f.read().strip()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-13b-chat-hf\", token=hf_api_key)\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-70b-chat-hf\", token=hf_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bf97e1816f4c78883338832b6c8ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/587 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db84588ebc345b5bb2f3f4b6d14c62e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fetensors.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca51abfd1424789943d69eb820430dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd41cd2826dd477380fce3a98df50cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271caa44407942199f30821a895486d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00003.safetensors:   0%|          | 0.00/9.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae7f8f1e2dc4236aa1989aec859575f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00003.safetensors:   0%|          | 0.00/6.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0ac0ee34cc44d380bb6dff7d2d316f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jmanning/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/transformers/utils/hub.py:373: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1962f2060a1f4679a80087d2fbff9809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-13b-chat-hf\", token=hf_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'How much wood could a wood chuck chuck if a wood chuck could chuck wood?'\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ids = model.generate(inputs.input_ids, max_length=100, num_beams=5, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "hf_api_key_fname = Path.cwd().parent.joinpath('data', 'hf_api_key.txt')\n",
    "with open(hf_api_key_fname) as f:\n",
    "    hf_api_key = f.read().strip()\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id='meta-llama/Llama-2-70b-chat-hf',\n",
    "    task='text-generation',\n",
    "    model_kwargs={'max_length': 64, 'token': hf_api_key}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_file = Path.cwd().parent.joinpath('data', 'prompt.txt')\n",
    "api_key_file = Path.cwd().parent.joinpath('data', 'api_key.txt')\n",
    "model = \"gpt-3.5-turbo-16k\"\n",
    "chunk_size = 5000\n",
    "\n",
    "def generate_gpt_responses_by_chunk(data_folder, prompt_file, api_key_file, model=\"gpt-3.5-turbo\",\n",
    "                                    chunk_size=20, max_files=None, max_attempts=3):\n",
    "    # Read API key\n",
    "    with open(api_key_file, 'r') as f:\n",
    "        openai.api_key = f.read().strip()\n",
    "        \n",
    "    # Read prompt template\n",
    "    with open(prompt_file, 'r') as f:\n",
    "        prompt_template = f.read()\n",
    "    \n",
    "    # Initialize variables\n",
    "    all_responses = pd.DataFrame()\n",
    "    all_errors = []\n",
    "\n",
    "    # Calculate total number of chunks for tqdm\n",
    "    total_chunks = 0\n",
    "    for file in os.listdir(data_folder)[:max_files]:\n",
    "        if file.endswith('.txt'):\n",
    "            with open(os.path.join(data_folder, file), 'r') as f:\n",
    "                text = f.read()\n",
    "            \n",
    "            sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "            sentences = [' '.join(s.strip().split()) for s in sentences if len(s.strip()) > 0]\n",
    "            total_chunks += -(-len(sentences) // chunk_size)\n",
    "\n",
    "    # Initialize tqdm\n",
    "    pbar = tqdm(total=total_chunks)\n",
    "    \n",
    "    # Start generating responses\n",
    "    for file in os.listdir(data_folder)[:max_files]:\n",
    "        if not file.endswith('.txt'):\n",
    "            continue\n",
    "\n",
    "        pkl_filename = f\"{file[:-4]}_chunk{chunk_size}.pkl\"\n",
    "        pkl_filepath = os.path.join(data_folder, pkl_filename)\n",
    "\n",
    "        if os.path.exists(pkl_filepath):\n",
    "            # Load existing data\n",
    "            with open(pkl_filepath, 'rb') as f:\n",
    "                responses_df, file_errors = pickle.load(f)\n",
    "        else:\n",
    "            # Read and chunk file\n",
    "            with open(os.path.join(data_folder, file), 'r') as f:\n",
    "                text = f.read()\n",
    "            \n",
    "            sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "            sentences = [' '.join(s.strip().split()) for s in sentences if len(s.strip()) > 0]\n",
    "            \n",
    "            chunks = [sentences[i:i + chunk_size] for i in range(0, len(sentences), chunk_size)]\n",
    "            responses_df = pd.DataFrame(columns=['file', 'chunk_idx', 'response'])\n",
    "            file_errors = []\n",
    "            \n",
    "            # Generate GPT responses for each chunk\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                prompt = prompt_template.replace(\"{text}\", ' '.join(chunk))\n",
    "\n",
    "                attempts = 0\n",
    "                while attempts < max_attempts:\n",
    "                    attempts += 1\n",
    "\n",
    "                    response = openai.ChatCompletion.create(model=model, messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant and an expert linguist. You are extremely good at following instructions.\"},\n",
    "                                                                                   {\"role\": \"user\", \"content\": prompt}])['choices'][0]['message']['content']\n",
    "                    \n",
    "                    # Correct common mistakes\n",
    "                    last_response = re.findall(r'P\\d+F\\d+', response.split()[-1])\n",
    "                    if last_response:\n",
    "                        break\n",
    "                    elif re.search(r'F\\d+$', response):\n",
    "                        response = \"P0\" + re.findall(r'F\\d+$', response)[-1]\n",
    "                        break\n",
    "                    elif re.search(r'P\\d+$', response):\n",
    "                        response = re.findall(r'P\\d+$', response)[-1] + \"F0\"\n",
    "                        break\n",
    "                    # Log the error if max_attempts reached\n",
    "                    if attempts >= max_attempts:\n",
    "                        file_errors.append((i, response))\n",
    "                    \n",
    "                responses_df = responses_df._append(pd.DataFrame({'file': [file], 'chunk_idx': [i], 'response': [response]}), ignore_index=True)\n",
    "                pbar.update(1)\n",
    "\n",
    "            # Save chunk responses to a pickle file\n",
    "            with open(pkl_filepath, 'wb') as f:\n",
    "                pickle.dump((responses_df, file_errors), f)\n",
    "        \n",
    "        # Append responses and errors\n",
    "        all_responses = all_responses._append(responses_df, ignore_index=True)\n",
    "        all_errors.extend([(file, *error_tuple) for error_tuple in file_errors])\n",
    "        \n",
    "    pbar.close()\n",
    "    return all_responses, all_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_summarize_gpt_responses(all_responses):\n",
    "    results_df = pd.DataFrame(columns=[\"filename\", \"past_count\", \"future_count\"])\n",
    "\n",
    "    for responses_df in all_responses:\n",
    "        filename = responses_df.iloc[0]['filename']\n",
    "        total_past = 0\n",
    "        total_future = 0\n",
    "        for index, row in responses_df.iterrows():\n",
    "            output = row['response']\n",
    "            try:\n",
    "                parts = output.split('F')\n",
    "                past_count = int(parts[0][1:])\n",
    "                future_count = int(parts[1])\n",
    "                total_past += past_count\n",
    "                total_future += future_count\n",
    "            except ValueError:\n",
    "                pass  # Ignore incorrectly formatted responses\n",
    "        \n",
    "        new_row = {\"filename\": filename, \"past_count\": total_past, \"future_count\": total_future}\n",
    "        results_df = results_df._append(new_row, ignore_index=True)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare manually vs. automatically tagged references from *The Chair*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Episode</th>\n",
       "      <th>tense</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Past</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Future</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Past</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Future</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Past</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Future</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>Past</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>Future</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Past</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Future</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>Past</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>Future</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Episode   tense  count\n",
       "0         1    Past     60\n",
       "1         1  Future     18\n",
       "2         2    Past     30\n",
       "3         2  Future     14\n",
       "4         3    Past     43\n",
       "5         3  Future     33\n",
       "6         4    Past     31\n",
       "7         4  Future     21\n",
       "8         5    Past     36\n",
       "9         5  Future     11\n",
       "10        6    Past     27\n",
       "11        6  Future     12"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill in proportions for manual reference counts\n",
    "ref_fname = str(Path.cwd().parent.joinpath('data', 'the_chair', 'the_chair_manual_reference_counts.csv'))\n",
    "manual = pd.read_csv(ref_fname)\n",
    "manual['Total'] = manual['Past'] + manual['Future']\n",
    "\n",
    "# # compute proportions\n",
    "# manual['p(Past)'] = manual['Past'] / manual['Total']\n",
    "# manual['p(Future)'] = manual['Future'] / manual['Total']\n",
    "\n",
    "manual.reset_index(inplace=True)\n",
    "manual['Episode'] = manual['index'] + 1\n",
    "manual.drop(['index', 'Total'], axis=1, inplace=True)\n",
    "\n",
    "manual = manual.melt(var_name='tense', value_name='count', id_vars=['Episode'])\n",
    "manual.sort_values(['Episode'], inplace=True)\n",
    "manual.reset_index(inplace=True, drop=True)\n",
    "manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I'd like your help, as a linguist and an expert on literature. Please read the following text, between the <text>...</text> tags, and carefully identify any sentences or phrases that refer to to past or future events.\n",
      "\n",
      "Your job is to follow the four steps below and then respond in JSON format, following the template below delimited by the <json_template>...</json_template> tags:\n",
      "\n",
      "1. Try to understand what is happening in the story excerpt depicted by the text.\n",
      "2. Split the text given below into individual sentences, denoted S0, S1, S2, ..., SN (assuming there are N sentences).  Keep track of each sentence's text and store it in the \"content\" field for that sentence (replacing the \"...\" in the template with the actual content of the sentence).\n",
      "3. For each sentence, count up the number of references to past (P) events and future (F) events, and store the counts in the \"P\" and \"F\" fields, respectively (replacing the \"...\" in the template with the actual counts).\n",
      "4. Continue steps 2 and 3 for each sentence (creating a new field for each sentence) until you've gone through all of the provided text.\n",
      "\n",
      "<json_template>\n",
      "{'S0': {'content': \"...\", 'P': \"...\", 'F': \"...\"},\n",
      "'S1': {'content': \"...\", 'P': \"...\", 'F': \"...\"},\n",
      "'S2': {'content': \"...\", 'P': \"...\", 'F': \"...\"},\n",
      "...\n",
      "'SN': {'content': \"...\", 'P': \"...\", 'F': \"...\"}}\n",
      "</json_template>\n",
      "\n",
      "Here is the text I'd like you to process:\n",
      "\n",
      "<text>\n",
      "[Larson] Did you at any point threaten Bill’s TA? What? No. Where is this coming from? Did you say she could get hurt if she talked to the student newspaper? No. [inhales] I mean, I, I… I… I mentioned that the… the department could get hurt if we… Pembroke Daily is running an article suggesting you issued a gag order. I would never do that. Did you have a conversation with Bill’s TA in which you asked her not to discuss Bill’s incident? I can try to kill the story if it’s inaccurate. I… That is certainly not what I meant to convey. Students are already mobilized, and we’re concerned that this is going to exacerbate things on campus. We would like you to make some kind of statement. Okay. I mean… I mean, yes. I’ve drafted a letter from both you and Dean Larson alerting Professor Dobson that next week’s hearing will be on termination for cause. It’s no longer a disciplinary hearing. What about due process? In order to fire a tenured professor, don’t you have… Tenure is not a blank check anymore. Particularly in this climate. And we heard about him lecturing hungover and showing nude photos in class. Or nude videos, I think it was. Videos. That was… Getting rides from female students. That happened once. Which one? All of them. I realize that’s not a great defense. So you knew about him with a coed? I mean, did she complain? Really? She shouldn’t have to. No, no, she shouldn’t have to. His wife died a year ago. Are you two involved? If I were a man, would you ask me that? The three of you left campus yesterday in the same car. Only because his was in the shop. If you are romantically involved, you need to declare it, or you yourself are in violation of university policy. Another option would be for you to step down as chair. My defending Professor Dobson has nothing to do with my feelings for him, which are entirely platonic and professional. I have a responsibility to protect my… You have a responsibility to this institution, to prevent issues like this from spinning out of control. You’ve managed to do the opposite. Sign here, if you would. Call me when you get this. We need to talk. It’s urgent. And… it’s pretty bad for both of us. Anyway, I have to go to this meeting, and I’m gonna drop something off to you, so just… Please call me immediately when you get this. Call me. You better call me. [“Stakes Avenue” by Love as Laughter playing on headphones] [Ju Ju] Who’s David Duchovny? [Ji-Yoon] Nobody. I just have to give this to Bill. Stay here. I have to tell him something now. I told you it can’t happen today. I have to tell him something for Día de los Muertos! [banging on door] Bill? I have to give you something. Bill? [exhales] His wife’s soul won’t know where to go. She will. She won’t be able to find him. Yes, she will, Ju Ju. You don’t know anything about Día de los Muertos. You don’t know anything about my heritage! Puta. [pulls handbrake] Guess what? The reason you know the word puta is because I’m giving you Spanish lessons. And the reason we’re going to Oaxaca this summer is because some of your ancestors are from there. Ava’s going to Disneyland. Duly fucking noted. [groans] [door closes] [in Korean] You’re early. [sighs] Yes, we… [in English] There was a mishap at Bill’s. Here’s her stuff. I’ll be back later. [in Korean] When are you coming back? I’m not sure. Minji only has a first birthday once. Everyone complains how they never see you. [in English] Appa, I don’t know what you want me to do. This is for my job. [in Korean] I thought this promotion means you don’t have to work so much. [in English] What promotion ever means you don’t have to work as much? [breathes deeply] Baby, for God’s sakes, just be good and do what halahbojee says, okay? [in Korean] How can she do what I tell her when she doesn’t speak Korean? [in English] Appa, you can speak English. And she understands more than you think. Here. [in Korean] See you later. I love you. [in English] You understand, right? [in Korean] I love you, Ju Ju. [sighs] She’s mad at me because she was supposed to work on her Mexico presentation this morning with Bill. [in English, sighing] She’s mad at me for bringing her here instead. [Habi] Mexico? [in Korean] For homework. [in English] She’s cultural ambassador for… for Día de los Muertos. It’s a Mexican tradition. Never mind. Heads up, Hitler! [laughing] [tires screeching] [pills hitting the ground] [music continues] [doorbell rings] [knocking on door] Hello? Mr. Duchovny? Hello? [water splashing] David? Hello? [water splashing] What the fuck? Hey. Hi. Hi. [gasps] [exhales] I didn’t know anybody was here. [spits] [exhales] Ji-Yoon? Yeah. The, uh… The door was open. Do you always leave your door open? Never had a problem before. That’s why I love it here. Nobody bothers you. Oh my God! [David] Oh. You okay? [exhales sharply] Yeah, sorry, I… For a second, I thought you were naked. Oh. Interesting. [car approaching] Bill! Bill! Bill! Hey. What are you doing? Going to McDonald’s. What are you guys doing here? We’re going to Minji’s birthday party. Who’s Minji? [Ju Ju] She’s my second cousin. Habi, can Bill come? No, no. Please? Yeah, I’m on a tight schedule. [smacks lips] Will there be cake? You left this at the copier. Uh, you’re not supposed to read this. I only glanced at the first few sentences to see what it was. It’s against the rules. Okay, let’s move on from the argument about whether or not I should’ve looked at it, and just get to the real argument here. I’m all ears. [inhales deeply] Never mind. I offered a positive assessment of your scholarship. The P&T committee doesn’t buy it when I don’t express any reservations whatsoever. So believe it or not, I’m… I’m trying to help you. [laughing] Help me? [Rentz] Yeah. You’re helping me? Yes. Ji-Yoon came to me and begged me to co-teach with you because your enrollments were so low. What? [Yaz] You were on a list. They were gonna force you to retire. So she merged us so that you could piggyback on my enrollments. What list? You’re lecturing to an empty hall. Because I don’t pander to my students. Nobody wants what you’re selling. I’m not a salesman. You’re not a professor either, ’cause you don’t have any students. John? John! [gasps] Have you heard about a list? All us dinosaurs, they’re targeting us, trying to force us into retirement. We gotta band together. There’s strength in numbers. We’re still in our intellectual prime and have plenty to offer. [farts] Was that you or me? For the Distinguished Lectureship, I was thinking of presenting my Yale dissertation. “The Schizophrenic Critique of Pure Reason in Beckett’s Early Novels.” I only wrote the one chapter. Well, that’s… that’s a hell of a chapter. Did you use really big font? Nope. I got sidetracked for a few decades, but I’ve… I’ve been thinking recently about finishing it and filing for my PhD. Dr. David Duchovny. Maybe too much alliteration. Do you think it’s unfair for people to start thinking of me as Dr. David Duchovny after thinking of me as just David Duchovny for so many years? Um… Anyway, take a gander. I reread it last night. It’s… It’s pretty good. Prescient, even. Prescient? Really? I think it’s pronounced “prescient,” unless we’re English. Aren’t we speaking English? I mean, maybe you chose the wrong department. Maybe you’re better suited for the schiences. Oh, and I… I don’t say that because you’re Asian. I mean, I don’t even know that you are Asian. And I don’t see color, or ethnicity, or even faces at this point. I just see vibe, an aura. And yours is lovely. [sighs] I’m gonna make a schmoothie. [laughs] Would you like a schmoothie? No, thank you. [David] Have you been to the farmers’ market here? No. [David] Ah. I used to think this town was devoid of culture, but I stand corrected. I mean, look… look at that carrot. Anyway, pretend I’m not here. [juicer whirring] [upbeat dance music playing] [clicking] [indistinct chatter] [woman 1 speaking indistinctly] Hi. Hi. [in Korean] It’s like a Frankenstein family. Why didn’t she adopt a baby from South Korea? [in English] Hi. [woman 2 speaking Korean] You can only adopt from South Korea if you’re married. She was closed out from international adoption because she’s single. Please, Madonna’s single and she was able to adopt. Angelina Jolie too. [Korean pop music playing] [Ju Ju] Bill! It’s not time for cake yet! [grunts] How much longer? Stay here for a sec. I’m trading Pokémon cards. Hey. Sit. Sit. [coughs] Hi. [man] Korean earmuffs. Excuse me? When children are screaming… What screaming? [both laugh] Hold with two hands. Uh-huh. Turn your head away. [laughs] You don’t make eye contact or drink in front of another. Okay. Okay? Like this. Okay. Gun bae. Gum bae. Gun bae. [man chuckles] [chuckles] “Gun” or “gum?” Gun. Gun. Gun bae. Gun bae. [chuckles] I… I can’t just catch you up with a quick tutorial. Why not? Because that’s an insane request. This is over 30 years old. A lot has happened in the last 30 years. Like what? Like affect theory, ecocriticism, digital humanities, new materialism, book history, developments in gender studies and critical race theory. When’s the last time you picked up an academic journal? I… I’ve been on tour with my band. So… Hmm. It shows. And you know what else? The fact that you’re using this honor from Pembroke to dust off your dissertation and go back and get your PhD, it’s… it’s self-serving. Whoa. Is… Is this hostility because Pembroke is like this lower-tier Ivy, and I went to Princeton? No. Okay… And Yale? No. no. My God, no. This is hostility because I promised this Distinguished Lectureship to someone who deserves it. The purpose of the talk is to present cutting-edge scholarship, and this reads like it’s out of the mid-’80s. I mean, like, the… The discipline has moved forward, and you’re still stuck back in a different era. [sighs] [groans] I just need a minute. Here, can I maybe… No. [laughing] [in Korean] I think that’s Ji-Yoon’s boyfriend. Peter Seung? No, it’s been so long since they broke up. He’s in Michigan now. I’m knitting him this sweater. Look at his face. He’s a white man. [men laughing] Oh, I see. Habi said they picked him up off the street. That makes sense. He looks messy. [sighs] [inhales deeply] [guitar playing] [David singing indistinctly] Only song I’ve ever heard quote Wallace Stevens. Fuck, I hope so. You have a good voice. Mmm. Was there someone else before me? A celebrity author? Did Pembroke offer this position to someone else first? It’s all right, I can take it. There was talk of James Franco a while back. Ugh. Well, he got his PhD from Yale. Oh, did he? Oh, he got it? Oh. Yeah. Yes, he… He did. He did. They might’ve invited Ethan Hawke, but he was shooting in Bulgaria. What was he shootin’? [Ji-Yoon] Pardon me? In Bulgaria. Well, a movie or a TV series? Well, I… I don’t know what he was shooting. There’s a lot of shootin’ in Bulgaria. Okay. [exhales] Look, so I did all that work at Yale on Beckett, right? But I… I figure I’ll just stick with that and then… [exhales] Let’s take a swim. Oh, I don’t… have a bathing suit. Well, you can borrow one. Here, borrow this one. Um, whose… Who… Who wore that? Oh, it’s mine. It’s a speedsuit. I wear it when I wanna swim for time. Skin’s a drag, you know, ’cause of hair. You can’t only teach Beckett for the rest of the semester. Why not? You got Murphy, Molloy, Malone Dies… The students bought the other books. So I’ll reimburse them. I’m a grossly overpaid actor/musician/novelist, and they’re students burdened with student debt. I will unburden them. No, the syllabus is a contract with them. You can’t change the reading… Let’s go for a swim. Okay, you know what? Teaching is not a pastime, it’s a profession. If you really wanna make a contribution to the field, tell them you’ve changed your mind. And give them a check to endow a chair in your name, and I’ll get you an honorary doctorate. The David Duchovny Chair in English Studies? The Dr. David Duchovny Chair in English Studies. [indistinct chatter] What’s this? The main event. Doljabi ceremony. Minji picks her future. She’s only one. Oh, she… she’s very smart. She can make a clear decision now. What’s all this? [Ju Ju] A stethoscope for a doctor, a pencil for a teacher, paintbrush for an artist, money for being rich, a tennis ball for an athlete, and a white string for long life. I would pick the string so I could live a long, long, long time. What about you? I can only pick one? Uh-huh. [people shouting excitedly] [Habi] You’re beautiful. [all cheering, applauding] [Ju Ju] Go, go, go! Go! Beautiful. Go! Go, cutie! [Habi] Let’s go, Minji. [man] Best of luck! [excited chatter] [all cheering] [laughing] Minji, get the string! The string! The string! [Habi] Let’s go, Minji. [man 1] That’s the one! [people laughing] So close. [man 2] Let’s go, Minji. [people] Oh! [Habi] Oh! [cheering] You can’t do that. [Habi] Get the money. This isn’t authentic. She’s clearly tampering with the process right now. Let her make her own choice. [all cheering] Great. Great. [all cheering] That lady right there, she rigged it. This lady rigg… She rigged the process. She… She wanted the paintbrush. Here. Hey, hey, mama. You can have this. Don’t listen to them. [man] Hey. Hey. Hold on, hold on. She wanted the paintbrush. Oh! [woman] Oh! [people] Oh! [grunts] [somber music playing] [Joan] This is one of the few professions where you get more respect as you get older. I mean, one of the reasons I went into this was that you don’t age out. I… I never thought I’d retire. As long as you’re not… out of it. Sixty-one. Oh, Jesus. That’s low. You got your glucose tablets? Where are they? [Joan] Hang on. [sighs] You get older… [Rentz] I don’t see them. …you accumulate more wisdom, you garner more respect. I, um… I’ve been, uh… I’ve been here for what, 32 years, was chair for six of those, and nothing like this ever happened. A lifetime of doing this, and I get nothing. Well, she wanted me to doctor my tenure letter for Yaz in exchange for co-teacher. I get put on a list. What about Bob? I mean, what about Bill? What about Bill? [chuckling] I can’t take you seriously when you look like you just stuck your head in a beehive. Here. Bill’s not on this list. No, Bill, everybody knows she’s in love with him. Now, if one of us had stepped out of line, she would not be going to the mat like this. Mmm. Well, we elected her. Her job is to represent our interests. She’s only protected his. We gotta do something. Like what? [scoffs] You wanna stage a coup? I’ve got great news. David Duchovny’s not giving the Distinguished Lectureship, you are. [sighs] What’s wrong? I already agreed to give it somewhere else. Where? Yale. Holy shit, that’s great. It’s also a job talk. They’ve invited me to apply for a position. Why didn’t you tell me? [breathes deeply] Look, I know it’s been a mess around here. I… I mean, I’ve been a mess. [inhales] You act like you owe them something. Like you’re here because they let you be here, not because you deserve it. I mean, what are they without us at this point? A name and a pile of bricks. A shit ton of money. Seeded by benefactors who got rich off of sugar and cotton and railroads. Off the backs of Black people and yellow people. And, yes, that includes Yale. Yale’s different? You should be running this place. Instead, you’re running around playing nice. You think that’s how I got here? By playing nice? Is that how you think I fucking got here? No. You are gonna be the first tenured Black woman in the department. [scoffs] That’s why I’m leaving. [sighs] Pembroke said and did all the right things to keep me here. But you know the real reason I stayed? It was because of Joan, and Bill, and this dazzling new hire named Yaz. Fucking Yale. [chuckles] You know what New Haven’s ranking is on WalletHub’s list of best college towns in America? A hundred and ninety-eight. A couple notches below Fargo, North Dakota. What are we? I don’t know. I’ll have to ask my dad. [chuckles softly] What are they offering? [inhales deeply] Expedited tenure and an endowed professorship. And a shit ton of money. We can beat that. [inhales deeply] I think. I’m getting a little bit full, but I love… It’s wonderful. Uh, Mr. Kim, thank… thank you all for helping clean up. You didn’t have to do that. But it’s nice to see my table. [Ju Ju] Bill, I’m ready. I need the pizza. Excuse me a second. Thank you. Thank you. Thank you. [sniffles] Excuse me. [Ju Ju] I need all her favorite things. [in Korean] How can a grown man live like this? He’s a widower. Ah. I’m a widower, and my house is clean. How long ago did he lose his wife? It’s been about a year. He works together with Ji-Yoon? Yes. English professor. And he wrote a book, maybe two? [in English] I’m so sorry about this afternoon. Thank you. I hope I didn’t mess it up. Okay. Okay. I couldn’t find any pizza, but I have pizza rolls. Okay, what do we do? We’re gonna make a trail. Okay. [Ju Ju] Let’s put them far apart so that she can smell it. [woman in Korean] If only there were a good Korean woman in his life. What about Ji-Yoon? He has a good job. Not bad-looking if he’d only shave. And he’s good with kids. They say he’s a drug addict and he drinks. You want Ji-Yoon to bring a drug addict alcoholic into her life? She’s turning 50 soon. [sighs] Maybe this is the last bus in town. [sighs] [phone dings] [in English] We have to go. Ju Ju, your mom got home early. She’s gonna find you. Bye. Wait. I have a question. Not for you, you goof, for your grandpa. [Ju Ju] Habi? Um, what did Ji-Yoon pick for her Dol ceremony? Do you remember? Yeah, she picked a pencil. Teacher. She go straight there. No one can stop her.\n",
      "</text>\n",
      "\n",
      "Response: \n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens. However, your messages resulted in 5115 tokens. Please reduce the length of the messages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         auto, errors \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     auto, errors \u001b[39m=\u001b[39m generate_gpt_responses_by_chunk(chair_dir, prompt_file\u001b[39m=\u001b[39;49mprompt_file, api_key_file\u001b[39m=\u001b[39;49mapi_key_file, chunk_size\u001b[39m=\u001b[39;49mchunk_size, max_files\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(chair_results_fname, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         pickle\u001b[39m.\u001b[39mdump((auto, errors), f)\n",
      "\u001b[1;32m/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb Cell 24\u001b[0m in \u001b[0;36mgenerate_gpt_responses_by_chunk\u001b[0;34m(data_folder, prompt_file, api_key_file, model, chunk_size, max_files, max_attempts)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X26sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mwhile\u001b[39;00m attempts \u001b[39m<\u001b[39m max_attempts:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X26sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     attempts \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X26sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(model\u001b[39m=\u001b[39;49mmodel, messages\u001b[39m=\u001b[39;49m[{\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mYou are a helpful assistant and an expert linguist. You are extremely good at following instructions.\u001b[39;49m\u001b[39m\"\u001b[39;49m},\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X26sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m                                                                    {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt}])[\u001b[39m'\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X26sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     \u001b[39m# Correct common mistakes\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X26sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     last_response \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mfindall(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+F\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+\u001b[39m\u001b[39m'\u001b[39m, response\u001b[39m.\u001b[39msplit()[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/openai/api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    764\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    766\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    767\u001b[0m     )\n\u001b[1;32m    768\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens. However, your messages resulted in 5115 tokens. Please reduce the length of the messages."
     ]
    }
   ],
   "source": [
    "chair_dir = Path.cwd().parent.joinpath('data', 'the_chair')\n",
    "\n",
    "chair_results_fname = chair_dir.joinpath(f'the_chair_gpt_responses_c{chunk_size}.pkl')\n",
    "\n",
    "if chair_results_fname.exists():\n",
    "    with open(chair_results_fname, 'rb') as f:\n",
    "        auto, errors = pickle.load(f)\n",
    "else:\n",
    "    auto, errors = generate_gpt_responses_by_chunk(chair_dir, prompt_file=prompt_file, api_key_file=api_key_file, chunk_size=chunk_size, max_files=1, model=model)\n",
    "    with open(chair_results_fname, 'wb') as f:\n",
    "        pickle.dump((auto, errors), f)\n",
    "\n",
    "auto = parse_and_summarize_gpt_responses(auto)\n",
    "auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chunk</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>[Larson] Did you at any point threaten Bill’s ...</td>\n",
       "      <td>P4F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>We would like you to make some kind of statem...</td>\n",
       "      <td>P1F4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>Videos.  That was…  Getting rides from female...</td>\n",
       "      <td>P4F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>No, no, she shouldn’t have to.  His wife died...</td>\n",
       "      <td>P4F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>You’ve managed to do the opposite.  Sign here...</td>\n",
       "      <td>P7F2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>[Ji-Yoon] Nobody. I just have to give this to...</td>\n",
       "      <td>P6F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>She won’t be able to find him.  Yes, she will...</td>\n",
       "      <td>P1F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>[breathes deeply]  Baby, for God’s sakes, jus...</td>\n",
       "      <td>P4F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>[Habi] Mexico?  [in Korean] For homework.  [i...</td>\n",
       "      <td>P1F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>[water splashing]   What the fuck?  Hey.  Hi....</td>\n",
       "      <td>P1F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>Oh my God!  [David] Oh.  You okay? [exhales s...</td>\n",
       "      <td>F1P0F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>Habi, can Bill come?  No, no.  Please?  Yeah,...</td>\n",
       "      <td>P2F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>I’m all ears.  [inhales deeply]  Never mind. ...</td>\n",
       "      <td>P3F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>What?  [Yaz] You were on a list.  They were g...</td>\n",
       "      <td>P2F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>John?  John!  [gasps]  Have you heard about a...</td>\n",
       "      <td>P2F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>Did you use really big font?  Nope.  I got sid...</td>\n",
       "      <td>P2F2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>Prescient? Really?  I think it’s pronounced “...</td>\n",
       "      <td>P0F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>And yours is lovely.  [sighs]  I’m gonna make...</td>\n",
       "      <td>P3F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>[in English] Hi.  [woman 2 speaking Korean] Y...</td>\n",
       "      <td>P4F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>[coughs]  Hi.  [man] Korean earmuffs.  Excuse ...</td>\n",
       "      <td>P0F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>Okay.  Gun bae.  Gum bae.  Gun bae.  [man chu...</td>\n",
       "      <td>P0F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>Because that’s an insane request.  This is ov...</td>\n",
       "      <td>P2F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>The fact that you’re using this honor from Pe...</td>\n",
       "      <td>P3F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>Here, can I maybe…  No.  [laughing]  [in Kore...</td>\n",
       "      <td>P1F2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>He looks messy.  [sighs]  [inhales deeply]  [g...</td>\n",
       "      <td>P4F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>Ugh.  Well, he got his PhD from Yale.  Oh, di...</td>\n",
       "      <td>P3F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>In Bulgaria.  Well, a movie or a TV series?  ...</td>\n",
       "      <td>P2F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>Um, whose… Who… Who wore that?  Oh, it’s mine...</td>\n",
       "      <td>P1F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>I will unburden them.  No, the syllabus is a ...</td>\n",
       "      <td>P1F4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>The main event.  Doljabi ceremony.  Minji pic...</td>\n",
       "      <td>P4F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>I can only pick one?  Uh-huh.  [people shouti...</td>\n",
       "      <td>P7F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>This isn’t authentic. She’s clearly tampering...</td>\n",
       "      <td>P3F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>You can have this.  Don’t listen to them.  [ma...</td>\n",
       "      <td>P1F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>Sixty-one.  Oh, Jesus.  That’s low.  You got ...</td>\n",
       "      <td>P1F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>Mmm. Well, we elected her.  Her job is to rep...</td>\n",
       "      <td>P2F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>I already agreed to give it somewhere else.  ...</td>\n",
       "      <td>P4F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>Like you’re here because they let you be here...</td>\n",
       "      <td>P1F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>You think that’s how I got here? By playing n...</td>\n",
       "      <td>P2F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>A hundred and ninety-eight.  A couple notches...</td>\n",
       "      <td>P2F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>I’m getting a little bit full, but I love… It...</td>\n",
       "      <td>P4F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>[sniffles] Excuse me.  [Ju Ju] I need all her...</td>\n",
       "      <td>P1F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>And he wrote a book, maybe two?  [in English] ...</td>\n",
       "      <td>P2F3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>[Ju Ju] Let’s put them far apart so that she ...</td>\n",
       "      <td>P1F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>[sighs]  [phone dings]  [in English] We have ...</td>\n",
       "      <td>P0F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>the_chair_s1e5_transcript.txt</td>\n",
       "      <td>Yeah, she picked a pencil.  Teacher.  She go ...</td>\n",
       "      <td>P1F1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename   \n",
       "0   the_chair_s1e5_transcript.txt  \\\n",
       "1   the_chair_s1e5_transcript.txt   \n",
       "2   the_chair_s1e5_transcript.txt   \n",
       "3   the_chair_s1e5_transcript.txt   \n",
       "4   the_chair_s1e5_transcript.txt   \n",
       "5   the_chair_s1e5_transcript.txt   \n",
       "6   the_chair_s1e5_transcript.txt   \n",
       "7   the_chair_s1e5_transcript.txt   \n",
       "8   the_chair_s1e5_transcript.txt   \n",
       "9   the_chair_s1e5_transcript.txt   \n",
       "10  the_chair_s1e5_transcript.txt   \n",
       "11  the_chair_s1e5_transcript.txt   \n",
       "12  the_chair_s1e5_transcript.txt   \n",
       "13  the_chair_s1e5_transcript.txt   \n",
       "14  the_chair_s1e5_transcript.txt   \n",
       "15  the_chair_s1e5_transcript.txt   \n",
       "16  the_chair_s1e5_transcript.txt   \n",
       "17  the_chair_s1e5_transcript.txt   \n",
       "18  the_chair_s1e5_transcript.txt   \n",
       "19  the_chair_s1e5_transcript.txt   \n",
       "20  the_chair_s1e5_transcript.txt   \n",
       "21  the_chair_s1e5_transcript.txt   \n",
       "22  the_chair_s1e5_transcript.txt   \n",
       "23  the_chair_s1e5_transcript.txt   \n",
       "24  the_chair_s1e5_transcript.txt   \n",
       "25  the_chair_s1e5_transcript.txt   \n",
       "26  the_chair_s1e5_transcript.txt   \n",
       "27  the_chair_s1e5_transcript.txt   \n",
       "28  the_chair_s1e5_transcript.txt   \n",
       "29  the_chair_s1e5_transcript.txt   \n",
       "30  the_chair_s1e5_transcript.txt   \n",
       "31  the_chair_s1e5_transcript.txt   \n",
       "32  the_chair_s1e5_transcript.txt   \n",
       "33  the_chair_s1e5_transcript.txt   \n",
       "34  the_chair_s1e5_transcript.txt   \n",
       "35  the_chair_s1e5_transcript.txt   \n",
       "36  the_chair_s1e5_transcript.txt   \n",
       "37  the_chair_s1e5_transcript.txt   \n",
       "38  the_chair_s1e5_transcript.txt   \n",
       "39  the_chair_s1e5_transcript.txt   \n",
       "40  the_chair_s1e5_transcript.txt   \n",
       "41  the_chair_s1e5_transcript.txt   \n",
       "42  the_chair_s1e5_transcript.txt   \n",
       "43  the_chair_s1e5_transcript.txt   \n",
       "44  the_chair_s1e5_transcript.txt   \n",
       "\n",
       "                                                chunk response  \n",
       "0   [Larson] Did you at any point threaten Bill’s ...     P4F0  \n",
       "1    We would like you to make some kind of statem...     P1F4  \n",
       "2    Videos.  That was…  Getting rides from female...     P4F0  \n",
       "3    No, no, she shouldn’t have to.  His wife died...     P4F0  \n",
       "4    You’ve managed to do the opposite.  Sign here...     P7F2  \n",
       "5    [Ji-Yoon] Nobody. I just have to give this to...     P6F0  \n",
       "6    She won’t be able to find him.  Yes, she will...     P1F1  \n",
       "7    [breathes deeply]  Baby, for God’s sakes, jus...     P4F1  \n",
       "8    [Habi] Mexico?  [in Korean] For homework.  [i...     P1F0  \n",
       "9    [water splashing]   What the fuck?  Hey.  Hi....     P1F0  \n",
       "10   Oh my God!  [David] Oh.  You okay? [exhales s...   F1P0F0  \n",
       "11   Habi, can Bill come?  No, no.  Please?  Yeah,...     P2F1  \n",
       "12   I’m all ears.  [inhales deeply]  Never mind. ...     P3F0  \n",
       "13   What?  [Yaz] You were on a list.  They were g...     P2F0  \n",
       "14   John?  John!  [gasps]  Have you heard about a...     P2F0  \n",
       "15  Did you use really big font?  Nope.  I got sid...     P2F2  \n",
       "16   Prescient? Really?  I think it’s pronounced “...     P0F0  \n",
       "17   And yours is lovely.  [sighs]  I’m gonna make...     P3F0  \n",
       "18   [in English] Hi.  [woman 2 speaking Korean] Y...     P4F1  \n",
       "19  [coughs]  Hi.  [man] Korean earmuffs.  Excuse ...     P0F0  \n",
       "20   Okay.  Gun bae.  Gum bae.  Gun bae.  [man chu...     P0F0  \n",
       "21   Because that’s an insane request.  This is ov...     P2F0  \n",
       "22   The fact that you’re using this honor from Pe...     P3F0  \n",
       "23   Here, can I maybe…  No.  [laughing]  [in Kore...     P1F2  \n",
       "24  He looks messy.  [sighs]  [inhales deeply]  [g...     P4F1  \n",
       "25   Ugh.  Well, he got his PhD from Yale.  Oh, di...     P3F1  \n",
       "26   In Bulgaria.  Well, a movie or a TV series?  ...     P2F0  \n",
       "27   Um, whose… Who… Who wore that?  Oh, it’s mine...     P1F0  \n",
       "28   I will unburden them.  No, the syllabus is a ...     P1F4  \n",
       "29   The main event.  Doljabi ceremony.  Minji pic...     P4F1  \n",
       "30   I can only pick one?  Uh-huh.  [people shouti...     P7F0  \n",
       "31   This isn’t authentic. She’s clearly tampering...     P3F0  \n",
       "32  You can have this.  Don’t listen to them.  [ma...     P1F0  \n",
       "33   Sixty-one.  Oh, Jesus.  That’s low.  You got ...     P1F0  \n",
       "34   Mmm. Well, we elected her.  Her job is to rep...     P2F0  \n",
       "35   I already agreed to give it somewhere else.  ...     P4F1  \n",
       "36   Like you’re here because they let you be here...     P1F1  \n",
       "37   You think that’s how I got here? By playing n...     P2F0  \n",
       "38   A hundred and ninety-eight.  A couple notches...     P2F1  \n",
       "39   I’m getting a little bit full, but I love… It...     P4F0  \n",
       "40   [sniffles] Excuse me.  [Ju Ju] I need all her...     P1F0  \n",
       "41  And he wrote a book, maybe two?  [in English] ...     P2F3  \n",
       "42   [Ju Ju] Let’s put them far apart so that she ...     P1F0  \n",
       "43   [sighs]  [phone dings]  [in English] We have ...     P0F1  \n",
       "44   Yeah, she picked a pencil.  Teacher.  She go ...     P1F1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'filename': 'the_chair_s1e5_transcript.txt',\n",
       "  'chunk': ' Here’s her stuff. I’ll be back later.  [in Korean] When are you coming back?  I’m not sure.  Minji only has a first birthday once.  Everyone complains how they never see you.  [in English] Appa, I don’t know what you want me to do. This is for my job.  [in Korean] I thought this promotion means you don’t have to work so much.  [in English] What promotion ever means you don’t have to work as much?',\n",
       "  'error': 'Invalid output format'},\n",
       " {'filename': 'the_chair_s1e5_transcript.txt',\n",
       "  'chunk': ' Well, she wanted me to doctor my tenure letter for Yaz  in exchange for co-teacher.  I get put on a list.  What about Bob? I mean, what about Bill? What about Bill?  [chuckling] I can’t take you seriously  when you look like you just stuck your head in a beehive. Here.  Bill’s not on this list.  No, Bill, everybody knows she’s in love with him.  Now, if one of us had stepped out of line,  she would not be going to the mat like this.',\n",
       "  'error': 'Invalid output format'}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer tense from text using NLTK's taggers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single sentence tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = str(Path.cwd().parent.joinpath('data'))\n",
    "tagger = os.path.join(data_dir, 'english-bidirectional-distsim.tagger')\n",
    "jar = os.path.join(data_dir, 'stanford-postagger.jar')\n",
    "\n",
    "stanford_tagger = StanfordPOSTagger(tagger, jar, encoding='utf8')\n",
    "\n",
    "def sentence_tense(x):\n",
    "  # source: https://stackoverflow.com/questions/30016904/determining-tense-of-a-sentence-python\n",
    "  def tense_detect(tagged_sentence):        \n",
    "    verb_tags = ['MD','MDF',\n",
    "                'BE','BEG','BEN','BED','BEDZ','BEZ','BEM','BER',\n",
    "                'DO','DOD','DOZ',\n",
    "                'HV','HVG','HVN','HVD','HVZ',\n",
    "                'VB','VBG','VBN','VBD','VBZ',\n",
    "                'SH',\n",
    "                'TO',                \n",
    "                'JJ']\n",
    "    \n",
    "    verb_phrase = []\n",
    "    for item in tagged_sentence:\n",
    "        if item[1] in verb_tags:\n",
    "            verb_phrase.append(item)\n",
    "\n",
    "    grammar = r'''\n",
    "            future perfect continuous passive:     {<MDF><HV><BEN><BEG><VBN|VBD>+}\n",
    "            conditional perfect continuous passive:{<MD><HV><BEN><BEG><VBN|VBD>+}\n",
    "            future continuous passive:             {<MDF><BE><BEG><VBN|VBD>+}   \n",
    "            conditional continuous passive:        {<MD><BE><BEG><VBN|VBD>+}    \n",
    "            future perfect continuous:             {<MDF><HV><BEN><VBG|HVG|BEG>+}   \n",
    "            conditional perfect continuous:        {<MD><HV><BEN><VBG|HVG|BEG>+}\n",
    "            past perfect continuous passive:       {<HVD><BEN><BEG><VBN|VBD>+}\n",
    "            present perfect continuous passive:    {<HV|HVZ><BEN><BEG><VBN|VBD>+}\n",
    "            future perfect passive:                {<MDF><HV><BEN><VBN|VBD>+}   \n",
    "            conditional perfect passive:           {<MD><HV><BEN><VBN|VBD>+}    \n",
    "            future continuous:                     {<MDF><BE><VBG|HVG|BEG>+ }   \n",
    "            conditional continuous:                {<MD><BE><VBG|HVG|BEG>+  }   \n",
    "            future indefinite passive:             {<MDF><BE><VBN|VBD>+ }\n",
    "            conditional indefinite passive:        {<MD><BE><VBN|VBD>+  }\n",
    "            future perfect:                        {<MDF><HV><HVN|BEN|VBN|VBD>+ }   \n",
    "            conditional perfect:                   {<MD><HV><HVN|BEN|VBN|VBD>+  }   \n",
    "            past continuous passive:               {<BED|BEDZ><BEG><VBN|VBD>+}  \n",
    "            past perfect continuous:               {<HVD><BEN><HVG|BEG|VBG>+}   \n",
    "            past perfect passive:                  {<HVD><BEN><VBN|VBD>+}\n",
    "            present continuous passive:            {<BEM|BER|BEZ><BEG><VBN|VBD>+}   \n",
    "            present perfect continuous:            {<HV|HVZ><BEN><VBG|BEG|HVG>+}    \n",
    "            present perfect passive:               {<HV|HVZ><BEN><VBN|VBD>+}\n",
    "            future indefinite:                     {<MDF><BE|DO|VB|HV>+ }       \n",
    "            conditional indefinite:                {<MD><BE|DO|VB|HV>+  }   \n",
    "            past continuous:                       {<BED|BEDZ><VBG|HVG|BEG>+}           \n",
    "            past perfect:                          {<HVD><BEN|VBN|HVD|HVN>+}\n",
    "            past indefinite passive:               {<BED|BEDZ><VBN|VBD>+}   \n",
    "            present indefinite passive:            {<BEM|BER|BEZ><VBN|VBD>+}            \n",
    "            present continuous:                    {<BEM|BER|BEZ><BEG|VBG|HVG>+}            \n",
    "            present perfect:                       {<HV|HVZ><BEN|HVD|VBN|VBD>+  }       \n",
    "            past indefinite:                       {<DOD><VB|HV|DO>|<BEDZ|BED|HVD|VBN|VBD>+}        \n",
    "            infinitive:                            {<TO><BE|HV|VB>+}\n",
    "            present indefinite:                    {<DO|DOZ><DO|HV|VB>+|<DO|HV|VB|BEZ|DOZ|BER|HVZ|BEM|VBZ>+}    \n",
    "            '''\n",
    "\n",
    "    if len(verb_phrase) > 0:\n",
    "      cp = nltk.RegexpParser(grammar)\n",
    "      result = cp.parse(verb_phrase)\n",
    "    else:\n",
    "      result = []\n",
    "    \n",
    "    tenses_set = set()\n",
    "    for node in result:\n",
    "      if type(node) is nltk.tree.Tree:\n",
    "        tenses_set.add(node.label())\n",
    "    \n",
    "    return tenses_set\n",
    "    \n",
    "  text = word_tokenize(x)\n",
    "  tagged = stanford_tagger.tag(x)\n",
    "  return tense_detect(tagged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document-level tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_document(x):\n",
    "  counts = {}\n",
    "  for s in tokenize.sent_tokenize(x):\n",
    "    if len(s) > 0:\n",
    "      for t in sentence_tense(s):\n",
    "        counts[t] = counts.get(t, 0) + 1\n",
    "    else:\n",
    "      pass\n",
    "  return counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Internet Movie Script Database (IMSDb)](https://imsdb.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsdb_dir = str(Path.cwd().parent.joinpath('data').joinpath('imsdb'))\n",
    "if not os.path.exists(imsdb_dir):\n",
    "  os.makedirs(imsdb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imsdb():\n",
    "    ALL_URL = \"https://imsdb.com/all-scripts.html\"\n",
    "    BASE_URL = \"https://imsdb.com\"\n",
    "    SOURCE = \"imsdb\"\n",
    "\n",
    "    def get_script_from_url(script_url):\n",
    "        text = \"\"\n",
    "\n",
    "        try:\n",
    "            if script_url.endswith('.pdf'):\n",
    "                text = get_pdf_text(script_url, os.path.join(SOURCE, file_name))\n",
    "                return text\n",
    "\n",
    "            if script_url.endswith('.html'):\n",
    "                script_soup = get_soup(\n",
    "                    script_url)\n",
    "                if script_soup == None:\n",
    "                    return text\n",
    "                if len(script_soup.find_all('td', class_=\"scrtext\")) < 1:\n",
    "                    return \"\"\n",
    "                script_text = script_soup.find_all(\n",
    "                    'td', class_=\"scrtext\")[0].pre\n",
    "\n",
    "                if script_text:\n",
    "                    script_text = script_soup.find_all(\n",
    "                        'td', class_=\"scrtext\")[0].pre.pre\n",
    "                    if script_text:\n",
    "                        text = script_text.get_text()\n",
    "\n",
    "                    else:\n",
    "                        script_text = script_soup.find_all(\n",
    "                            'td', class_=\"scrtext\")[0].pre\n",
    "                        text = script_text.get_text()\n",
    "        except Exception as err:\n",
    "            # print(script_url)\n",
    "            # print(err)\n",
    "            text = \"\"\n",
    "\n",
    "        return text\n",
    "\n",
    "    def get_script_url(movie):\n",
    "        script_page_url = movie.contents[0].get('href')\n",
    "        name = movie.contents[0].text\n",
    "        movie_name = script_page_url.split(\"/\")[-1].strip('Script.html')\n",
    "\n",
    "        script_page_soup = get_soup(BASE_URL + urllib.parse.quote(script_page_url))\n",
    "        if script_page_soup == None:\n",
    "            return \"\", name\n",
    "        paras = script_page_soup.find_all('p', align=\"center\")\n",
    "        if len(paras) < 1:\n",
    "            return \"\", \"\"\n",
    "        script_url = paras[0].contents[0].get('href')\n",
    "\n",
    "        return script_url, name\n",
    "\n",
    "    soup = get_soup(ALL_URL)\n",
    "    movielist = soup.find_all('p')\n",
    "\n",
    "    for movie in tqdm(movielist, desc=SOURCE):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            script_url, name = get_script_url(movie)\n",
    "    \n",
    "        if script_url == \"\":\n",
    "            continue\n",
    "        \n",
    "        script_url = BASE_URL + urllib.parse.quote(script_url)\n",
    "        file_name = format_filename(name)\n",
    "\n",
    "        if os.path.exists(os.path.join(imsdb_dir, file_name + '.txt')):\n",
    "            continue\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            text = get_script_from_url(script_url)\n",
    "\n",
    "        if text == \"\" or name == \"\":\n",
    "            continue\n",
    "        \n",
    "        with open(os.path.join(imsdb_dir, file_name + '.txt'), 'w', errors=\"ignore\") as out:\n",
    "            out.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1127 IMSDB scripts.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(imsdb_dir):\n",
    "    fnames = [f for f in os.listdir(imsdb_dir) if f.endswith('.txt')]\n",
    "else:\n",
    "    fnames = []\n",
    "\n",
    "if len(fnames) < 1000:\n",
    "    get_imsdb()\n",
    "    fnames = [f for f in os.listdir(imsdb_dir) if f.endswith('.txt')]\n",
    "\n",
    "print(f'Found {len(fnames)} IMSDB scripts.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens in the directory: 26023895\n",
      "Estimated cost with GPT-3.5-turbo: $104.09558\n",
      "Estimated cost with GPT-4: $3122.8674\n"
     ]
    }
   ],
   "source": [
    "def count_tokens_in_directory(directory_path):\n",
    "    filenames = [os.path.join(directory_path, f) for f in os.listdir(directory_path) if f.endswith('.txt')]\n",
    "    total_tokens = 0\n",
    "    \n",
    "    for filename in filenames:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            tokens = len(text.split())  # A rough approximation\n",
    "            total_tokens += tokens\n",
    "    \n",
    "    return total_tokens\n",
    "\n",
    "# You need to set the cost per token for each model according to your specific OpenAI plan\n",
    "cost_per_token_gpt3_5 = 0.000004\n",
    "cost_per_token_gpt4 = 0.00012\n",
    "\n",
    "total_tokens = count_tokens_in_directory(imsdb_dir)\n",
    "\n",
    "total_cost_gpt3_5 = total_tokens * cost_per_token_gpt3_5\n",
    "total_cost_gpt4 = total_tokens * cost_per_token_gpt4\n",
    "\n",
    "print(f\"Total tokens in the directory: {total_tokens}\")\n",
    "print(f\"Estimated cost with GPT-3.5-turbo: ${total_cost_gpt3_5}\")\n",
    "print(f\"Estimated cost with GPT-4: ${total_cost_gpt4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smuggle stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanza.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a randomly chosen excerpt from a randomly chosen transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Excerpt from Lock-Stock-and-Two-Smoking-Barrels.txt:**\n",
       "\n",
       "Harry, that boy doesn't know his arsehole from his ear-hole, or you\n",
       "\n",
       "from a hoodwink. This bar is mine, and he has nothing to do with it.\n",
       "\n",
       "HATCHET\n",
       "\n",
       "What, and I care? Remember, you do have the luxurious advantage of\n",
       "\n",
       "being able to sustain your son's life.\n",
       "\n",
       "JD\n",
       "\n",
       "And you do have a reputation, so I'll choose my words carefully. But\n",
       "\n",
       "not to put too fine a point on it, fuck yourself, Harry!\n",
       "\n",
       "Barry pulls a kind of mock-scared face and clutches his heart.\n",
       "\n",
       "80"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = np.random.choice(fnames)\n",
    "\n",
    "with open(os.path.join(imsdb_dir, sample), 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [x.strip() for x in lines if len(x.strip()) > 0]\n",
    "\n",
    "    # choose a 10 line snippet at random\n",
    "    start = np.random.randint(0, len(lines) - 10)\n",
    "    snippet = lines[start:start+10]\n",
    "\n",
    "Markdown(f'**Excerpt from {sample}:**\\n\\n' + '\\n\\n'.join(snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatGPT's solution (after some tweaking)!\n",
    "\n",
    "def count_tenses_in_files(filepaths):\n",
    "    df = pd.DataFrame(columns=['filename', 'past_tense', 'future_tense'])\n",
    "\n",
    "    for filepath in filepaths:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "\n",
    "        sentences = sent_tokenize(text)\n",
    "\n",
    "        past_count = 0\n",
    "        future_count = 0\n",
    "\n",
    "        for sentence in sentences:\n",
    "            # Expand contractions for better matching\n",
    "            sentence = re.sub(r\"won't\", \"will not\", sentence)\n",
    "            sentence = re.sub(r\"can't\", \"cannot\", sentence)\n",
    "            sentence = re.sub(r\"i'm\", \"i am\", sentence)\n",
    "            sentence = re.sub(r\"ain't\", \"is not\", sentence)\n",
    "            sentence = re.sub(r\"(\\w+)'ll\", \"\\\\1 will\", sentence)\n",
    "            sentence = re.sub(r\"(\\w+)n't\", \"\\\\1 not\", sentence)\n",
    "            sentence = re.sub(r\"(\\w+)'ve\", \"\\\\1 have\", sentence)\n",
    "            sentence = re.sub(r\"(\\w+)'s\", \"\\\\1 is\", sentence)\n",
    "            sentence = re.sub(r\"(\\w+)'re\", \"\\\\1 are\", sentence)\n",
    "\n",
    "            # Check for future tense patterns\n",
    "            if re.search(r'\\bwill\\b|\\bshall\\b|\\bam going to\\b|\\bwill have\\b|\\bshall have\\b|\\bwill be\\b|\\bshall be\\b|\\b(is|are) going to\\b|\\b(is|are|am) about to\\b|\\b(is|are|am) planning to\\b|\\b(is|are|am) looking forward to\\b', sentence, re.IGNORECASE):\n",
    "                future_count += 1\n",
    "\n",
    "            # Check for past tense patterns\n",
    "            if re.search(r'\\bwas\\b|\\bwere\\b|\\bhad\\b|\\bdid\\b|\\bhad been\\b|\\bwas going to\\b|\\bwere going to\\b|\\bwas supposed to\\b|\\bwere supposed to\\b|\\bwould have\\b|\\bshould have\\b|\\bcould have\\b|\\bmight have\\b|\\bwas planning to\\b|\\bwere planning to\\b|\\bwas looking forward to\\b|\\bwere looking forward to\\b', sentence, re.IGNORECASE):\n",
    "                past_count += 1\n",
    "\n",
    "        df = df.append({'filename': filepath, 'past_tense': past_count, 'future_tense': future_count}, ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dict(d1, d2):\n",
    "  for k in d2:\n",
    "    if k in d1:\n",
    "      d1[k] += d2[k]\n",
    "    else:\n",
    "      d1[k] = d2[k]\n",
    "  return d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test run: validate against The Chair (Season 1, Episodes 1--6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_fname = lambda n: str(Path.cwd().parent.joinpath('data').joinpath('the_chair_s1e' + str(n) + '_transcript.txt'))\n",
    "ref_fname = str(Path.cwd().parent.joinpath('data').joinpath('the_chair_manual_reference_counts.csv'))\n",
    "\n",
    "def get_demo_tenses(fname):\n",
    "    text = open(fname, 'r').read()\n",
    "    tenses = pd.DataFrame.from_dict(tag_document(text), orient='index', columns=['count']).reset_index().rename(columns={'index': 'tense'})\n",
    "\n",
    "    mapping = {'present indefinite': 'Present',\n",
    "            'past indefinite': 'Past',\n",
    "            'conditional indefinite': 'Future',\n",
    "            'infinitive': 'Present'}\n",
    "\n",
    "    tenses['index'] = tenses['tense'].apply(lambda x: mapping[x] if x in mapping else x)\n",
    "    \n",
    "    # drop present tense\n",
    "    tenses = tenses.groupby('index').sum().reset_index().sort_values('count', ascending=False).set_index('index').loc[['Past', 'Future']]\n",
    "    tenses['proportion'] = tenses['count'] / tenses['count'].sum()\n",
    "\n",
    "    return tenses.drop('tense', axis=1).reset_index().rename(columns={'index': 'tense'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Episode</th>\n",
       "      <th>tense</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Future</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Future</td>\n",
       "      <td>0.318182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.565789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Future</td>\n",
       "      <td>0.434211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>Future</td>\n",
       "      <td>0.403846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.765957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>Future</td>\n",
       "      <td>0.234043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>Future</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Episode   tense  proportion\n",
       "0         1    Past    0.769231\n",
       "6         1  Future    0.230769\n",
       "1         2    Past    0.681818\n",
       "7         2  Future    0.318182\n",
       "2         3    Past    0.565789\n",
       "8         3  Future    0.434211\n",
       "3         4    Past    0.596154\n",
       "9         4  Future    0.403846\n",
       "4         5    Past    0.765957\n",
       "10        5  Future    0.234043\n",
       "5         6    Past    0.692308\n",
       "11        6  Future    0.307692"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill in proportions for manual reference counts\n",
    "manual = pd.read_csv(ref_fname)\n",
    "manual['Total'] = manual['Past'] + manual['Future']\n",
    "\n",
    "# convert to proportions\n",
    "manual['Past'] = manual['Past'] / manual['Total']\n",
    "manual['Future'] = manual['Future'] / manual['Total']\n",
    "\n",
    "manual.reset_index(inplace=True)\n",
    "manual['Episode'] = manual['index'] + 1\n",
    "manual.drop(['index', 'Total'], axis=1, inplace=True)\n",
    "\n",
    "manual = manual.melt(var_name='tense', value_name='proportion', id_vars=['Episode'])\n",
    "manual.sort_values(['Episode'], inplace=True)\n",
    "manual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Java command failed : ['/Users/jmanning/opt/anaconda3/envs/prediction-retrodiction/bin/java', '-mx1000m', '-cp', '/Users/jmanning/prediction-retrodiction-paper/data/stanford-postagger.jar', 'edu.stanford.nlp.tagger.maxent.MaxentTagger', '-model', '/Users/jmanning/prediction-retrodiction-paper/data/english-bidirectional-distsim.tagger', '-textFile', '/var/folders/tp/qtzc39jx5w556wl5w3dj21wr0000gn/T/tmppp4qbrsh', '-tokenize', 'false', '-outputFormatOptions', 'keepEmptySentences', '-encoding', 'utf8']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m episodes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39m1\u001b[39m, \u001b[39m7\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tenses \u001b[39m=\u001b[39m [get_demo_tenses(demo_fname(n)) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m episodes]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# add episode labels\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tenses):\n",
      "\u001b[1;32m/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb Cell 20\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m episodes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39m1\u001b[39m, \u001b[39m7\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tenses \u001b[39m=\u001b[39m [get_demo_tenses(demo_fname(n)) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m episodes]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# add episode labels\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tenses):\n",
      "\u001b[1;32m/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb Cell 20\u001b[0m in \u001b[0;36mget_demo_tenses\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_demo_tenses\u001b[39m(fname):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(fname, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mread()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     tenses \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_dict(tag_document(text), orient\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mreset_index()\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mtense\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     mapping \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mpresent indefinite\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mPresent\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mpast indefinite\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mPast\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mconditional indefinite\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mFuture\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39minfinitive\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mPresent\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     tenses[\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m tenses[\u001b[39m'\u001b[39m\u001b[39mtense\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: mapping[x] \u001b[39mif\u001b[39;00m x \u001b[39min\u001b[39;00m mapping \u001b[39melse\u001b[39;00m x)\n",
      "\u001b[1;32m/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb Cell 20\u001b[0m in \u001b[0;36mtag_document\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m tokenize\u001b[39m.\u001b[39msent_tokenize(x):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(s) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m sentence_tense(s):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m       counts[t] \u001b[39m=\u001b[39m counts\u001b[39m.\u001b[39mget(t, \u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb Cell 20\u001b[0m in \u001b[0;36msentence_tense\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m tenses_set\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m text \u001b[39m=\u001b[39m word_tokenize(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m tagged \u001b[39m=\u001b[39m stanford_tagger\u001b[39m.\u001b[39;49mtag(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X43sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tense_detect(tagged)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/nltk/tag/stanford.py:90\u001b[0m, in \u001b[0;36mStanfordTagger.tag\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtag\u001b[39m(\u001b[39mself\u001b[39m, tokens):\n\u001b[1;32m     89\u001b[0m     \u001b[39m# This function should return list of tuple rather than list of list\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtag_sents([tokens]), [])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/nltk/tag/stanford.py:112\u001b[0m, in \u001b[0;36mStanfordTagger.tag_sents\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    109\u001b[0m _input_fh\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    111\u001b[0m \u001b[39m# Run the tagger and get the output\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m stanpos_output, _stderr \u001b[39m=\u001b[39m java(\n\u001b[1;32m    113\u001b[0m     cmd, classpath\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stanford_jar, stdout\u001b[39m=\u001b[39;49mPIPE, stderr\u001b[39m=\u001b[39;49mPIPE\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    115\u001b[0m stanpos_output \u001b[39m=\u001b[39m stanpos_output\u001b[39m.\u001b[39mdecode(encoding)\n\u001b[1;32m    117\u001b[0m \u001b[39m# Delete the temporary file\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/nltk/internals.py:146\u001b[0m, in \u001b[0;36mjava\u001b[0;34m(cmd, classpath, stdin, stdout, stderr, blocking)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m p\u001b[39m.\u001b[39mreturncode \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    145\u001b[0m     \u001b[39mprint\u001b[39m(_decode_stdoutdata(stderr))\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mJava command failed : \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(cmd))\n\u001b[1;32m    148\u001b[0m \u001b[39mreturn\u001b[39;00m (stdout, stderr)\n",
      "\u001b[0;31mOSError\u001b[0m: Java command failed : ['/Users/jmanning/opt/anaconda3/envs/prediction-retrodiction/bin/java', '-mx1000m', '-cp', '/Users/jmanning/prediction-retrodiction-paper/data/stanford-postagger.jar', 'edu.stanford.nlp.tagger.maxent.MaxentTagger', '-model', '/Users/jmanning/prediction-retrodiction-paper/data/english-bidirectional-distsim.tagger', '-textFile', '/var/folders/tp/qtzc39jx5w556wl5w3dj21wr0000gn/T/tmppp4qbrsh', '-tokenize', 'false', '-outputFormatOptions', 'keepEmptySentences', '-encoding', 'utf8']"
     ]
    }
   ],
   "source": [
    "episodes = np.arange(1, 7, dtype=int)\n",
    "tenses = [get_demo_tenses(demo_fname(n)) for n in episodes]\n",
    "\n",
    "# add episode labels\n",
    "for i, t in enumerate(tenses):\n",
    "    t['episode'] = episodes[i]\n",
    "\n",
    "# combine into one dataframe\n",
    "tenses = pd.concat(tenses, ignore_index=True)\n",
    "\n",
    "sns.barplot(tenses, x='tense', y='proportion', hue='episode', palette='viridis')\n",
    "plt.xlabel('Tense', fontsize=14)\n",
    "plt.ylabel('Proportion of references', fontsize=14)\n",
    "plt.legend(title='Episode', loc='upper right')\n",
    "sns.despine(top=True, right=True)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "# add manual reference counts as dotted lines\n",
    "for i, p in enumerate(ax.patches):\n",
    "    x = [p.get_x(), p.get_x() + p.get_width()]  # X-coordinate of the center of the bar\n",
    "    y = manual.iloc[i]['proportion']\n",
    "    ax.plot(x, [y, y], linestyle='dotted', linewidth=2, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jmanning/opt/anaconda3/envs/prediction-retrodiction/bin/java\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('which java')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Java command failed : ['/Users/jmanning/opt/anaconda3/envs/prediction-retrodiction/bin/java', '-mx1000m', '-cp', '/Users/jmanning/prediction-retrodiction-paper/data/stanford-postagger.jar', 'edu.stanford.nlp.tagger.maxent.MaxentTagger', '-model', '/Users/jmanning/prediction-retrodiction-paper/data/english-bidirectional-distsim.tagger', '-textFile', '/var/folders/tp/qtzc39jx5w556wl5w3dj21wr0000gn/T/tmpnv4bm30d', '-tokenize', 'false', '-outputFormatOptions', 'keepEmptySentences', '-encoding', 'utf8']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jmanning/prediction-retrodiction-paper/code/meta-analysis.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m stanford_tagger\u001b[39m.\u001b[39;49mtag(\u001b[39m'\u001b[39;49m\u001b[39mThis is a test\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49msplit())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/nltk/tag/stanford.py:90\u001b[0m, in \u001b[0;36mStanfordTagger.tag\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtag\u001b[39m(\u001b[39mself\u001b[39m, tokens):\n\u001b[1;32m     89\u001b[0m     \u001b[39m# This function should return list of tuple rather than list of list\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtag_sents([tokens]), [])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/nltk/tag/stanford.py:112\u001b[0m, in \u001b[0;36mStanfordTagger.tag_sents\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    109\u001b[0m _input_fh\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    111\u001b[0m \u001b[39m# Run the tagger and get the output\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m stanpos_output, _stderr \u001b[39m=\u001b[39m java(\n\u001b[1;32m    113\u001b[0m     cmd, classpath\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stanford_jar, stdout\u001b[39m=\u001b[39;49mPIPE, stderr\u001b[39m=\u001b[39;49mPIPE\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    115\u001b[0m stanpos_output \u001b[39m=\u001b[39m stanpos_output\u001b[39m.\u001b[39mdecode(encoding)\n\u001b[1;32m    117\u001b[0m \u001b[39m# Delete the temporary file\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prediction-retrodiction/lib/python3.10/site-packages/nltk/internals.py:146\u001b[0m, in \u001b[0;36mjava\u001b[0;34m(cmd, classpath, stdin, stdout, stderr, blocking)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m p\u001b[39m.\u001b[39mreturncode \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    145\u001b[0m     \u001b[39mprint\u001b[39m(_decode_stdoutdata(stderr))\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mJava command failed : \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(cmd))\n\u001b[1;32m    148\u001b[0m \u001b[39mreturn\u001b[39;00m (stdout, stderr)\n",
      "\u001b[0;31mOSError\u001b[0m: Java command failed : ['/Users/jmanning/opt/anaconda3/envs/prediction-retrodiction/bin/java', '-mx1000m', '-cp', '/Users/jmanning/prediction-retrodiction-paper/data/stanford-postagger.jar', 'edu.stanford.nlp.tagger.maxent.MaxentTagger', '-model', '/Users/jmanning/prediction-retrodiction-paper/data/english-bidirectional-distsim.tagger', '-textFile', '/var/folders/tp/qtzc39jx5w556wl5w3dj21wr0000gn/T/tmpnv4bm30d', '-tokenize', 'false', '-outputFormatOptions', 'keepEmptySentences', '-encoding', 'utf8']"
     ]
    }
   ],
   "source": [
    "stanford_tagger.tag('This is a test'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1127/1127 [5:02:25<00:00, 16.10s/it]   \n"
     ]
    }
   ],
   "source": [
    "all_tenses = []\n",
    "for f in tqdm(fnames):\n",
    "  tenses = {}\n",
    "  dialogue = get_dialogue(os.path.join(imsdb_dir, f))\n",
    "\n",
    "  if dialogue is None:\n",
    "    continue\n",
    "\n",
    "  for d in dialogue['Character_dialogue'].values:\n",
    "    d = d.strip()\n",
    "    if len(d) > 0:\n",
    "      tenses = add_dict(tenses, tag_document(d))\n",
    "  \n",
    "  all_tenses.append((f[:-4], tenses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tenses2df(all_tenses):\n",
    "    keys = set()\n",
    "    for t in all_tenses:\n",
    "        keys = keys.union(set(t[1].keys()))\n",
    "\n",
    "    df = pd.DataFrame(columns=list(keys), index=pd.Index([t[0] for t in all_tenses], name='Film'))\n",
    "    for m, t in all_tenses:\n",
    "        for k in t:\n",
    "            df.loc[m, k] = t[k]\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    df['Total'] = df.sum(axis=1)\n",
    "\n",
    "    for k in keys:\n",
    "        df[k] = df[k] / df['Total']\n",
    "    df.drop('Total', axis=1, inplace=True)\n",
    "    return df.dropna(how='all', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conditional indefinite</th>\n",
       "      <th>present indefinite</th>\n",
       "      <th>past indefinite</th>\n",
       "      <th>infinitive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Film</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Midnight-Express</th>\n",
       "      <td>0.061722</td>\n",
       "      <td>0.542012</td>\n",
       "      <td>0.272303</td>\n",
       "      <td>0.123963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Big-Eyes</th>\n",
       "      <td>0.076048</td>\n",
       "      <td>0.555096</td>\n",
       "      <td>0.284532</td>\n",
       "      <td>0.084325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Warrior</th>\n",
       "      <td>0.069118</td>\n",
       "      <td>0.520588</td>\n",
       "      <td>0.272794</td>\n",
       "      <td>0.137500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hellraiser-Hellseeker</th>\n",
       "      <td>0.088144</td>\n",
       "      <td>0.512725</td>\n",
       "      <td>0.278088</td>\n",
       "      <td>0.121043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hannah-and-Her-Sisters</th>\n",
       "      <td>0.087430</td>\n",
       "      <td>0.511512</td>\n",
       "      <td>0.270068</td>\n",
       "      <td>0.130989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smashed</th>\n",
       "      <td>0.125676</td>\n",
       "      <td>0.448649</td>\n",
       "      <td>0.283108</td>\n",
       "      <td>0.142568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wild-Wild-West</th>\n",
       "      <td>0.093483</td>\n",
       "      <td>0.529380</td>\n",
       "      <td>0.240385</td>\n",
       "      <td>0.136752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sessions-The</th>\n",
       "      <td>0.115983</td>\n",
       "      <td>0.505658</td>\n",
       "      <td>0.239745</td>\n",
       "      <td>0.138614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Silver-Linings-Playbook</th>\n",
       "      <td>0.107998</td>\n",
       "      <td>0.481406</td>\n",
       "      <td>0.280183</td>\n",
       "      <td>0.130413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four-Rooms</th>\n",
       "      <td>0.090014</td>\n",
       "      <td>0.557900</td>\n",
       "      <td>0.218472</td>\n",
       "      <td>0.133615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         conditional indefinite  present indefinite   \n",
       "Film                                                                  \n",
       "Midnight-Express                       0.061722            0.542012  \\\n",
       "Big-Eyes                               0.076048            0.555096   \n",
       "Warrior                                0.069118            0.520588   \n",
       "Hellraiser-Hellseeker                  0.088144            0.512725   \n",
       "Hannah-and-Her-Sisters                 0.087430            0.511512   \n",
       "...                                         ...                 ...   \n",
       "Smashed                                0.125676            0.448649   \n",
       "Wild-Wild-West                         0.093483            0.529380   \n",
       "Sessions-The                           0.115983            0.505658   \n",
       "Silver-Linings-Playbook                0.107998            0.481406   \n",
       "Four-Rooms                             0.090014            0.557900   \n",
       "\n",
       "                         past indefinite  infinitive  \n",
       "Film                                                  \n",
       "Midnight-Express                0.272303    0.123963  \n",
       "Big-Eyes                        0.284532    0.084325  \n",
       "Warrior                         0.272794    0.137500  \n",
       "Hellraiser-Hellseeker           0.278088    0.121043  \n",
       "Hannah-and-Her-Sisters          0.270068    0.130989  \n",
       "...                                  ...         ...  \n",
       "Smashed                         0.283108    0.142568  \n",
       "Wild-Wild-West                  0.240385    0.136752  \n",
       "Sessions-The                    0.239745    0.138614  \n",
       "Silver-Linings-Playbook         0.280183    0.130413  \n",
       "Four-Rooms                      0.218472    0.133615  \n",
       "\n",
       "[998 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tenses2df(all_tenses)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Proportion', ylabel='Tense'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=df.reset_index().melt(id_vars='Film', var_name='Tense', value_name='Proportion'), y='Tense', x='Proportion', orient='h')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prediction-retrodiction",
   "language": "python",
   "name": "prediction-retrodiction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
