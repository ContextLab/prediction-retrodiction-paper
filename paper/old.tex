\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[font=small,labelfont=bf]{caption}
\usepackage{geometry}
\usepackage{natbib}
\usepackage{pxfonts}
\usepackage{graphicx}
% \graphicspath{ {./figures-low/} }
% \DeclareGraphicsExtensions{.png,.pdf}
\graphicspath{ {./figures-default/} }
\usepackage{newfloat}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{lineno}
\usepackage{placeins}
\usepackage{authblk}
\usepackage{textcomp}
\usepackage{listings}
\bibliographystyle{apalike}

\doublespacing
\linenumbers

\title{\Large Characters' psychological arrows of time drive temporal asymmetries in observers' inferrences about past and future narrative events}
\author[1]{Xinming Xu}
\author[2]{Ziyan Zhu}
\author[1, $\star$]{Jeremy R. Manning}
\affil[1]{Dartmouth College, Hanover, NH, USA}
\affil[2]{Peking University, Beijing, China}
\affil[$\star$]{Address correspondence to jeremy.r.manning@dartmouth.edu}

\newcommand{\stimDescription}{S1} % table
\newcommand{\segments}{S1} % figure
\newcommand{\events}{S2} %
\newcommand{\references}{S3}

\begin{document}

\maketitle

\begin{abstract} {\footnotesize
  How much can we infer about the past and future, given our current knowledge and observations in the present?  Inferences about our own lives are time-asymmetric: we are better able to infer the past than the future, since we remember our past but not our future.  The asymmetry in our memories is known as the \textit{psychological arrow of time}.  But when both the past and future are unexperienced and unobserved, for example when we make inferences about \textit{other} people's lives, are our inferences about the past and future time-symmetric or asymmetric?  To study these questions, we had participants view segments of a character-driven television drama.  They used free-form responses to guess at what would happen just before or just after each just-watched segment.  We found that participants' inferences were time-asymmetric, in that they inferred past events more accurately than future events after controlling for their exposure to past and future events in the narrative.  This asymmetry was driven by \textit{characters'} biases in conversational references to their own pasts.  Our work reveals a temporal asymmetry in how observations of other peoplesâ€™ behaviors can inform us about the past and future.

\textbf{Keywords: episodic memory, prediction, retrodiction, narratives, conversation}}

\end{abstract}

\section*{Introduction}

What we experience in the current moment tells us about \textit{now}-- but what does it tell us about the past or future?  One way of examining this question is to consider highly simplified scenarios that are artificially constructed in the laboratory.  At one extreme, for fully observable deterministic sequences, observing any part of the sequence provides sufficient information to reconstruct the entire past and future history of the stimulus.  For example, if we observe the partial sequence ``5, 6, 7, 8, 9, 10,'' we might reasonably guess that the just-preceding number was 4, and the just-proceeding number will be 11.  If we were given additional information through further observations, or by being told about the rules for generating the sequence, our confidence would increase.  Eventually, with more observations or more knowledge about the underlying rules, our uncertainty might approach zero.  At another extreme, for purely random sequences, observing the current state provides no information about the past or future.

The statistical learning literature~\citep{SchaTurk15, Hass17, MaheEtal22} has tended to focus on manufactured scenarios between these two extremes, whereby participants experience structured (but not fully deterministic) sequences.  Often the sequences encountered in this domain are Markov processes, whereby (in the simplest framing, as in first-order Markov processes) each element of the sequence is solely dependent on the immediately preceding element, plus some additional noise~\citep{McNeEtal06, CuniEtal09, FurlEtal11, DaikEtal14, DaikEtal15, KoelEtal16, JonePash07, TummEtal16}.  In the typical setup, participants are instructed to adjust their behaviors or to form explicit predictions about what will come next, given their observations up to that point.  In some studies, participants are also asked to generate inferences about the unobserved past (i.e., what came \textit{earlier}) in a sequence, prior to their first observation~\citep{JonePash07}.

Markov sequences are, by definition, symmetric in time: after learning the ``rules'' (i.e., transition probabilities) that govern how the sequences are generated, observing any part of the sequence provides equal information about its past and future states~\citep{Cove94, BialEtal01, ElliEtal09}.  By contrast, real-world experiences are often asymmetric, since our memories provide us with information about our past experiences but not our yet-to-be-experienced future.  This memory-driven asymmetry in our knowledge is known as the \textit{psychological arrow of time}~\citep[e.g.,][]{Hawk85}.  Although the notion of the psychological arrow of time helps to formalize why we know more about our \textit{own} past than our future, how generally does this hold?  In real-world situations where we are \textit{equally} ignorant of the past and future, as for \textit{other} people's lives where we lack memories of the relevant past, is our knowledge about the past and future symmetric or asymmetric (Fig.~\ref{fig:intro1})?  For example, imagine that you are meeting a stranger for the first time.  Would you be able to more accurately or easily form inferences about what had happened in their past versus their future~\citep{TamiThor18, KostSaxe13}?  Or suppose you started watching a movie partway through.  Again, given your observations in the present, would your guesses about what had happened before you started watching be more (or less) accurate than your guesses about what will happen next?  In general, when the past and future are \textit{both} unobserved, are we better at inferring the past or the future in real-world settings?

\begin{figure}[tp]
  \centering
  \includegraphics[width=\textwidth]{intro1}
  \caption{\textbf{Retrodiction, retrospection, and prediction.} In one's own life, one may draw on memory to retrospect (i.e., review or re-evaluate) the past or predict the future.  This process is time-asymmetric, since our own past is (typically) observed whereas our future is not.  When we make inferences about \textit{other} people's lives, however, we often have uncertainty about both their past and future, since we may have observed neither.  We may \textit{retrodict} the unobserved past and predict the unobserved future of other people's lives.}
  \label{fig:intro1}
\end{figure}

If we hope to connect prior work on statistical learning tasks that employ sequences generated using relatively simple rules with the sorts of inferences we make in everyday life, several considerations apply.  One set of considerations concerns how similar the underlying neurocognitive processes are when we encounter simple sequences in the laboratory versus more complex sequences in our real-world experiences.  In other words, if our day-to-day experiences violate the Markov assumption by displaying interactions between temporally separated occurrences or events, does this change anything meaningful in terms of how our brains process, respond to, leverage, or remember those experiences?  Another set of considerations concerns how similar the experiences themselves are.  For example, to what extent are real-world experiences deterministic versus stochastic?  To what extent are real-world experiences structured versus random?  And to what extent do real-world experiences satisfy the Markov assumption?  Narrative stimuli, such as stories and movies, can provide a useful testbed for exploring several of these questions.

Although narratives are unlikely to be confused with one's own experiences, narratives are most compelling when they mirror some of the structure of real-world experiences.  Character behaviors and interactions are often designed in a way that helps the audience connect with or relate to the characters.  Events in narratives also unfold in ways that are intended to build rapport or engagement with the audience.  This might be accomplished by having events follow a believable structure that is reminiscent of real-world experiences, or by designing the audience's experiences in ways that communicate clear ``rules'' or ``features'' that help to immerse the audience in the narrative's universe.  These same aspects of narratives that authors use to drive engagement with characters and events can lead narratives to replicate some core aspects of real-world experiences that are typically lost or overlooked in traditional sequence learning paradigms.  Narratives can drive the audience to form a theory of mind of the characters~\citep{TamiThor18}, or to build situation models~\citep{RangRitc12, BoweEtal79} of the narrative's universe.  Events in narratives may unfold in a consistent or logical way, but they also often incorporate stochastic elements and events that violate the Markov assumption, such as when the consequences of an action or event early on in the narrative are realized much later on.

If inferences formed for real-world events and narratives are like inferences for the Markov sequences often studied in the statistical learning literature, people should be equally adept at inferring the past and future.  Alternatively, perhaps important differences between naturalistic versus Markov sequences might lead to an advantage for the past or future.  In the above examples of meeting a stranger or starting a movie partway through, perhaps the \textit{stranger's} (or characters') asymmetric knowledge about their own pasts might influence their observable behaviors.  Despite the past and future being equally unknown to \textit{you} prior to the current moment, other people's asymmetric knowledge about their own observed pasts might give you an advantage at inferring the unobserved past versus future~\citep{PillEtal15}.  Similarly, if a conversation you joined partway through was focused on planning a future event, that might advantage your inferences of the future (versus the past).  In general, what sorts of behaviors might reflect other individuals' asymmetric knowledge about their past, or their plans for the future?  Are there particular types of information that people are especially sensitive to, or that are particularly informative or useful?   Could we quantify or characterize those factors in a systematic way?  Or might they be too subtle or nuanced to formally define?

At a high level, these questions all relate to how people form inferences about the past and future, given their observations.  But these questions also often relate to issues of temporal symmetry-- i.e., whether inferring the past is \textit{easier} or \textit{harder} than inferring the future.  Presumably, the overall amount of information present will determine something about how \textit{much} may be inferred before or after the present.  In other words, a tiny amount of information, or an unreliable observation, and so on, will provide less insight into other moments than a large amount of reliable information.  In a sense, this is trivial: more information is ``better'' if our goal is to form inferences.  However, \textit{controlling} for the amount of information, can we learn anything meaningful about inherent biases in either our memory systems (including related systems for forming inferences) or in the sort of information we are likely to encounter?  Studying these questions often entails comparing inferences about the past versus the future by characterizing any apparent symmetries or asymmetries.

We designed a naturalistic paradigm for exposing participants to scenarios where the past and future were equally unobserved.  We asked our participants to watch a series of movie segments drawn from a character-driven dramatic television show.  Across the conditions and trials in the experiment, we carefully controlled for how much of the past or future of the narrative the participants had experienced prior to viewing the target segment.  We then asked the participants to guess about what might have happened before the target segment (\textit{retrodiction}), what might happen after the target segment (\textit{prediction}), or to recount what they had observed in the target segment itself (\textit{recall}).  We used manual annotations and sentence-level natural language processing models to characterize participants' responses.

\section*{Results}
Participants in our study ($n = 36$) watched segments from two storylines, drawn from the CBS television show, \textit{Why Women Kill}.  Each storyline comprised 11 segments (mean duration: 2.05~min; range: 0.97--3.87~min, Table \stimDescription).  We asked participants to use free-form (typed) text responses to retrodict what had happened prior to a just-watched segment, predict what would happen next, or recall what they had just watched. We referred to the to-be-retrodicted, to-be-predicted, or to-be-recalled segment as the target segment for each response. We systematically varied whether participants watched the segments in forward or reverse chronological order, and how many segments preceded or proceeded the target segment they had seen prior to making a response (Fig.~\ref{fig:method}, \textit{Task design}).

\begin{figure}[tp]
  \centering
  \includegraphics[width=\textwidth]{methods}
  \caption{\textbf{Task overview.} Participants watched segments of two storylines from the television series \textit{Why Women Kill}.  They made free-form text responses to either retrodict what had happened in the previous segment, predict what would happen in the next segment, or recall what happened in the just-watched segment. Across four counterbalanced sequences, we systematically varied whether participants watched the segments in forward or reverse chronological order, whether (or not) responses were cued using the main characters in the target segment, and which other segments participants had watched prior to making a response.  For each segment, we collected several retrodiction, prediction, and/or recall responses across different experimental conditions.}
  \label{fig:method}
\end{figure}


We asked participants to generate four types of responses after watching each video segment: uncued responses, character-cued responses, updated responses, and recalls (Fig.~\ref{fig:method}, \textit{Data overview}).  To generate \textit{uncued} responses, we asked participants to either retrodict (uncued retrodiction; \textit{u-R}) what happened shortly before or predict (uncued prediction; \textit{u-P}) what happened shortly after the just-watched segment.  To generate \textit{character-cued} responses, we asked participants to retrodict (character-cued retrodiction; \textit{c-R}) or predict (character-cued prediction; \textit{c-P}) what came before or after the just-watched segment, but we provided additional information to the participant about which character(s) would be present in the target (to-be-retrodicted or to-be-predicted) segment.  We hypothesized that character-cued responses should be more accurate than uncued responses, to the extent that participants incorporate the character information we provided to them into their retrodictions and predictions.  To generate updated responses, we asked participants to watch an additional segment that came just prior to or just after the target segment, and then to update their retrodiction (\textit{c-RP}) or prediction (\textit{c-PR}) about the target segment. Results on updated responses are not reported in this paper. Finally, we also asked participants to \textit{recall} what happened in the just-watched segment.  We labeled these responses according to which other segments participants had watched prior to the just-watched target.  Retrodiction-matched recall (\textit{re(R)}) responses were made during the retrodiction sequences (B1 and B2; Fig.~\ref{fig:method}), whereas prediction-matched recall (\textit{re(P)}) responses were made during the prediction sequences (A1 and A2).  Participants' recalls provided us with a benchmark for examining information about the participants' experiences and memories, without asking the participants to explicitly speculate about the unobserved.



For each retrodiction and prediction, participants were asked to generate at least one, and not more than three, responses that constituted ``the sorts of things [the participant would] expect to have remembered if [they] had watched the [target] segment.''  They were asked to generate multiple responses only if those additional responses were (in their judgement) of equal likelihood to occur.  On average, participants generated 1.08 responses per prompt; therefore we chose to consider only participants' first (``most probable'' or ``most important'') responses to each prompt.  We also discarded a small number ($n = 20$) of character-cued responses that did not contain references to all cued characters, along with one additional response due to the participant's misunderstanding of the task instructions during that trial.  We carried out our analyses on the remaining 2084 retrodiction, prediction, and recall responses.

\begin{figure}[tp]
  \centering
  \includegraphics[width=0.80\textwidth]{results1}
  \caption{\textbf{Retrodiction, prediction, and recall performance by experimental condition.} \textbf{A.  Methods schematic.}  For each retrodiction, prediction, and recall response, we calculated the hit rate for events in the target segment, the response precision (see \textit{Methods}), and the response convergence across participants (see \textit{Methods}).  \textbf{B. Target event hit rate.} Mean proportions of target events that were contained in participants' responses, for each response type, averaged across target segments.  \textbf{C. Response precision.}  Mean precisions of participants' responses, for each response type, averaged across target segments.  The horizontal lines denote the mean pairwise semantic similarities (see \textit{Methods}) across recall responses (re(R): orange; re(P): blue).  \textbf{D. Response convergence.}  Mean (across-participant) convergence of participants' responses, for each response type, averaged across target segments.  All panels: error bars denote bootstrapped 95\% confidence intervals.  Asterisks indicate significance in the (generalized) linear mixed models: * denotes $p < 0.05$ and ** denotes $p < 0.01$.}
  \label{fig:result1}
\end{figure}
 
We used two general approaches to assess the quality of participants' responses (see \textit{Methods}, Fig.~\ref{fig:result1}A).  One approach entailed manually annotating events in the video and counting the number of matched events in participants' responses.  We identified a total of 117 unique events reflected across the 22 video segments (range: 3--9 per segment; see \textit{Methods}, Table \stimDescription).  We assigned one ``point'' to each of these video events.  We also identified 23 additional events in participants' responses that were either summaries of several events or that were partial matches to the manually identified video events.  We assigned 0.5 point to each of these additional events.  This point system enabled us to compute the numbers and proportions (\textit{hit rates}) of correctly retrodicted, predicted, and recalled events contained in each response.  Our second approach entailed using a natural language processing model~\citep{CerEtal18} to embed annotations and responses in a 512-dimensional feature space.  This approach was designed to capture conceptual overlap between responses that were not necessarily tied to specific events.  To quantify this conceptual overlap, we computed the similarities between the embeddings of different sets of responses.  Following \cite{HeusEtal21}, we defined the \textit{precision} of each participants' retrodictions or predictions about a given segment as the median cosine similarities between the embeddings of (a) the participant's retrodiction or prediction response for the given segment and (b) each \textit{other} participant's recalls of the same segment.  In other words, precision is designed to measure the extent to which retrodictions and predictions captured the conceptual content that (other) participants remembered.  We also developed a related measure, which we call \textit{convergence}, to characterize response similarities across participants.  In particular, we defined convergence as the mean cosine similarity between the embeddings of a participant's responses to a given target segment and all other participants' responses (of the same type) to the same segment.  We analyzed the data using generalized linear mixed models, with participant and stimulus (e.g., target segment) identities as crossed random effects (see \textit{Methods}).

First we sought to validate a main effect of response type (i.e., uncued responses, character-cued responses, and recalls), irrespective of the temporal direction (retrodiction versus prediction).  Across these three types of responses, participants have access to increasing amounts of information about the target segment.  Therefore, across these response types, we hypothesized that participants' responses should become both more accurate and more convergent across individuals.  Consistent with this hypothesis, participants' character-cued retrodictions and predictions were associated with higher target event hit rates than uncued retrodictions and predictions (odds ratio (OR): 2.65, $Z = 4.24$, $p < 0.001$, 95\% confidence interval (CI): 1.69 to 4.16; Fig.~\ref{fig:result1}B).  These character-cued responses were also more precise ($b = 0.13$, $t(18.1) = 9.43$, $p < 0.001$, CI: 0.10 to 0.16; Fig.~\ref{fig:result1}C) and convergent across individuals ($b = 0.11$, $t(18.6) = 6.21$, $p < 0.001$, CI: 0.07 to 0.15; Fig.~\ref{fig:result1}D).   Relative to character-cued responses, participants' recalls showed higher target event hit rates (OR = 21.83, $Z = 10.61$, $p < 0.001$, CI: 12.35 to 38.59) and more convergence across individuals ($b = 0.20$, $t(19.4) = 9.10$, $p < 0.001$, CI: 0.16 to 0.25). These results are consistent with the common-sense notion that access to more information about a target segment yields better performance (i.e., higher hit rates, precision, and convergence across individuals).

Next we carried out a series of analyses specifically aimed at characterizing temporal direction effects--- i.e, the relative quality of retrodictions versus predictions across different types of responses.  We hoped that these analyses might provide insights into our central question about whether the present is equally informative about the past and future.  Across both uncued and character-cued responses (Fig.~\ref{fig:method}), retrodictions had numerically higher hit rates than predictions (Fig.~\ref{fig:result1}B).  However, these differences were only statistically reliable for character-cued responses (uncued responses: OR = 1.17, $Z = 0.35$, $p = 0.73$, CI: 0.47 to 2.92; character-cued responses: OR = 1.93, $Z = 2.15$, $p = 0.03$, CI: 1.06 to 3.52).  We observed a similar pattern of results for the precisions of participants' responses (Fig.~\ref{fig:result1}C).  Specifically, their responses tended to be numerically more precise for retrodictions versus predictions, but the differences were only statistically reliable for character-cued responses (uncued responses: $b = 0.03$, $t(20.9) = 1.09$, $p = 0.29$, CI: -0.03 to 0.10; character-cued responses: $b = 0.06$, $t(20.8) = 3.01$, $p = 0.007$, CI: 0.02 to 0.11).  We also consistently observed numerically higher convergence across participants for retrodictions versus predictions (Fig.~\ref{fig:result1}D), but neither of these differences were statistically reliable (uncued responses: $b = 0.03$, $t(17.9) = 0.75$, $p = 0.46$, CI: -0.05 to 0.11; character-cued responses: $b = 0.04$, $t(17.4) = 1.46$, $p = 0.16$, CI: -0.02 to 0.09).  Because the retrodiction versus prediction performance differences we observed were only statistically reliable when participants were cued with the target segments' characters, this suggests that information about the unobserved past versus the unobserved future may differently affect retrodictions versus predictions.  Taken together, these results suggest that participants are generally better at making retrodictions than predictions.  We also verified that this was not solely a consequence of how participants' memory performance might have been affected by watching different segments (or making different responses to other segments) across conditions by comparing recall responses in the retrodiction-matched recall (\textit{re(R)}) and prediction-matched recall (\textit{re(P)}) conditions.  Recall performance was similar in both conditions (target event hit rate: OR = 1.12, $Z = 1.07$, $p = 0.29$, CI: 0.91 to 1.39; convergence: $b = 0.03$, $t(19.3) = 1.89$, $p = 0.07$, CI: 0.00 to 0.07).

\begin{figure}[tp]
  \centering
  \includegraphics[width=\textwidth]{results2}
  \caption{\textbf{Retrodictions and predictions of temporally near and distant events.}  \textbf{A. Illustration of annotation approach.}  For each uncued retrodiction and prediction response, we calculated the number of (retrodicted or predicted) events as a function of temporal distance from the target segment, or \textit{lag}.  Onscreen (explicit) events are tagged using integer-valued lags, whereas offscreen (implicit) events are tagged using half-step lags ($\pm 0.5$, $\pm 1.5$, etc.).  \textbf{B. Number of events hit in participants' uncued retrodictions and predictions for each event type.}  Here we separated events we identified in participants' responses according to whether they occurred in the target segment (lags of $\pm 1$), during the interval between the target segment and the just-watched segment (lags of $\pm 0.5$), at longer temporal distances ($|\mathrm{lag}| > 1$), or were incorrect (unmatched with any past or future events in the narrative).  The counts displayed in the panel are averaged across just-watched segments.  \textbf{C. Number of events hit as a function of temporal distance.}  Here the (across-segment) mean numbers of events hit in participants' uncued retrodictions (orange) and predictions (blue) are displayed as a function of temporal distance to the just-watched segment (lag).  Error bars denote bootstrapped 95\% confidence intervals.  Colors denote temporal direction (orange: past; blue: future) and distance (darker shading: onscreen events from segments adjacent to the target segment; lighter shading: offscreen events).}
  \label{fig:result2}
\end{figure}

The above analyses were focused solely on the target segment (i.e., retrodiction of segment $i - 1$ after watching segments $i...11$, or prediction of segment $i + 1$ after watching segments $1...i$).  We wondered whether participants' responses might also contain longer-range information about preceding or proceeding events.  In order to carry out this analysis properly, we reasoned that participants might reference past or future events that were \textit{implied} to have occurred offscreen, but not explicitly shown onscreen.  For example, a character in location A during one scene might appear in location B during the immediately following scene.  Although it wasn't shown onscreen, we can infer that the character traveled between locations A and B sometime between the time intervals separating the scenes~\citep{Bord08}.  In all, we manually identified a set of 74 \textit{implicit} offscreen events that were implied to have occurred given what was (explicitly) depicted onscreen (Fig.~\ref{fig:result2}A), plus one additional partial event and one additional summary event.  We defined the just-watched segment as having a \textit{lag} of 0.  We assigned the target segment of a participant's retrodiction or prediction (i.e., the immediately preceding or proceeding segment) a lag of -1 or +1, respectively.  The segment following the next was assigned a lag of 2, and so on.  We tagged offscreen events using half steps.  For example, an offscreen event that occurred after the prior segment but before the just-watched segment would be assigned a lag of -0.5.

Because there is no ``ground truth'' number of offscreen events, we could not compute the hit rates for offscreen events.  Instead, we counted up the absolute \textit{number} of retrodicted or predicted events as a function of lag.  In other words, given that the participant had just watched segment $i$, we asked how many events from segment $i + lag$ they retrodicted or predicted, on average, given that they were aiming to retrodict or predict events at lags of $\pm 1$.  We also counted the numbers of \textit{unmatched} events in participants' responses that did not correspond to any events in the relevant segments of the narrative.  We focused specifically on \textit{uncued} retrodictions and predictions, which we hypothesized would provide the cleanest characterizations of participants' initial estimates of the unobserved past and future (i.e., without potential biases introduced by additional character information, as in the character-cued responses).  The numbers of uncued retrodicted and predicted target (lag = $\pm 1$) events were not reliably different (OR = 0.92, $Z = -0.15$, $p = 0.88$, CI: 0.30 to 2.84).  In other words, uncued retrodictions and predictions over short timescales did not exhibit reliable asymmetries.  However, when retrodicting, participants mentioned events from the distant past ($\mathrm{lag} < -1$) more often than participants predicted events from the distant future ($\mathrm{lag} > 1$; OR = 9.10, $Z = 3.80$, $p < 0.001$, CI: 2.92 to 28.39; Fig.~\ref{fig:result2}B, C; for results from the character-cued conditions, see Fig.~\events).  Despite this asymmetry in the accuracies of participants' long-range retrodictions versus predictions, there were no reliable differences in the \textit{numbers} of uncued retrodicted versus predicted events (across all lags; OR = 1.05, $Z = 0.75$, $p = 0.45$, CI: 0.93 to 1.18).  Nor did we find any reliable differences in the numbers of offscreen events immediately before or after the just-watched segment ($lag = \pm 0.5$; OR = 0.75, $Z = -0.36$, $p = 0.72$, CI: 0.15 to 3.59).  The apparent discrepancy between participants' asymmetric accuracy but symmetric event counts was due to participants' tendencies to reference ``unmatched'' events (i.e., events that did not correspond to any explicit or implicit event in the story) more in their predictions than retrodictions (OR = 0.36, $Z = -4.53$, $p < 0.001$, CI: 0.23 to 0.56).  We confirmed that the retrodiction advantage held when controlling for absolute lag (OR = 34.31, $Z = 3.28$, $p = 0.001$, CI: 4.16 to 283.20), for onscreen events alone (OR = 47.54, $Z = 3.74$, $p < 0.001$, CI: 6.27 to 360.60), and marginally for offscreen events alone (OR = 24.76, $Z = 1.71$, $p = 0.09$, CI: 0.63 to 975.27).  Taken together, these analyses show that (in generating uncued responses) participants tend to reach ``further'' into the unobserved past, and with greater accuracy, than the unobserved future.

\begin{figure}[tp]
  \centering
  \includegraphics[width=0.9\textwidth]{results3}
  \caption{\textbf{Characters' references drive participants' retrodiction and prediction performance.}  \textbf{A. Illustration of annotation approach.}  We manually annotated references to events in past or future segments in characters' spoken conversations.  We matched each such reference with its corresponding storyline event (and its corresponding segment number for onscreen events, or half-step segment number for offscreen events).  We then tracked the hit rate separately for referenced versus unreferenced events, in participants' uncued retrodictions and predictions.  \textbf{B. Reference rate as a function of lag.}  Across all possible just-watched segments (lag 0), the bar heights denote the average proportions of events referenced in other past (orange, negative lags) or future (blue, positive lags) segments.  \textbf{C. Difference in hit rates between all events and unreferenced events.}  To highlight the effect of characters' references to past and future events on participants' retrodictions and predictions, here we display the difference in across-segment mean hit rates between all events and unreferenced events, as a function of temporal distance (lag) to the just-watched segment.  \textbf{D. Hit rates for unreferenced events.}  The average response hit rates for unreferenced events are displayed as a function of temporal distance to the just-watched segment.  Error bars denote bootstrapped 95\% confidence intervals.  Panels B--D: colors are described in the Figure~\ref{fig:result2} caption.  \textbf{E.  Hit rates and counts of referenced and unreferenced events.}  As a function of temporal distance to the just-watched segment, the sub-panels display the across-segment mean numbers ($x$-axes) and hit rates ($y$-axes) of referenced (red) and unreferenced (gray) events that participants hit (darker shading) or missed (lighter shading) in their uncued retrodictions (top sub-panel) and uncued predictions (bottom sub-panel).}
  \label{fig:result3}
\end{figure}

What might be driving participants to retrodict further and more accurately into the unobserved past, compared with their predictions of the unobserved future?  By inspecting the video content, we noticed that characters in the television show frequently referenced both past events and (planned or predicted) future events in their spoken conversations.  We wondered whether the characters' references might show temporal asymmetries that might explain participants' behaviors.  Across all of the characters' conversations, and across all of the video segments, we manually identified a total of 82 references to past or future events (i.e., that occurred onscreen or offscreen before or after the events depicted in the current segment; Fig.~\ref{fig:result3}A, \references A).  Characters tended to reference the past (52 references) more than the future (30 references), consistent with previous work~\citep{DemiEtal18}.  References to the past were also skewed to more temporally distant events compared with references to the future (Figs.~\ref{fig:result3}B,~\references B).  These observations indicate that the characters in the stimulus display a preference for the past (versus future) in their conversations.  Might this asymmetry be driving the asymmetries in participants' retrodictions versus predictions?

Controlling for temporal distance (lag), past and future events that story characters referenced in their conversations were associated with higher hit rates than unreferenced events (uncued retrodiction: OR = 12.70, $Z = 10.94$, $p < 0.001$, CI: 8.06 to 20.03; uncued prediction: OR = 8.29, $Z = 6.83$, $p < 0.001$, CI: 4.52 to 15.20; Fig.~\ref{fig:result3}E).  This indicates that participants' responses are at least partially influenced by the characters' conversations.  
To estimate the contributions of charactersâ€™ references on hit rates, we computed the difference in hit rates between all events (which comprised both referenced and unreferenced events) and unreferenced events, as a function of lag. 
These differences exhibited a temporal asymmetry in favor of retrodiction (Fig.~\ref{fig:result3}C).  
This indicates that the asymmetries in participants' retrodictions versus predictions are also at least partially influenced by the characters' conversations. 
However, these temporal asymmetries in participants' retrodictions and predictions persisted even for events that characters never referenced in their conversations (hit rates of uncued retrodicted versus predicted unreferenced events: OR = 2.00, $Z = 2.40$, $p = 0.02$, CI: 1.14 to 3.51; Fig.~\ref{fig:result3}D).  When we further separated the unreferenced events into onscreen events and offscreen events, we found that these asymmetries held only for the onscreen events (onscreen: OR = 2.65, $Z = 2.59$, $p = 0.01$, CI: 1.27 to 5.54; offscreen: OR = 1.50, $Z = 0.91$, $p = 0.36$, CI: 0.63 to 3.62).  Taken together, these analyses suggest that asymmetries in the number of references characters make to past and future events partially (but not entirely) explain why participants tend to retrodict the past further and more accurately than they predict the future.

\begin{figure}[tp]
  \centering
  \includegraphics[width=0.8\textwidth]{results4}
  \caption{\textbf{Reference-adjacent events are associated with higher hit rates.}  \textbf{A. Illustration of annotation approach.}  We extended the annotation procedure depicted in Figure~\ref{fig:result3}A to also label unreferenced events that were either temporally adjacent to (i.e., immediately preceding or proceeding) a referenced event (reference-adjacent events) or not (remaining events).  \textbf{B. Adjacent reference rate for unreferenced events as a function of lag.}  Across all possible just-watched segments (lag 0), the bar heights denote the average proportion of unreferenced events in other past (orange, negative lags) or future (blue, positive lags) segments that were temporally adjacent to any referenced event.  \textbf{C. Difference in hit rates between unreferenced events and remaining events.}  To highlight the effect of reference adjacency on retrodiction and prediction of unreferenced events, here we display the difference in across-segment mean hit rates between unreferenced events and remaining events, as a function of temporal distance (lag) to the just-watched segment.  \textbf{D.  Hit rates for remaining events.}  The across-segment mean response hit rates for unreferenced events that were \textit{not} temporally adjacent to any referenced events are displayed as a function of temporal distance to the just-watched segment. Error bars denote bootstrapped 95\% confidence intervals.  Panels B--D: colors are described in the Figure~\ref{fig:result2} caption.  \textbf{E. Hit rates and counts of referenced, reference-adjacent, and remaining events.}  As a function of temporal distance to the just-watched segment, the sub-panels display the numbers ($x$-axes) and proportions ($y$-axes) of referenced (red), reference-adjacent (purple), and remaining (gray) events that participants hit (darker shading) or missed (lighter shading) in their uncued retrodictions (top sub-panel) and uncued predictions (bottom sub-panel).}
  \label{fig:result4}
\end{figure}

If characters' direct references cannot fully account for the temporal asymmetry in retrodicting the unobserved past versus predicting the unobserved future, what other factors might explain this phenomenon?  The results above indicate that charactersâ€™ references to specific unobserved events in the past or future boost participantsâ€™ estimates of these events.  If there are associations and dependencies between temporally adjacent events, might charactersâ€™ references to specific events also boost participantsâ€™ estimates of other events that were temporally \textit{adjacent} to the referenced events (Fig.~\ref{fig:result4}A)?  Because characters tended to refer to past events more often than future events, the proportions of unreferenced events that were adjacent to referenced events should show a similar temporal asymmetry in favor of the past.  We confirmed this intuition by computing the proportions of unreferenced events in the stimulus that were temporally adjacent to past or future events referenced by the characters during a given segment.  Here we defined \textit{temporally adjacent} as any event within an absolute lag of one relative to a referenced onscreen event, or within an absolute lag of 0.5 to a referenced offscreen event.  We also defined \textit{remaining} events as unreferenced events that were not temporally adjacent to any referenced events.  As shown in Figure~\ref{fig:result4}B, we observed higher proportions of unreferenced past than future events that were temporally adjacent to referenced events.  Further, these reference-adjacent events had higher hit rates than remaining events after controlling for absolute lag (uncued retrodiction: OR = 7.15, $Z = 2.40$, $p = 0.02$, CI: 1.44 to 35.58; uncued prediction: OR = 3.11, $Z = 2.30$, $p = 0.02$, CI: 1.18 to 8.21; Fig.~\ref{fig:result4}E).  To estimate the contributions of reference adjacency on hit rates, we computed the difference in hit rates between unreferenced events (which comprised both reference-adjacent and remaining events) and remaining events, as a function of lag.  These differences exhibited a temporal asymmetry in favor of retrodiction.  This suggests that reference-adjacent events also contribute to participants' retrodiction advantage.  Remaining events did \textit{not} exhibit a reliable temporal asymmetry (OR = 0.75, $Z = 0.33$, $p = 0.74$, CI: 0.14 to 4.08; Fig.~\ref{fig:result4}D), suggesting that, after accounting for temporal adjacency, character's references to past and future events can explain participants' retrodiction advantage.

\begin{figure}[tp]
  \centering
  \includegraphics[width=\textwidth]{results5}
  \caption{\textbf{Referenced events are associated with higher hit rates, but referring events are not.}  \textbf{A. Illustration of annotation approach.}  We extended the annotation procedure depicted in Figure~\ref{fig:result3}A to also label which events \textit{contained} references to events in other segments.  \textbf{B. Referenced versus referring events.}  During event $i$, when a character makes a reference to another event ($j$), we define $i$ as the \textit{referring} event and $j$ as the \textit{referenced} event.  \textbf{C.  Referring rate as a function of lag.}  Across all possible just-watched segments (lag 0), the bar heights denote the across-segment mean proportions of events containing references to events in other past (orange, negative lags) or future (blue, positive lags) segments.  The bar colors are described in the Figure~\ref{fig:result2} caption.  \textbf{D. Hit rates and counts of referenced, referring, and other events.}  As a function of temporal distance to the just-watched segment, the sub-panels display the numbers ($x$-axes) and hit rates ($y$-axes) of referenced (red), referring (green), and other (gray) events that participants hit (darker shading) or missed (lighter shading) in their uncued retrodictions (top sub-panel) and uncued predictions (bottom sub-panel).}
  \label{fig:result5}
\end{figure}

The preceding analyses show that when characters reference past or future events, those referenced events, and other events that are temporally adjacent to the referenced events, are more likely to be retrodicted and predicted.  In other words, referring to a past or future event in conversation leads to a ``boost'' in that event's hit rate.  We wondered whether this boost was bi-directional.  In particular: when a character refers (during a \textit{referring event}) to another event (i.e., the \textit{referenced event}), does this boost only the referenced event's hit rate, or does the referring event also receive a boost?  We labeled each event as a ``referring event'', a ``referenced event'', or a ``other event'' (i.e., not referring or referenced; Fig.~\ref{fig:result5}A, B).  We limited our analysis to references to onscreen (explicit) events.   Consistent with our analysis of character's references to other events (Fig.~\ref{fig:result3}B), \textit{referring} events exhibited a \textit{forward} temporal asymmetry (Fig.~\ref{fig:result5}C).  Controlling for absolute lag, we found that referring events were associated with lower hit rates than referenced events (uncued retrodiction: OR = 0.03, $Z = -4.81$, $p < 0.001$, CI: 0.01 to 0.11; uncued prediction: OR = 0.04, $Z = -5.84$, $p < 0.001$, CI: 0.01 to 0.12; Fig.~\ref{fig:result3}D) and had no reliable differences in hit rates compared with other events (uncued retrodiction: OR = 0.37, $Z = -1.46$, $p = 0.15$, CI: 0.10 to 1.41; uncued prediction: OR = 2.16, $Z = 1.68$, $p = 0.09$, CI: 0.88 to 5.30).  This indicates that only referenced events received a hit rate boost (relative to referring events), suggesting that the retrodictive and predictive benefits of references are directed (i.e., asymmetric).


\section*{Discussion}
We asked participants to watch sequences of movie segments from a character-driven television drama.  Across trials and participants, we controlled for how many segments preceding or proceeding the target segment the participants had seen, prior to watching the target segment.  Then we asked participants to either predict what would happen next, retrodict what had happened before, or recount what had happened in the just-watched target segment.  We found that participants tended to more accurately and more readily retrodict the unobserved past than predict the unobserved future.  We traced this temporal asymmetry to (a) charactersâ€™ tendencies to refer to past events more than future events in their ongoing conversations, and (b) associations between temporally proximal events (Fig.~\ref{fig:discussion}).  Our findings provide a number of important insights into how we make inferences about the unobserved past and future, and how we can study and quantify these processes.

\begin{figure}[tp]
  \centering
  \includegraphics[width=\textwidth]{discussion}
  \caption{\textbf{How much information about the past and future can be extracted by observing the present?}  By definition, let us say that the present moment (lag 0) contains all information about itself (dark gray).  Given learned statistical regularities, one might extrapolate from the present moment into the past or future (light gray).  As illustrated in this schematic, the information contained in the present about other moments in time falls off with absolute lag.  This falloff is approximately time-symmetric.  References in the present to past events (dark orange) or future events (dark blue) provide additional information about those referenced moments in time, beyond what could be inferred solely from statistical regularities.  This additional information about those referenced moments can also be extrapolated to other moments that are temporally nearby to \textit{them} (light orange and blue).}
  \label{fig:discussion}
\end{figure}

In free recall of random word lists, when the participant recalls the word studied at position $x$, they are likely to next recall the word studied at positions $x \pm 1$.  This phenomenon is termed the \textit{contiguity effect}~\citep{Kaha96}.  The contiguity effect has a well-characterized forward asymmetry~\citep{KahaEtal22}, whereby the probability of next recalling the word from position $x + 1$ is more likely than recalling the word from position $x - 1$.  This forward asymmetry suggests that we move through our memories with greater ease in the forward (versus reverse) temporal direction.  Although our memory systems likely play a role in retrodiction and prediction~\citep{MomeHowa18, BarrEtal20, ChowEtal16}, it is important to draw a distinction between our current paradigm and the circumstances leading to the forward asymmetry in the free recall contiguity effect.  In free recall, for example, relative to the moment the word from position $x$ was studied, the response period is nearer in time to the study of word $x + 1$ than to $x - 1$.  In our paradigm, however, the past and future are equidistant from the present moment.

Several prior studies have examined retrodiction and prediction in statistical learning paradigms that use Markov sequences as stimuli.  In these paradigms, both infants~\citep{TummEtal16} and adults~\citep{JonePash07} show a (numerical) prediction advantage over retrodiction.  During paired associates learning, when Aâ€“B pairs of items are presented simultaneously, participants generally show similar forward (generating B when cued with A) and backward (generating A when cued with B) performance~\citep{AschEben62, Kaha02}.  Taken together, these classic studies do not show the advantage for retrodiction over prediction that we observe here.  What accounts for these apparent discrepancies?  Why do people display a forward temporal asymmetry in free recall and for Markov sequences, temporal \textit{symmetry} in paired associates learning, but a backward asymmetry in our task?  Our work suggests that three main factors determine how readily participants infer one event from another in more complex (e.g., ``naturalisticâ€™â€™) circumstances.  The first factor is that nearby events are associated.  This may follow from the notion that events in narratives, as in real-world experiences, tend to change gradually.  In other words, what is happening in the present moment (where you are located, what you are doing, who you are with, what you are thinking or feeling, etc.) will, in general, be similar to what was happening a moment ago, and also to what will happen in the next moment.  These similarities are roughly symmetric: the past and present are (on average) as similar as the present and future, after controlling for temporal distance.  In our study, this symmetry provides a balanced forward \textit{and} backward advantage for events that are nearby in time to the present moment (Fig.~\ref{fig:discussion}, gray).  The second factor is that, when characters in the narrative refer to other (temporally distant) moments, participants incorporate those references into their retrodictions and predictions (Fig.~\ref{fig:result3}; dark orange and blue in Fig.~\ref{fig:discussion}).  Other work has tended to focus on how memories can be shared across people through conversational references to \textit{prior} experiences~\citep{HirsEcht12, MahrCsib18, Dess07}.  Our study extends this notion by showing that ``memory sharingâ€™â€™ need not be limited solely to past events.  Rather, conversations can also provide information about the \textit{future}, in the form of shared prospective memories.  Presumably due to inferred associations between temporally adjacent events, events that are nearby in time to a referenced event also receive a boost (Fig.~\ref{fig:result4}, light orange and blue in Fig.~\ref{fig:discussion}).  We expect that these first two factors will hold across different narratives and real-world experiences, as associations between temporally proximal items and experiences have been widely documented~\citep[for review, see][]{KahaEtal22, Mann20}.  The third factor is that characters in the narrative used in our study tend to refer to past events more than future events (Fig.~\ref{fig:result3}).  This temporal asymmetry in the charactersâ€™ conversations is what appears to drive the advantage for retrodiction over prediction in our study.  At least one prior study suggests that people are also more likely to refer to past (versus future) events in natural conversations~\citep{DemiEtal18}.  To the extent that this holds in general across narratives and experiences, we expect that the retrodiction advantage we observe here will apply in general.  However, we also hypothesize that in scenarios where people discuss the future \textit{more} than the past, participants should show a \textit{prediction} advantage.  Similarly, when the past and future are balanced in conversations, we hypothesize that the asymmetry should disappear.


% Our memories give information about our past, but not our future.  Why do we only have memories of the past?  Why do we perceive time as flowing from the past \textit{to} the future?  The fundamental laws of physics are time-reversible: given the present position and velocity of a particle, the past and future states of that particle are equally knowable.  In the extreme, causal determinists have argued that an imaginary being who knew the positions and velocities of every particle in the universe (referred to as Laplaceâ€™s demon) would be able to perfectly compute the entire past and future states of the universe using classical mechanics~\citep{Hawk99}.  Given incomplete information, however, past and future are \textit{not} equal.  According to the second law of thermodynamics, the total entropy (e.g., uncertainty or randomness) in a system never decreases.  This ``thermodynamic arrow of time'' implies that the past will always be less uncertain than the future~\citep{Albe00, Carr10, Carr16}.  It is difficult to draw direct inferences about how the thermodynamic arrow of time might affect our memory systems.  One possibility is that the thermodynamic arrow of time may help to explain why we can remember the past but not the future~\citep{MlodBrun14, Rove22}, although this view is currently under debate~\citep{Golo21, HemmShen19}.  The thermodynamic arrow of time has two potential implications for our study.  First, to the extent that the thermodynamic arrow of time explains why we remember the past (but not the future), this gives people (and characters in realistic narratives) more information about their own pasts than about their own futures.  Second, the thermodynamic arrow of time also applies to the \textit{observers}' inferences about the past and future.  Because the past is inherently less uncertain than the future, this may confer an advantage to retrodiction over prediction.  A substantial challenge is that real-world events (unlike Markov processes) have no ground truth uncertainty.  Even attempts to \textit{estimate} uncertainty will be heavily dependent on which factors and scales we consider in our calculations.  When we group several microstates into the same macrostate~\citep[known as \textit{course-graining};][]{Rove14}, we make an implicit assumption about which ``level'' of granularity is relevant.  If we retrodict and predict with different degrees of course-graining, this will in turn affect the temporal symmetry of those processes.

In our study, we explicitly designed participants' experiences such that both the past and future were unobserved.  How representative is this scenario of everyday life?  For example, we might try to speculate about the unobserved future when making plans or goals, but when might we encounter situations where the past is unobserved but still useful for us to speculate about?  Real-life events have long-range dependencies.  In general, because the future depends on what happened in the past, discovering or estimating information about the unobserved past can help us form predictions about the future.  We illustrate this point in Figure~\ref{fig:discussion} by showing that the additional information contributed by a referenced past event can also extend into the future (light orange bars at lags $> 0$).  This could explain why humans devote substantial effort and resources to attempting to figure out what happened in the unobserved past: history, anthropology, geology, detective and forensic science, and other related fields are each primarily focused on understanding, retrodicting, or reconstructing past events.




\section*{Methods}
\subsection*{Participants}
A total of 36 participants (25 female, mean age 21.47 years, range 19--50 years) were recruited from the Dartmouth College community. All participants had self-reported normal or corrected-to-normal vision, hearing, and memory, and had not watched any episodes of \textit{Why Women Kill} before the experiment. Participants gave written consent to enroll in the study under a protocol approved by the Committee for the Protection of Human Subjects at Dartmouth College.  Participants received course credit or monetary compensation for their time. Two participants completed only the first half of the study and one participantâ€™s data of the second half was lost due to technical error. All available data were used in the analyses.

\subsection*{Stimuli}
The stimulus used in the study were segments of the CBS television series \textit{Why Women Kill} Season 1. The TV series contained three distinct storylines depicting three womenâ€™s marital relationships. The three storylines, which took place in the 1960s, 1980s, and 2019, were shown in an interleaved fashion in the original episodes. The first 11 segments from the 1960s and 1980s storylines, across the first and second episodes, were used in our study. Segments were divided based on major scene cuts, which primarily corresponded to storyline shifts in the original episodes. The mean length of the segments was 2.05 min (range 0.97--3.87 min). We chose this TV series based on its strictly linear storytelling (within each storyline) and its realistic settings where most events depicted everyday life. The plots were focused on the main characters (Beth in storyline 1 and Simone in storyline 2), who were present in all the segments in the corresponding storylines.

\subsection*{Task design and procedure}
Our experimental paradigm was divided across two testing sessions. In each session, participants performed a sequence of tasks on segments from one storyline (Fig.~\ref{fig:method}).  For each storyline, there were four different task sequences: two forward chronological order sequences and two backward chronological order sequences. Participants completed one task sequence in forward chronological order for one storyline, and one in backward chronological order for the other storyline. The order of the two sessions (forward chronological order sequence first or backward chronological order sequence first), and the pairing of task sequences with storylines, were counterbalanced across participants.

Tasks in each sequence alternated between watching, recall, and retrodiction or prediction, with the specific order of tasks differing across the four sequences. For example, in sequence A1, participants first watched segment 1, followed by an immediate recall of segment 1. Then they predicted what would happen in segment 2 (first uncued and then character-cued). Participants then watched segment 3 and recalled segment 3. After that, participants guessed what happened in segment 2 again, which we termed ``updated prediction''. Then they watched segment 2, recalled segment 2, and so on as depicted in Figure~\ref{fig:method}.  This procedure was repeated to cover all possible segments.
We also note several edge cases at the start and end of the narrative sequences.  Since no segments precede the first segment, participants could never make ``prediction'' responses with the first segment as their target.  For analogous reasons, participants never made ``retrodiction'' responses with the last segment as their target.  Another edge case occurred in task sequences B2 and A2 (Fig.~\ref{fig:method}).  In the A1 and A2 sequences, participants experience the narrative in the original (forward) order, predicting one segment ahead along the way.  In the B1 and B2 sequences, participants experience the narrative in the reverse order, retrodicting one segment ahead along the way.  However, because A2 and B2 are offset from A1 and B2 by one segment, the initial A2 responses are \textit{retro}dictions, and the initial B2 responses are \textit{pre}dictions (i.e., they conflict with the temporal directions of the remaining responses in those conditions).  We therefore excluded from our analysis those initial retrodiction responses from the A2 condition, and the initial prediction responses from the B2 condition.

Before watching each segment, participants were given the following task instructions. After watching the video, participants were instructed to type their responses (retrodiction, prediction, or recall) in 1--4 sentences.  Participants were also asked to specify the characters' names in their responses, i.e., avoiding use of characters' pronouns. For the recall task, the names of the characters in the recall segment were displayed, and participants were asked to summarize the major plot points in the present tense. For the retrodiction and prediction tasks, participants were instructed to retrodict or predict the major plot points of the segment (also in the present tense), as though they had watched the segment and were writing a plot synopsis. They were also instructed to avoid speculation words (e.g., ``I \textit{think} Beth will...''). For the uncued retrodiction and prediction tasks, participants made retrodictions or predictions without any cues provided, so they had to guess which of the characters would be present in the segment. For character-cued retrodictions and predictions, the characters in the target segment were revealed on the screen, alongside participantsâ€™ previous responses. Participants were instructed to include or incorporate those characters into their character-cued responses, if their previous responses did not contain all the characters provided. They were also told that the characters were not necessarily listed in their order of appearance in the segment, and that only the main characters would be given. Also, the characters given did not necessarily interact with each other in that segment, and they could appear in successive events in that segment. If participantsâ€™ previous responses included all the characters given, then they could directly proceed to the next task without updating their response. For all of the prediction and retrodiction tasks, participants were instructed to provide at least one response, but they were given the opportunity enter up to three responses if they felt that multiple possibilities were more or less equally likely. Each response (including recall) was followed by a confidence rating on a 1--5 point scale. However, these confidence data were not analyzed in the present study.

Before their first testing session, participants were given a practice session, where they watched the first segment of storyline 3 followed by a recall trial, an uncued prediction trial, and a character-cued prediction trial. Participants' responses were checked by the experimenter to ensure compliance with the instructions. To provide participants with sufficient background information about the storyline (especially for the backward chronological sequences), at the beginning of each session, participants were shown the time, location, and the main characters (with pictures) of the storyline. The first session was approximately 1.5~h long and the second session was approximately 1~h long. We allowed participants, at their own discretion and convenience, to sign up for two consecutive testing time-slots (i.e., with their testing sessions occurring in immediate succession), or for testing sessions on two different days. The mean inter-session interval was 0.73 days (range: 0--4 days). The experiment was conducted in a sound- and light-attenuated testing room. Videos were displayed using a 27-inch iMac desktop computer (resolution: $5120 \times 2880$) and sound was presented using the iMacâ€™s built-in speakers. The experiment was implemented using jsPsych~\citep{deLe15} and JATOS~\citep{LangEtal15}.

\subsection*{Video annotation}
Events in the first 11 segments of the two storylines were identified by the first author (X.X.), corresponding to major plot points (total: 117; mean: 5.32 per segment; range 3--9). Additionally, 74 offscreen events were identified. Of these 74 offscreen events, 43 events were identified from references in conversations during onscreen events. Another 16 events were identified based on charactersâ€™ transits between two places.  For example, if in segment 1 character A was in place A and in segment 2 she was in place B, then the transit from place A to B for character A would be identified as an offscreen event. The remaining 15 offscreen events were identified based on logical inferences.  For example, if a photo was shown in an onscreen event (but not the act of it being taken), then the action that someone took the photo would be identified as an offscreen event.  Offscreen events always occurred between two contiguous segments, or before the first segment. The purpose of identifying offscreen events was to match participantsâ€™ responses to video events; thus our identification of these offscreen events was not intended to be exhaustive.

\subsection*{Response analyses}
Participants' retrodiction, prediction, and recall responses were minimally processed to correct obvious typos (e.g., in charactersâ€™ names) and remove speculation descriptions (e.g., ``I predict that...'').  All responses were manually coded and matched to events from the video annotations. Retrodiction and prediction responses were coded by two coders (X.X. and Z.Z.). Recall responses were coded by one coder (X.X.).  While most responses were clearly identifiable as either matching specific storyline events or as not matching any storyline events, several ambiguous cases arose.  First, some responses combined or summarized over several (distinct) storyline events.  Second, some responses lacked any specific detail (e.g., ``character A and B talk'' without describing the specific topic(s) of conversation or providing other relevant details).  Based on participants' responses, in addition to the original 117 onscreen events and 74 offscreen events, we added 25 new events (23 onscreen, 2 offscreen) that either summarized across several events or partially matched the annotated events.  Whereas the original events were each assigned a value of one point, we assigned these additional events a half point.  This point system enabled us to directly match events in participants' responses to the annotated events.  In our analyses of retrodictions, predictions, and recalls, we added up the number of points earned for each response to estimate participants' event hit rates.

We coded only the first retrodiction or prediction response in each trial.  For these responses, we also only considered storyline events that were in the same temporal direction as the target segment.  For example, if a participant was asked to retrodict what happened in segment $n$, only events from segments $1...n$ were considered in our analysis.  When coding recall responses, we considered only events from the target segment.  

An additional ambiguous case arose in one participant's responses pertaining to segment 12, storyline 2, whereby the participant correctly identified an onscreen event that had not been included in our original annotations.  To account for this participant's response, we retroactively added that event to our annotations of that segment.  We also identified and counted unmatched events in participants' responses (i.e., events that did not match any annotated events).  In several cases, the two coders' independent scoring disagreed.  These cases were resolved through discussions between the two coders.

To estimate the semantic similarities between pairs of responses, we first transformed each response into a 512-dimensional vector (embedding) using \textit{Universal Sentence Encoder}~\citep[Transformer USE, ][]{CerEtal18}.  We defined \textit{similarity} as the cosine of the angle formed by the responses' vectors.  Following~\cite{HeusEtal21}, we defined the \textit{precision} of participants' responses as the median similarity between that response's vector and the embedding vectors for all other participants' recalls of the target segment.  We defined the \textit{convergence} of a given response as the mean similarity between that response's vector and all other participants' responses to the corresponding segment, in the same condition.  To compute these median or mean similarities we first applied the Fisher $z$-transformation to the similarity values, then took the median or mean of the $z$-transformed similarities, and finally applied the inverse $z$-transformation to obtain the precision or convergence score.

To test the validity and reliability of the USE embeddings, we performed a classification analysis of recall responses using a leave-one-out approach. For each recall response, we calculated its semantic similarity with all other recall responses for the same storyline.  We took the segment with the highest median semantic similarity (to the recall response) as the ``predicted'' segment.  Across all responses, the predicted segments matched the true recalled segments' labels 98.6\% of the time (1088 out of 1103 predictions; chance level: 9\%).

\subsection*{Reference coding}
Two coders (X.X. and Z.Z.) identified character dialogues in the narrative that referred to past events or future (onscreen or offscreen) events.  Only references to events that occurred in a different segment were included in this tagging procedure.  For each reference, the source segment and the referred event number were recorded. A total of 82 references were identified.  Of these, 30 referred to onscreen events and 52 referred to offscreen events. For these referenced events, their corresponding summary events or partial events were also labelled as referenced. In instances where the coders disagreed about a given tag, disagreements were resolved through discussions between the two coders.  In our analyses, each storyline event was coded according to whether or not it had been referenced in the segment(s) that the participant had viewed thus far in the experiment.

In principle, a given event could receive multiple labels.  For example, during event $A$, a character might speak about another event, $B$, during which a reference to a third event ($C$) was made.  In this scenario, event $B$ could be both a ``referring event'' ($B \rightarrow C$) \textit{and} a referenced event ($A \rightarrow B$).  In practice, however, this scenario was quite rare, accounting for only one out of a total of 30 onscreen events.

\subsection*{Statistical analysis}
We used (generalized) linear mixed models to analyze the hit rates and numbers of events retrodicted, predicted, and recalled, as well as the precisions and convergences of participant's responses.  Our models were implemented in \texttt{R} using the \texttt{afex} package.  We carried out comparisons or contrasts, and extracted $p$-values, using the \texttt{emmeans} package.  Participants and stimuli (e.g., segment identity) were modeled as crossed random effects (as specified below).  Random effects were selected as the maximal structure that allowed model convergence. All of our statistical tests were two-sided.

For our tests of the target event hit rates across four \texttt{levels} (uncued, character-cued, updated, and recall; Fig.~\ref{fig:result1}B), we fit a generalized linear mixed model with a binomial link function:
\begin{lstlisting}[language=R]
  cbind(thp, ttp - thp) ~ direction * level * seg_cnt * storyline +
(direction * level | target) +
(direction * level * seg_cnt | subject)
\end{lstlisting}
where \texttt{thp} was the number of points hit for the target segment, \texttt{ttp} was the total number of points for the target segment (from its annotations), \texttt{direction} was either retrodiction or prediction, \texttt{level} had four levels (uncued, character-cued, updated, and recall), \texttt{seg\_cnt} represented the number of segments in the storyline that had been watched (1--10, centered),  \texttt{storyline} had two levels (1 or 2), and \texttt{target} had 22 levels according to the identity of the target segment.  For our tests of precision and convergence (Fig.~\ref{fig:result1}C, D), we fit linear mixed models using the same formula.  To test the effect of \texttt{direction} (retrodiction or prediction) on target event hit rates, precision, and convergence, we fit a (generalized) linear mixed model separately for each of the three levels (uncued, character-cued, and recall).  

For our tests comparing the numbers of hits for different types of events (Fig.~\ref{fig:result2}B), we fit generalized linear mixed models using the same formula, but with a poisson link function.  For these models, we manually doubled the point counts to ensure that half points were mapped onto integers, ensuring compatibility with the poisson link function.

For our analyses of the numbers of events hit, controlling for lag (Fig.~\ref{fig:result2}C), we fit a generalized linear mixed model with a poisson link function:
\begin{lstlisting}[language=R]
  hp_lag ~ direction * full_stp * lag * storyline +
  (direction | base_seg) + (1 | base_seg_pair) +
  (direction * full_stp | lag * storyline | subject)
  \end{lstlisting}
where \texttt{hp\_lag} is the numbers of ``points'' earned (for each lag) in each trial (we manually doubled the point counts to ensure that half points were mapped onto integers, for compatibility with the poisson link function), \texttt{full\_stp} denoted whether the given events (of the given lag) were onscreen (i.e., full step) or offscreen (i.e., half step), \texttt{lag} denotes the (centered) absolute lag, \texttt{base\_seg} denotes the identity of the just-watched segment (22 levels), and \texttt{base\_seg\_pair} denotes the pairing of the just-watched segment and the segment at each lag (440 levels).

For our analyses of the proportions of events hit for referenced versus unreferenced events (Fig.~\ref{fig:result3}D, E), we fit a generalized linear model with a binomial link function:
\begin{lstlisting}[language=R]
  cbind(hp_lag, tp_lag - hp_lag) ~ direction * reference * full_stp +
  lag + (direction | base_seg) +
  (1 | base_seg_pair) +
  (direction * reference * full_stp + lag | subject)
\end{lstlisting}
where \texttt{hp\_lag} denotes the number of earned hit points for each reference type (referenced or unreferenced) at each lag, \texttt{tp\_lag} denotes the total number of possible hit points for each reference type at each lag, and the other variables adhered to the same notation used in the above formulas.

For our tests of the proportions of events hit for all three reference types (referenced, reference-adjacent, and remaining: Fig.~\ref{fig:result4}D, E; or referenced, referring, and other: Fig.~\ref{fig:result5}D), we fit a generalized linear mixed model using the same formula as above, but with three (rather than two) \texttt{reference} levels.

\section*{Code and data availability}
All of the code and data generated for the current manuscript are available online at:

https://github.com/ContextLab/prediction-retrodiction-paper

% \bibliographystyle{apa}
\bibliography{cdl}

\section*{Acknowledgements}
We thank Luke Chang, Yi Fang, Paxton Fitzpatrick, Caroline Lee, Meghan Meyer, Lucy Owen, and Kirsten Ziman for feedback and scientific discussions.  Our work was supported in part by NSF CAREER Award Number 2145172 to J.R.M. The content is solely the responsibility of the authors and does not necessarily represent the official views of our supporting organizations.  The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.

\section*{Author contributions}
Conceptualization: X.X. and J.R.M.; Methodology: X.X. and J.R.M.; Software: X.X.; Analysis: X.X. and Z.Z.; Writing, Reviewing, and Editing: X.X., Z.Z., and J.R.M.; Supervision: J.R.M.

\section*{Competing interests}
The authors declare no competing interests.
\end{document} 